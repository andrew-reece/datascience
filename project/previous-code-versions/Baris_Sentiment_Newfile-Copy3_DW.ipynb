{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Team - Predictive Model\n",
      "Baris Baloglu & Javier Pineda (de Mar)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### QuickRuns:\n",
      "Description: under each key section a quickrun bar helps to quickly navigate to the next necessary step of the parts of the notebook to improve overview and increase speed while running specific parts of the project:\n",
      "<br>\n",
      "\n",
      "<a href=\"#import_data\">Stanford</a>\n",
      "<br>\n",
      "<a href=\"#import_data\">Rottentomatoes</a>\n",
      "<br>\n",
      "<a href=\"#import_data\">NewYorkTimes</a>\n",
      "<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 1. Importing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 1.1 Normal Import Statements <a name=\"import_data\"></a>\n",
      "Collecting all import statements and global settings together in one spot."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#test if canvas stays in on plt.show\n",
      "%matplotlib inline\n",
      "# Not sure what we'll need exactly, so just importing all the usual suspects here\n",
      "import json\n",
      "import requests\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import re\n",
      "import scipy.stats as stats\n",
      "import os, sys\n",
      "import math\n",
      "import time\n",
      "from nltk.corpus import stopwords #If this line doesn't work, use nltk.downloads() and download corpus#\n",
      "\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "\n",
      "\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "#%pylab inline\n",
      "\n",
      "pd.set_option('display.width', 5000)\n",
      "pd.set_option('display.max_columns', 30)\n",
      "pd.set_option('max_rows', 100)\n",
      "\n",
      "# set some nicer defaults for matplotlib\n",
      "from matplotlib import rcParams\n",
      "\n",
      "#these colors come from colorbrewer2.org. Each is an RGB triplet\n",
      "dark2_colors = [(0.10588235294117647, 0.6196078431372549, 0.4666666666666667),\n",
      "                (0.8509803921568627, 0.37254901960784315, 0.00784313725490196),\n",
      "                (0.4588235294117647, 0.4392156862745098, 0.7019607843137254),\n",
      "                (0.9058823529411765, 0.1607843137254902, 0.5411764705882353),\n",
      "                (0.4, 0.6509803921568628, 0.11764705882352941),\n",
      "                (0.9019607843137255, 0.6705882352941176, 0.00784313725490196),\n",
      "                (0.6509803921568628, 0.4627450980392157, 0.11372549019607843),\n",
      "                (0.4, 0.4, 0.4)]\n",
      "\n",
      "rcParams['figure.figsize'] = (10, 6)\n",
      "rcParams['figure.dpi'] = 150\n",
      "rcParams['axes.color_cycle'] = dark2_colors\n",
      "rcParams['lines.linewidth'] = 2\n",
      "rcParams['axes.grid'] = False\n",
      "rcParams['axes.facecolor'] = 'white'\n",
      "rcParams['font.size'] = 14\n",
      "rcParams['patch.edgecolor'] = 'none'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 111
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######<a href=\"#sentiment_data\">Stanford</a> - <a href=\"#sentiment_data\">RottenTomatoes</a> - <a href=\"#sentiment_data\">NewYorkTimes</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2. Get Data\n",
      "\n",
      "Collect all different data sources used as training data in one chapter. All data will be stored in a CSV-File for later usage.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 2.1 Sentiment Analysis Words (sentiment_df) (Run mandatory) <a name=\"sentiment_data\"></a>\n",
      "\n",
      "This is the sentiment data which is used as a reference for word sentiment scores. It is needed for almost all following actions this is why it should be run in any case."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read sentiment data from text file\n",
      "sentiment_df = pd.read_table('sentiment_data.txt', sep='\\t')\n",
      "\n",
      "StopWordList = stopwords.words(\"english\")\n",
      "sentiment_df['in_stopword'] = False\n",
      "sentiment_df['in_stopword'][sentiment_df.word.isin(StopWordList)] = True\n",
      "sentiment_df_NS = sentiment_df[sentiment_df.in_stopword == False]\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 118
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentiment_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>word</th>\n",
        "      <th>happiness_rank</th>\n",
        "      <th>happiness_average</th>\n",
        "      <th>happiness_standard_deviation</th>\n",
        "      <th>twitter_rank</th>\n",
        "      <th>google_rank</th>\n",
        "      <th>nyt_rank</th>\n",
        "      <th>lyrics_rank</th>\n",
        "      <th>in_stopword</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  laughter</td>\n",
        "      <td> 1</td>\n",
        "      <td> 8.50</td>\n",
        "      <td> 0.9313</td>\n",
        "      <td> 3600</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1728</td>\n",
        "      <td> False</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> happiness</td>\n",
        "      <td> 2</td>\n",
        "      <td> 8.44</td>\n",
        "      <td> 0.9723</td>\n",
        "      <td> 1853</td>\n",
        "      <td> 2458</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1230</td>\n",
        "      <td> False</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>      love</td>\n",
        "      <td> 3</td>\n",
        "      <td> 8.42</td>\n",
        "      <td> 1.1082</td>\n",
        "      <td>   25</td>\n",
        "      <td>  317</td>\n",
        "      <td>  328</td>\n",
        "      <td>   23</td>\n",
        "      <td> False</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>     happy</td>\n",
        "      <td> 4</td>\n",
        "      <td> 8.30</td>\n",
        "      <td> 0.9949</td>\n",
        "      <td>   65</td>\n",
        "      <td> 1372</td>\n",
        "      <td> 1313</td>\n",
        "      <td>  375</td>\n",
        "      <td> False</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>   laughed</td>\n",
        "      <td> 5</td>\n",
        "      <td> 8.26</td>\n",
        "      <td> 1.1572</td>\n",
        "      <td> 3334</td>\n",
        "      <td> 3542</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 2332</td>\n",
        "      <td> False</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 97,
       "text": [
        "        word  happiness_rank  happiness_average  happiness_standard_deviation  twitter_rank  google_rank  nyt_rank  lyrics_rank in_stopword\n",
        "0   laughter               1               8.50                        0.9313          3600          NaN       NaN         1728       False\n",
        "1  happiness               2               8.44                        0.9723          1853         2458       NaN         1230       False\n",
        "2       love               3               8.42                        1.1082            25          317       328           23       False\n",
        "3      happy               4               8.30                        0.9949            65         1372      1313          375       False\n",
        "4    laughed               5               8.26                        1.1572          3334         3542       NaN         2332       False"
       ]
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######<a href=\"#sf_make_data\">Stanford</a> - <a href=\"#rt_csv_get_data\">RottenTomatoes</a> - <a href=\"#nyt_csv_get_data\">NewYorkTimes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 2.2 Stanford MovieDB (stanford_df) <a name=\"sf_make_data\"></a>\n",
      "25k reviews divided in 12.5k positive ones and 12.5k negative. Ratings range from 1-10 for 1 negative and 10 positive. All neutral reviews have been excluded beforehand. Dataframe will be constructed from filesystem structure. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Set up function to create stanford dataframe. A function is used to create reusability for the later use in case of testing data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# here the parameter \"data_set\" is a string (either 'train' or 'test')\n",
      "def make_stanford_df(data_set):\n",
      "\n",
      "    # making lists of negative and positive training data filenames, respectively\n",
      "    path_neg = \"stanford_movie/%s/neg/\" % data_set\n",
      "    neg_list = os.listdir(path_neg)\n",
      "    \n",
      "    path_pos = \"stanford_movie/%s/pos/\" % data_set\n",
      "    pos_list = os.listdir(path_pos)\n",
      "    \n",
      "    # making sure we're only getting the filenames we want\n",
      "    # there seems to be hidden files at least in the neg folder\n",
      "    neg_list = [i for i in neg_list if i[0].isdigit()]\n",
      "    pos_list = [i for i in pos_list if i[0].isdigit()]\n",
      "    \n",
      "    # making dataframe for negative training data\n",
      "    neg_df = pd.DataFrame(neg_list, columns = ['filename'])\n",
      "    \n",
      "    neg_df['id'] = neg_df.apply(lambda x: \n",
      "                            'neg' + x['filename'][:x['filename'].index('_')], axis=1)\n",
      "    \n",
      "    neg_df['rating'] = neg_df.apply(lambda x: \n",
      "                            x['filename'][x['filename'].index('_')+1:-4], axis=1)\n",
      "    \n",
      "    neg_df['path'] = path_neg\n",
      "    \n",
      "    # making dataframe for positive training data\n",
      "    pos_df = pd.DataFrame(pos_list, columns = ['filename'])\n",
      "    pos_df['id'] = pos_df.apply(lambda x: \n",
      "                            'pos' + x['filename'][:x['filename'].index('_')], axis=1)\n",
      "    pos_df['rating'] = pos_df.apply(lambda x: \n",
      "                            x['filename'][x['filename'].index('_')+1:-4], axis=1)\n",
      "    \n",
      "    pos_df['path'] = path_pos\n",
      "    \n",
      "    # concatenating negative and positive training data into one dataframe\n",
      "    stanford_df = pd.concat([neg_df, pos_df], ignore_index=True)\n",
      "    \n",
      "    # adding column with the movie reviews\n",
      "    stanford_df['review'] = stanford_df.apply(lambda x: \n",
      "                            open(x['path'] + x['filename'], 'r').read(), axis=1)\n",
      "\n",
      "    return stanford_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######<a href=\"#sf_csv_get_data\">Stanford</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Call function to create dataframe:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stanford_df = make_stanford_df('train')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save dataframe to file:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stanford_df.to_csv('stanford_df.csv', index=False)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load dataframe from CSV: <a name=\"sf_csv_get_data\"></a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stanford_df = pd.read_csv('stanford_df.csv')\n",
      "stanford_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>filename</th>\n",
        "      <th>id</th>\n",
        "      <th>rating</th>\n",
        "      <th>path</th>\n",
        "      <th>review</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>     0_3.txt</td>\n",
        "      <td>     neg0</td>\n",
        "      <td> 3</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> Story of a man who has unnatural feelings for ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 10000_4.txt</td>\n",
        "      <td> neg10000</td>\n",
        "      <td> 4</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> Airport '77 starts as a brand new luxury 747 p...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 10001_4.txt</td>\n",
        "      <td> neg10001</td>\n",
        "      <td> 4</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> This film lacked something I couldn't put my f...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 10002_1.txt</td>\n",
        "      <td> neg10002</td>\n",
        "      <td> 1</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> Sorry everyone,,, I know this is supposed to b...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 10003_1.txt</td>\n",
        "      <td> neg10003</td>\n",
        "      <td> 1</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> When I was little my parents took me along to ...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "      filename        id  rating                       path                                             review\n",
        "0      0_3.txt      neg0       3  stanford_movie/train/neg/  Story of a man who has unnatural feelings for ...\n",
        "1  10000_4.txt  neg10000       4  stanford_movie/train/neg/  Airport '77 starts as a brand new luxury 747 p...\n",
        "2  10001_4.txt  neg10001       4  stanford_movie/train/neg/  This film lacked something I couldn't put my f...\n",
        "3  10002_1.txt  neg10002       1  stanford_movie/train/neg/  Sorry everyone,,, I know this is supposed to b...\n",
        "4  10003_1.txt  neg10003       1  stanford_movie/train/neg/  When I was little my parents took me along to ..."
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######<a href=\"#sf_csv_clean_data\">Stanford</a> - (<a href=\"#rt_csv_get_data\">RottenTomatoes</a> - <a href=\"#nyt_csv_get_data\">NewYorkTimes</a>)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some Statistics: <a name=\"sf_stat_get_data\"></a> \n",
      "<br>Compare with: <a href=\"#sf_stat_clean_data\">Clean</a>, <a href=\"#sf_stat_prep_data\">Prepare</a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'length of set:', len(stanford_df)\n",
      "print 'average postlength:', int(np.mean(stanford_df[~stanford_df.review.isnull()].review.apply(lambda x: len(x))))\n",
      "print 'number of positive reviews:', len(stanford_df[stanford_df.rating >= 7])\n",
      "print 'number of negative reviews:', len(stanford_df[stanford_df.rating <= 4])\n",
      "print 'max postlength', stanford_df[~stanford_df.review.isnull()].review.apply(lambda x: len(x)).max()\n",
      "print 'min postlength', stanford_df[~stanford_df.review.isnull()].review.apply(lambda x: len(x)).min()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of set: 25000\n",
        "average postlength: 1325\n",
        "number of positive reviews: 12500\n",
        "number of negative reviews: 12500\n",
        "max postlength "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13704\n",
        "min postlength 52\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 2.3 RottenTomatoes (rottentomatoes_df) <a name=\"rt_get_data\"></a>\n",
      "Around 8k reviews divided in about 6k fresh ones and 2k rotten. Rating's range is binary for 1 fresh and 0 rotten. No neutral reviews have been excluded beforehand. Dataframe will be constructed from local CSV file out of HW3. <a name=\"rt_csv_get_data\"></a> "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rottentomatoes_df = pd.read_csv('critics.csv')\n",
      "rottentomatoes_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>critic</th>\n",
        "      <th>fresh</th>\n",
        "      <th>imdb</th>\n",
        "      <th>publication</th>\n",
        "      <th>quote</th>\n",
        "      <th>review_date</th>\n",
        "      <th>rtid</th>\n",
        "      <th>title</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> Owen Gleiberman</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td> Entertainment Weekly</td>\n",
        "      <td>                                               NaN</td>\n",
        "      <td> 2011-09-07</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>     Derek Adams</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>             Time Out</td>\n",
        "      <td> So ingenious in concept, design and execution ...</td>\n",
        "      <td> 2009-10-04</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> Richard Corliss</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>        TIME Magazine</td>\n",
        "      <td>                 The year's most inventive comedy.</td>\n",
        "      <td> 2008-08-31</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>     David Ansen</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>             Newsweek</td>\n",
        "      <td> A winning animated feature that has something ...</td>\n",
        "      <td> 2008-08-18</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>   Leonard Klady</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>              Variety</td>\n",
        "      <td> The film sports a provocative and appealing st...</td>\n",
        "      <td> 2008-06-09</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "            critic  fresh    imdb           publication                                              quote review_date  rtid      title\n",
        "0  Owen Gleiberman  fresh  114709  Entertainment Weekly                                                NaN  2011-09-07  9559  Toy story\n",
        "1      Derek Adams  fresh  114709              Time Out  So ingenious in concept, design and execution ...  2009-10-04  9559  Toy story\n",
        "2  Richard Corliss  fresh  114709         TIME Magazine                  The year's most inventive comedy.  2008-08-31  9559  Toy story\n",
        "3      David Ansen  fresh  114709              Newsweek  A winning animated feature that has something ...  2008-08-18  9559  Toy story\n",
        "4    Leonard Klady  fresh  114709               Variety  The film sports a provocative and appealing st...  2008-06-09  9559  Toy story"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######(<a href=\"#sf_csv_get_data\">Stanford</a>) - <a href=\"#rt_csv_clean_data\">RottenTomatoes</a> - (<a href=\"#nyt_csv_get_data\">NewYorkTimes</a>)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some Statistics: <a name=\"rt_stat_get_data\"></a> \n",
      "<br>Compare with: <a href=\"#rt_stat_clean_data\">Clean</a>, <a href=\"#rt_stat_prep_data\">Prepare</a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'length of set:', len(rottentomatoes_df)\n",
      "print 'average postlength:', int(np.mean(rottentomatoes_df[~rottentomatoes_df.quote.isnull()].quote.apply(lambda x: len(x))))\n",
      "print 'number of positive reviews:', len(rottentomatoes_df[rottentomatoes_df.fresh == 'fresh'])\n",
      "print 'number of negative reviews:', len(rottentomatoes_df[rottentomatoes_df.fresh == 'rotten'])\n",
      "print 'max postlength', rottentomatoes_df[~rottentomatoes_df.quote.isnull()].quote.apply(lambda x: len(x)).max()\n",
      "print 'min postlength', rottentomatoes_df[~rottentomatoes_df.quote.isnull()].quote.apply(lambda x: len(x)).min()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of set: 27692\n",
        "average postlength: 117\n",
        "number of positive reviews: 11833\n",
        "number of negative reviews: 8458\n",
        "max postlength 256\n",
        "min postlength "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 2.4 New York Times DB (nytimes_df) <a name=\"nyt_get_data\"></a>\n",
      "Around XX lead paragraphs of articles based from given keyword arguments (article set can be changed by altering search parameter below). Note that lead paragraphs are low on words. Data is retrieved online and is saved into a CSV file in the end. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "API parameter: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## NYT API keys\n",
      "api_key_article = \"851e7d0a131bee9bc01097470c238637:13:47475506\"\n",
      "api_key_community = \"519167db119ee6408c4ee51b3c391e11:0:47475506\"\n",
      "api_key_geo = \"a984ad78bf017f0ade1fcd980aa6353f:15:47475506\"\n",
      "api_key_popular = \"09dfaf288ad6c2ec46893a27ca758d41:19:47475506\"\n",
      "api_key_movies = \"e8a48f7d7731698b05267146c681c352:5:47475506\"\n",
      "api_key_semantic = \"9063b41607bbf486247b8e596a1456b8:7:47475506\"\n",
      "api_key_newswire = \"209ebb7b0ab44094970e8b39c63fea7e:2:47475506\"\n",
      "api_key_timestags = \"43b3366f288db10cb019fd532299723f:10:47475506\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Search parameters: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "begindate = \"20000101\" #YYYYMMDD\n",
      "enddate = \"20131112\" #YYYYMMDD\n",
      "\n",
      "## just picked a few terms meant to have a fair spread in content\n",
      "terms = ['mindfulness', 'debt', 'kardashian', 'obama',\n",
      "         'romney', 'obamacare', 'god', 'terrorism', 'nazi', \n",
      "         'hussein', 'war', 'depression', 'abortion', 'sex']\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Get data from nytimes.com: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# intially an empty dataframe\n",
      "nytimes_df = pd.DataFrame()\n",
      "\n",
      "# loop through terms\n",
      "for term in terms:\n",
      "    \n",
      "    # api request for each term\n",
      "    url = ''.join([\"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=\", term,\n",
      "                   \"&begin_date=\", begindate, \n",
      "                   \"&end_date=\", enddate,\n",
      "                   \"&api-key=\",api_key_article])\n",
      "        \n",
      "    req = requests.get(url).text\n",
      "    \n",
      "    # decode into json dicts\n",
      "    jsons = json.loads(req)\n",
      "    \n",
      "    # loop through each article returned from API request\n",
      "    for doc in jsons['response']['docs']:\n",
      "\n",
      "        # making dataframe; a term will appear in multiple rows\n",
      "        doc_df = pd.DataFrame([term], columns = ['term'])\n",
      "        \n",
      "        # alternative way of dealing with none-types\n",
      "        if json.dumps(doc['abstract']) != 'null':\n",
      "        \n",
      "            # encode weird ascii stuff\n",
      "            abstract = [doc['abstract'].encode('utf-8')]\n",
      "            \n",
      "            # making dataframe and adding abstracts\n",
      "            doc_df['abstract'] = abstract\n",
      "            \n",
      "        # this way we take all data, and we can do away with what we don't want later    \n",
      "        else:\n",
      "            abstract = np.nan\n",
      "            doc_df['abstract'] = abstract\n",
      "            \n",
      "        # can add an if-else clause for anything you want to get, then add to doc_df\n",
      "        if json.dumps(doc['lead_paragraph']) != 'null':\n",
      "            \n",
      "            lead = [doc['lead_paragraph'].encode('utf-8')]\n",
      "            doc_df['lead'] = lead\n",
      "            \n",
      "        else:\n",
      "            lead = np.nan\n",
      "            doc_df['lead'] = lead\n",
      "        \n",
      "        nytimes_df = pd.concat([nytimes_df, doc_df]).reset_index(drop=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save dataframe to file:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nytimes_df.to_csv('nytimes_df.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load dataframe from CSV: <a name=\"nyt_csv_get_data\"></a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nytimes_df = pd.read_csv('nytimes_df.csv')\n",
      "nytimes_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>abstract</th>\n",
        "      <th>lead</th>\n",
        "      <th>term</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> Mindfulness is terrific for the person practic...</td>\n",
        "      <td> The other night at a dinner party, a friend de...</td>\n",
        "      <td> mindfulness</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>                                               NaN</td>\n",
        "      <td> Mindfulness is terrific for the person practic...</td>\n",
        "      <td> mindfulness</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> Jennifer Egan article on her experience at Spi...</td>\n",
        "      <td> Peter Williams sits cross-legged on an upholst...</td>\n",
        "      <td> mindfulness</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> Two-thirds of doctors experience the emotional...</td>\n",
        "      <td>                                               NaN</td>\n",
        "      <td> mindfulness</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> In this week's Doctor and Patient column, Dr. ...</td>\n",
        "      <td> Everybody has to multitask at work. But when d...</td>\n",
        "      <td> mindfulness</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "                                            abstract                                               lead         term\n",
        "0  Mindfulness is terrific for the person practic...  The other night at a dinner party, a friend de...  mindfulness\n",
        "1                                                NaN  Mindfulness is terrific for the person practic...  mindfulness\n",
        "2  Jennifer Egan article on her experience at Spi...  Peter Williams sits cross-legged on an upholst...  mindfulness\n",
        "3  Two-thirds of doctors experience the emotional...                                                NaN  mindfulness\n",
        "4  In this week's Doctor and Patient column, Dr. ...  Everybody has to multitask at work. But when d...  mindfulness"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######(<a href=\"#sf_csv_get_data\">Stanford</a> - <a href=\"#rt_csv_get_data\">RottenTomatoes</a>) - <a href=\"#nyt_csv_clean_data\">NewYorkTimes</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some Statistics: <a name=\"nyt_stat_get_data\"></a> \n",
      "<br>Compare with: <a href=\"#nyt_stat_clean_data\">Clean</a>, <a href=\"#nyt_stat_prep_data\">Prepare</a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'length of set:', len(nytimes_df)\n",
      "print 'average postlength:', int(np.mean(nytimes_df.lead[~nytimes_df.lead.isnull()].apply(lambda x: len(x))))\n",
      "print 'number of positive reviews:', 'currently unknown'\n",
      "print 'number of negative reviews:', 'currently unknown'\n",
      "print 'max postlength', nytimes_df.lead[~nytimes_df.lead.isnull()].apply(lambda x: len(x)).max()\n",
      "print 'min postlength', nytimes_df.lead[~nytimes_df.lead.isnull()].apply(lambda x: len(x)).min()\n",
      "                            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of set: 140\n",
        "average postlength: 325\n",
        "number of positive reviews: currently unknown\n",
        "number of negative reviews: currently unknown\n",
        "max postlength 1380\n",
        "min postlength 35\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 3. Clean Data\n",
      "\n",
      "Clear datasources from any empty or unneccassary data rows or specific entries.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 3.1 Stanford MovieDB (stanford_clean_df) <a name=\"sf_csv_clean_data\"></a>\n",
      "Currently no cleaning neccessary. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stanford_clean_df = stanford_df\n",
      "stanford_clean_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>filename</th>\n",
        "      <th>id</th>\n",
        "      <th>rating</th>\n",
        "      <th>path</th>\n",
        "      <th>review</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>     0_3.txt</td>\n",
        "      <td>     neg0</td>\n",
        "      <td> 3</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> Story of a man who has unnatural feelings for ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 10000_4.txt</td>\n",
        "      <td> neg10000</td>\n",
        "      <td> 4</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> Airport '77 starts as a brand new luxury 747 p...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 10001_4.txt</td>\n",
        "      <td> neg10001</td>\n",
        "      <td> 4</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> This film lacked something I couldn't put my f...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 10002_1.txt</td>\n",
        "      <td> neg10002</td>\n",
        "      <td> 1</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> Sorry everyone,,, I know this is supposed to b...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 10003_1.txt</td>\n",
        "      <td> neg10003</td>\n",
        "      <td> 1</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> When I was little my parents took me along to ...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "      filename        id  rating                       path                                             review\n",
        "0      0_3.txt      neg0       3  stanford_movie/train/neg/  Story of a man who has unnatural feelings for ...\n",
        "1  10000_4.txt  neg10000       4  stanford_movie/train/neg/  Airport '77 starts as a brand new luxury 747 p...\n",
        "2  10001_4.txt  neg10001       4  stanford_movie/train/neg/  This film lacked something I couldn't put my f...\n",
        "3  10002_1.txt  neg10002       1  stanford_movie/train/neg/  Sorry everyone,,, I know this is supposed to b...\n",
        "4  10003_1.txt  neg10003       1  stanford_movie/train/neg/  When I was little my parents took me along to ..."
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######<a href=\"#prep_features\">Stanford</a> - (<a href=\"#rt_csv_clean_data\">RottenTomatoes</a> - <a href=\"#nyt_csv_clean_data\">NewYorkTimes</a>)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some Statistics: <a name=\"sf_stat_celan_data\"></a> \n",
      "<br>Compare with: <a href=\"#sf_stat_get_data\">Plain</a>, <a href=\"#sf_stat_prep_data\">Prepare</a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'length of set:', len(stanford_clean_df)\n",
      "print 'average postlength:', int(np.mean(stanford_clean_df[~stanford_clean_df.review.isnull()].review.apply(lambda x: len(x))))\n",
      "print 'number of positive reviews:', len(stanford_clean_df[stanford_clean_df.rating >= 7])\n",
      "print 'number of negative reviews:', len(stanford_clean_df[stanford_clean_df.rating <= 4])\n",
      "print 'max postlength', stanford_clean_df[~stanford_clean_df.review.isnull()].review.apply(lambda x: len(x)).max()\n",
      "print 'min postlength', stanford_clean_df[~stanford_clean_df.review.isnull()].review.apply(lambda x: len(x)).min()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of set: 25000\n",
        "average postlength: 1325\n",
        "number of positive reviews: 12500\n",
        "number of negative reviews: 12500\n",
        "max postlength "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13704\n",
        "min postlength 52\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 3.2 RottenTomatoes (rottentomatoes_clean_df)\n",
      "Around 8k reviews divided in about 6k fresh ones and 2k rotten. Rating's range is binary for 1 fresh and 0 rotten. No neutral reviews have been excluded beforehand. Dataframe will be constructed from local CSV file out of HW3. <a name=\"rt_csv_get_data\"></a> "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rottentomatoes_clean_df = rottentomatoes_df[~rottentomatoes_df.quote.isnull()]\n",
      "rottentomatoes_clean_df = rottentomatoes_clean_df[rottentomatoes_clean_df.fresh != 'none']\n",
      "rottentomatoes_clean_df = rottentomatoes_clean_df[rottentomatoes_clean_df.quote.str.len() > 0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save dataframe to file:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rottentomatoes_clean_df.to_csv('rottentomatoes_clean_df.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load dataframe from CSV: <a name=\"rt_csv_clean_data\"></a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rottentomatoes_clean_df = pd.read_csv('rottentomatoes_clean_df.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######(<a href=\"#sf_csv_clean_data\">Stanford</a>) - <a href=\"#prep_features\">RottenTomatoes</a> - (<a href=\"#nyt_csv_clean_data\">NewYorkTimes</a>)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some Statistics: <a name=\"rt_stat_clean_data\"></a> \n",
      "<br>Compare with: <a href=\"#rt_stat_get_data\">Plain</a>, <a href=\"#rt_stat_prep_data\">Prepare</a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rottentomatoes_clean_df = pd.read_csv('rottentomatoes_clean_df.csv')\n",
      "print 'length of set:', len(rottentomatoes_clean_df)\n",
      "print 'average postlength:', int(np.mean(rottentomatoes_clean_df.quote.apply(lambda x: len(x))))\n",
      "print 'number of positive reviews:', len(rottentomatoes_clean_df[rottentomatoes_clean_df.fresh == 'fresh'])\n",
      "print 'number of negative reviews:', len(rottentomatoes_clean_df[rottentomatoes_clean_df.fresh == 'rotten'])\n",
      "print 'max postlength', rottentomatoes_clean_df.quote.apply(lambda x: len(x)).max()\n",
      "print 'min postlength', rottentomatoes_clean_df.quote.apply(lambda x: len(x)).min()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of set: 15572\n",
        "average postlength: 117\n",
        "number of positive reviews: 9486\n",
        "number of negative reviews: 6086\n",
        "max postlength 256\n",
        "min postlength 4\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 3.3 New York Times DB (nytimes_clean_df)\n",
      "Eliminate all empty lead paragraphs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nytimes_clean_df = nytimes_df[~nytimes_df.lead.isnull()]\n",
      "nytimes_clean_df = nytimes_clean_df[nytimes_clean_df.lead != 'none']\n",
      "nytimes_clean_df = nytimes_clean_df[nytimes_clean_df.lead.str.len() > 0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save dataframe to file:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nytimes_clean_df.to_csv('nytimes_clean_df.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load dataframe from CSV: <a name=\"nyt_csv_clean_data\"></a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nytimes_clean_df = pd.read_csv('nytimes_clean_df.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######(<a href=\"#sf_csv_clean_data\">Stanford</a> - <a href=\"#rt_csv_clean_data\">RottenTomatoes</a>) - <a href=\"#prep_features\">NewYorkTimes</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some Statistics: <a name=\"nyt_stat_clean_data\"></a> \n",
      "<br>Compare with: <a href=\"#nyt_stat_get_data\">Plain</a>, <a href=\"#nyt_stat_prep_data\">Prepare</a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'length of set:', len(nytimes_clean_df)\n",
      "print 'average postlength:', int(np.mean(nytimes_clean_df.lead.apply(lambda x: len(x))))\n",
      "print 'number of positive reviews:', 'currently unknown'\n",
      "print 'number of negative reviews:', 'currently unknown'\n",
      "print 'max postlength', nytimes_clean_df.lead.apply(lambda x: len(x)).max()\n",
      "print 'min postlength', nytimes_clean_df.lead.apply(lambda x: len(x)).min()\n",
      "                            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of set: 134\n",
        "average postlength: 325\n",
        "number of positive reviews: currently unknown\n",
        "number of negative reviews: currently unknown\n",
        "max postlength 1380\n",
        "min postlength 35\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 4. Prepare Data\n",
      "\n",
      "Prepare datasources with neccessary extenstion including required featurelist. Result will be stored in local CSV files.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Features <a name=\"prep_features\"></a>\n",
      "Collection of feature methods that can be called by dataframe to apply on all rows."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def post_length(text):\n",
      "    \n",
      "    words_df = pd.DataFrame(text.split(' '), columns=['words'])\n",
      "    words_df['words'] = words_df.words.apply(lambda x: str.lower(re.sub(\"\\W\", '', x)))\n",
      "    words_df['word_length'] = words_df.words.apply(lambda x: len(x))\n",
      "    words_df = words_df[words_df.word_length > 0]\n",
      "    tot_word_count = len(words_df)\n",
      "    return tot_word_count\n",
      "\n",
      "\n",
      "def avg_word_length(text):\n",
      "    words_df = pd.DataFrame(text.split(' '), columns=['words'])\n",
      "    words_df['words'] = words_df.words.apply(lambda x: str.lower(re.sub(\"\\W\", '', x)))           \n",
      "    words_df['word_length'] = words_df.words.apply(lambda x: len(x))\n",
      "    words_df = words_df[words_df.word_length > 0]      \n",
      "    average_length = round(np.mean(words_df.word_length.values), 2)    \n",
      "    return average_length\n",
      "\n",
      "\n",
      "def avg_senti_score(text):\n",
      "    #now = time.time()\n",
      "    words_df = pd.DataFrame(text.split(' '), columns=['words'])\n",
      "    words_df['words'] = words_df.words.apply(lambda x: str.lower(re.sub(\"\\W\", '', x)))\n",
      "    words_df['word_length'] = words_df.words.apply(lambda x: len(x))\n",
      "    words_df = words_df[words_df.word_length > 0]\n",
      "    words_df['in_sentiment'] = False\n",
      "    words_df['in_sentiment'][words_df.words.isin(sentiment_df.word)] = True\n",
      "    words_df['happiness_avg'] = np.nan\n",
      "    words_df['happiness_avg'][words_df.in_sentiment == True] = words_df.words[words_df.in_sentiment == True].apply(lambda x: \n",
      "                float(sentiment_df.happiness_average[sentiment_df.word == x].values))\n",
      "    average_score = round(np.mean(words_df.happiness_avg[~words_df.happiness_avg.isnull()].values), 3)\n",
      "    #later = time.time()\n",
      "    #print 'time used for entry:', float(later - now)\n",
      "    return float(average_score)\n",
      "\n",
      "\"\"\"\n",
      "def avg_senti_score2(text):\n",
      "    #now = time.time()\n",
      "    words_df = pd.DataFrame(text.split(' '), columns=['words'])\n",
      "    words_df['words'] = words_df.words.apply(lambda x: str.lower(re.sub(\"\\W\", '', x)))\n",
      "    words_df['word_length'] = words_df.words.apply(lambda x: len(x))\n",
      "    words_df = words_df[words_df.word_length > 0]\n",
      "    words_df['in_sentiment'] = False\n",
      "    words_df['in_sentiment'][words_df.words.isin(sentiment_df.word)] = True\n",
      "    words_df['happiness_avg2'] = np.nan\n",
      "    words_df['happiness_avg2'][words_df.in_sentiment == True] = words_df.words[words_df.in_sentiment == True].apply(lambda x: \n",
      "                float(sentiment_df.happiness_average2[sentiment_df.word == x].values))\n",
      "    average_score2 = round(np.mean(words_df.happiness_avg2[~words_df.happiness_avg2.isnull()].values), 3)\n",
      "    #later = time.time()\n",
      "    #print 'time used for entry:', float(later - now)\n",
      "    return float(average_score2)\n",
      "\"\"\"\n",
      "\n",
      "def avg_senti_score2(text):\n",
      "    #now = time.time()\n",
      "    words_df = pd.DataFrame(text.split(' '), columns=['words'])\n",
      "    words_df['words'] = words_df.words.apply(lambda x: str.lower(re.sub(\"\\W\", '', x)))\n",
      "    words_df['word_length'] = words_df.words.apply(lambda x: len(x))\n",
      "    words_df = words_df[words_df.word_length > 0]\n",
      "    words_df['in_sentiment'] = False\n",
      "    words_df['in_sentiment'][words_df.words.isin(sentiment_df_NS.word)] = True\n",
      "    words_df['happiness_avg_2'] = np.nan\n",
      "    words_df['happiness_avg_2'][words_df.in_sentiment == True] = words_df.words[words_df.in_sentiment == True].apply(lambda x: \n",
      "                float(sentiment_df_NS.happiness_average[sentiment_df_NS.word == x].values))\n",
      "    average_score_2 = round(np.mean(words_df.happiness_avg_2[~words_df.happiness_avg_2.isnull()].values), 3)\n",
      "    #later = time.time()\n",
      "    #print 'time used for entry:', float(later - now)\n",
      "\n",
      "    return float(average_score_2)\n",
      "\n",
      "def dyn_senti_score(text):    \n",
      "    #now = time.time()\n",
      "    words_df = pd.DataFrame(text.split(' '), columns=['words'])\n",
      "    words_df['words'] = words_df.words.apply(lambda x: str.lower(re.sub(\"\\W\", '', x)))\n",
      "    words_df['word_length'] = words_df.words.apply(lambda x: len(x))\n",
      "    words_df = words_df[words_df.word_length > 0]\n",
      "    words_df['in_sentiment'] = False\n",
      "    words_df['in_sentiment'][words_df.words.isin(sentiment_df_NS.word)] = True\n",
      "    words_df['happiness_avg'] = np.nan\n",
      "    words_df['happiness_avg'][words_df.in_sentiment == True] = words_df.words[words_df.in_sentiment == True].apply(lambda x: \n",
      "                float(sentiment_df_NS.happiness_average[sentiment_df_NS.word == x].values))\n",
      "   \n",
      "    avg_sent_score = round(np.mean(words_df.happiness_avg[~words_df.happiness_avg.isnull()].values), 3)\n",
      "\n",
      "    sent_min = words_df['happiness_avg'].min(axis=0)\n",
      "    sent_max = words_df['happiness_avg'].max(axis=0)\n",
      "    sent_range = sent_max - sent_min\n",
      "    range_constant = 0.1\n",
      "    dispersion = range_constant * sent_range\n",
      "    ## lower and upper boundaries for dynamic exclusion\n",
      "    \n",
      "    dyn_exclude_min = avg_sent_score - dispersion\n",
      "    dyn_exclude_max = avg_sent_score + dispersion\n",
      "    \n",
      "    words_df['dyn_exclusion'] = 'True'\n",
      "    words_df['dyn_exclusion'][(words_df.happiness_avg >=dyn_exclude_max)] = 'False'\n",
      "    words_df['dyn_exclusion'][(words_df.happiness_avg <=dyn_exclude_min)] = 'False'\n",
      "\n",
      "    \n",
      "    avghdyn = np.nan\n",
      "    avghdyn = words_df[words_df['dyn_exclusion'] == 'False']['happiness_avg'].mean()\n",
      "    \n",
      "    return float(avghdyn)\n",
      "\n",
      "def google_rank(text):   \n",
      "    words_df = pd.DataFrame(text.split(' '), columns=['words'])\n",
      "    words_df['words'] = words_df.words.apply(lambda x: str.lower(re.sub(\"\\W\", '', x)))\n",
      "    words_df['word_length'] = words_df.words.apply(lambda x: len(x))\n",
      "    words_df = words_df[words_df.word_length > 0]\n",
      "    words_df['in_sentiment'] = False\n",
      "    words_df['in_sentiment'][words_df.words.isin(sentiment_df_NS.word)] = True\n",
      "    words_df['google_rank'] = np.nan\n",
      "    words_df['google_rank'][words_df.in_sentiment == True] = words_df.words[words_df.in_sentiment == True].apply(lambda x: \n",
      "        float(sentiment_df.google_rank[sentiment_df.word == x].values))\n",
      "    google_rank = round(np.mean(words_df.google_rank[~words_df.google_rank.isnull()].values), 3)\n",
      "    return float(google_rank)\n",
      "\n",
      "def twitter_rank(text):  \n",
      "    words_df = pd.DataFrame(text.split(' '), columns=['words'])\n",
      "    words_df['words'] = words_df.words.apply(lambda x: str.lower(re.sub(\"\\W\", '', x)))\n",
      "    words_df['word_length'] = words_df.words.apply(lambda x: len(x))\n",
      "    words_df = words_df[words_df.word_length > 0]\n",
      "    words_df['in_sentiment'] = False\n",
      "    words_df['in_sentiment'][words_df.words.isin(sentiment_df_NS.word)] = True\n",
      "    words_df['twitter_rank'] = np.nan\n",
      "    words_df['twitter_rank'][words_df.in_sentiment == True] = words_df.words[words_df.in_sentiment == True].apply(lambda x: \n",
      "        float(sentiment_df.twitter_rank[sentiment_df.word == x].values))\n",
      "    twitter_rank = round(np.mean(words_df.twitter_rank[~words_df.twitter_rank.isnull()].values), 3)\n",
      "    return float(twitter_rank)\n",
      "\n",
      "def nyt_rank(text):   \n",
      "    words_df = pd.DataFrame(text.split(' '), columns=['words'])\n",
      "    words_df['words'] = words_df.words.apply(lambda x: str.lower(re.sub(\"\\W\", '', x)))\n",
      "    words_df['word_length'] = words_df.words.apply(lambda x: len(x))\n",
      "    words_df = words_df[words_df.word_length > 0]\n",
      "    words_df['in_sentiment'] = False\n",
      "    words_df['in_sentiment'][words_df.words.isin(sentiment_df_NS.word)] = True\n",
      "    words_df['nyt_rank'] = np.nan\n",
      "    words_df['nyt_rank'][words_df.in_sentiment == True] = words_df.words[words_df.in_sentiment == True].apply(lambda x: \n",
      "        float(sentiment_df.nyt_rank[sentiment_df.word == x].values))\n",
      "    nyt_rank = round(np.mean(words_df.nyt_rank[~words_df.nyt_rank.isnull()].values), 3)\n",
      "    return float(nyt_rank)\n",
      "\n",
      "def lyrics_rank(text):   \n",
      "    words_df = pd.DataFrame(text.split(' '), columns=['words'])\n",
      "    words_df['words'] = words_df.words.apply(lambda x: str.lower(re.sub(\"\\W\", '', x)))\n",
      "    words_df['word_length'] = words_df.words.apply(lambda x: len(x))\n",
      "    words_df = words_df[words_df.word_length > 0]\n",
      "    words_df['in_sentiment'] = False\n",
      "    words_df['in_sentiment'][words_df.words.isin(sentiment_df_NS.word)] = True\n",
      "    words_df['lyrics_rank'] = np.nan\n",
      "    words_df['lyrics_rank'][words_df.in_sentiment == True] = words_df.words[words_df.in_sentiment == True].apply(lambda x: \n",
      "        float(sentiment_df.lyrics_rank[sentiment_df.word == x].values))\n",
      "    lyrics_rank = round(np.mean(words_df.lyrics_rank[~words_df.lyrics_rank.isnull()].values), 3)\n",
      "    return float(lyrics_rank)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 164
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "functions = [post_length, avg_word_length, avg_senti_score, avg_senti_score2, dyn_senti_score, google_rank, twitter_rank, nyt_rank, lyrics_rank]\n",
      "\n",
      "rottentomatoes_prep_df = make_prep_df(rottentomatoes_clean_df[:50], 'quote', functions)\n",
      "\n",
      "#rottentomatoes_prep_df.sort(['dyn_senti_score', 'avg_senti_score2'], ascending=True)[['avg_senti_score','dyn_senti_score', 'avg_senti_score2']]\n",
      "\n",
      "rottentomatoes_prep_df.head()\n",
      "\n",
      "print 'calculating variance of various sentiment calculations'\n",
      "print 'no stopwords', np.std(rottentomatoes_prep_df.avg_senti_score)\n",
      "print 'stop words', np.std(rottentomatoes_prep_df.dyn_senti_score)\n",
      "print 'stopwords, avg', np.std(rottentomatoes_prep_df.avg_senti_score2)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " calculating variance of various sentiment calculations\n",
        "no stopwords 0.30369176325\n",
        "stop words 0.58214172291\n",
        "stopwords, avg 0.567148211067\n"
       ]
      }
     ],
     "prompt_number": 166
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######<a href=\"#prep_function\">Stanford</a> - <a href=\"#prep_function\">RottenTomatoes</a> - <a href=\"#prep_function\">NewYorkTimes</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Prepare Function <a name=\"prep_function\"></a>\n",
      "\n",
      "This function will add the desired feature columns to any dataframe that has a column of texts."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \"text_col\" parameter is the column name (string) where the text is\n",
      "# features parameter is a list of functions to implement on the dataframe\n",
      "def make_prep_df(df, text_col, features):\n",
      "    \n",
      "    # making copy of dataframe\n",
      "    df_copy = df.copy()\n",
      "    \n",
      "    # renaming text column to make it easy to deal with\n",
      "    df_copy = df_copy.rename(columns={text_col: 'text_col'})\n",
      "    \n",
      "    # deleting rows where there are no words in the text column\n",
      "    df_copy = df_copy[~df_copy.text_col.isnull()].reset_index(drop=True)\n",
      "    \n",
      "    #map(features, lambda x: df_copy[x.__name__] = np.nan)\n",
      "    #map(features, lambda y: df_copy[y.__name__] = df_copy.text_col.apply(lambda x: y(x)))\n",
      "    \n",
      "    for func in features:\n",
      "        # making a column that has the same name as the function\n",
      "        df_copy[func.__name__] = np.nan\n",
      "        df_copy[func.__name__] = df_copy.text_col.apply(lambda x: func(x))\n",
      "        df_copy = df_copy[~df_copy[func.__name__].isnull()].reset_index(drop=True)\n",
      "        \n",
      "    # deleting rows where there is no average sentiment score\n",
      "    #df_copy = df_copy[~df_copy.avg_senti_score.isnull()]\n",
      "    #df_copy = df_copy.sort('avg_senti_score', ascending=False).reset_index(drop=True)\n",
      "    \n",
      "    # changing text column back to its original name\n",
      "    df_copy = df_copy.rename(columns={'text_col': text_col})\n",
      "    \n",
      "    # returns prepared dataframe\n",
      "    return df_copy\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######<a href=\"#sf_csv_prep_data\">Stanford</a> - <a href=\"#rt_csv_prep_data\">RottenTomatoes</a> - <a href=\"#nyt_csv_prep_data\">NewYorkTimes</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 4.1 Stanford MovieDB (stanford_prep_df)\n",
      "Add feature columns for Stanford MovieDB:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "functions = [post_length, avg_word_length, avg_senti_score]\n",
      "\n",
      "stanford_prep_df = make_prep_df(stanford_clean_df, 'review', functions)\n",
      "stanford_prep_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'stanford_clean_df' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-50-7f177b109cf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfunctions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpost_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_word_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_senti_score\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstanford_prep_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_prep_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstanford_clean_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'review'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mstanford_prep_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'stanford_clean_df' is not defined"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save dataframe to file:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stanford_prep_df.to_csv('stanford_prep_df.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'stanford_prep_df' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-51-ccc9ccd476d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstanford_prep_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stanford_prep_df.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'stanford_prep_df' is not defined"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load dataframe from CSV: <a name=\"sf_csv_prep_data\"></a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stanford_prep_df = pd.read_csv('stanford_prep_df.csv')\n",
      "stanford_prep_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IOError",
       "evalue": "File stanford_prep_df.csv does not exist",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-52-605c54378e4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstanford_prep_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stanford_prep_df.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstanford_prep_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/python.app/Contents/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, nrows, iterator, chunksize, verbose, encoding, squeeze)\u001b[0m\n\u001b[1;32m    399\u001b[0m                     buffer_lines=buffer_lines)\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/python.app/Contents/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/python.app/Contents/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/python.app/Contents/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/python.app/Contents/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0;31m# #2442\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/python.app/Contents/lib/python2.7/site-packages/pandas/_parser.so\u001b[0m in \u001b[0;36mpandas._parser.TextReader.__cinit__ (pandas/src/parser.c:2771)\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;32m//anaconda/python.app/Contents/lib/python2.7/site-packages/pandas/_parser.so\u001b[0m in \u001b[0;36mpandas._parser.TextReader._setup_parser_source (pandas/src/parser.c:4803)\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;31mIOError\u001b[0m: File stanford_prep_df.csv does not exist"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######<a href=\"#train_data\">Stanford</a> - (<a href=\"rt_csv_prep_data\">RottenTomatoes</a> - <a href=\"#nyt_csv_prep_data\">NewYorkTimes</a>)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some Statistics: <a name=\"sf_stat_prep_data\"></a> \n",
      "<br>Compare with: <a href=\"#sf_stat_get_data\">Plain</a>, <a href=\"#sf_stat_clean_data\">Clean</a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'length of set:', len(stanford_prep_df)\n",
      "print 'average postlength:', int(np.mean(stanford_prep_df.review.apply(lambda x: len(x))))\n",
      "print 'number of positive reviews:', len(stanford_prep_df[stanford_prep_df.rating >= 7])\n",
      "print 'number of negative reviews:', len(stanford_prep_df[stanford_prep_df.rating <= 4])\n",
      "print 'max postlength', stanford_prep_df.review.apply(lambda x: len(x)).max()\n",
      "print 'min postlength', stanford_prep_df.review.apply(lambda x: len(x)).min()\n",
      "                            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of set: 25000\n",
        "average postlength: 1325\n",
        "number of positive reviews: 12500\n",
        "number of negative reviews: 12500\n",
        "max postlength 13704\n",
        "min postlength "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "52\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 4.2 RottenTomatoes (rottentomatoes_prep_df)\n",
      "Add feature columns:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rottentomatoes_clean_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>critic</th>\n",
        "      <th>fresh</th>\n",
        "      <th>imdb</th>\n",
        "      <th>publication</th>\n",
        "      <th>quote</th>\n",
        "      <th>review_date</th>\n",
        "      <th>rtid</th>\n",
        "      <th>title</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>        Derek Adams</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>       Time Out</td>\n",
        "      <td> So ingenious in concept, design and execution ...</td>\n",
        "      <td> 2009-10-04</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>    Richard Corliss</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>  TIME Magazine</td>\n",
        "      <td>                 The year's most inventive comedy.</td>\n",
        "      <td> 2008-08-31</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>        David Ansen</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>       Newsweek</td>\n",
        "      <td> A winning animated feature that has something ...</td>\n",
        "      <td> 2008-08-18</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>      Leonard Klady</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>        Variety</td>\n",
        "      <td> The film sports a provocative and appealing st...</td>\n",
        "      <td> 2008-06-09</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> Jonathan Rosenbaum</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td> Chicago Reader</td>\n",
        "      <td> An entertaining computer-generated, hyperreali...</td>\n",
        "      <td> 2008-03-10</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 65,
       "text": [
        "               critic  fresh    imdb     publication                                              quote review_date  rtid      title\n",
        "0         Derek Adams  fresh  114709        Time Out  So ingenious in concept, design and execution ...  2009-10-04  9559  Toy story\n",
        "1     Richard Corliss  fresh  114709   TIME Magazine                  The year's most inventive comedy.  2008-08-31  9559  Toy story\n",
        "2         David Ansen  fresh  114709        Newsweek  A winning animated feature that has something ...  2008-08-18  9559  Toy story\n",
        "3       Leonard Klady  fresh  114709         Variety  The film sports a provocative and appealing st...  2008-06-09  9559  Toy story\n",
        "4  Jonathan Rosenbaum  fresh  114709  Chicago Reader  An entertaining computer-generated, hyperreali...  2008-03-10  9559  Toy story"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "functions = [post_length, avg_word_length, avg_senti_score]\n",
      "\n",
      "rottentomatoes_prep_df = make_prep_df(rottentomatoes_clean_df, 'quote', functions)\n",
      "rottentomatoes_prep_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>critic</th>\n",
        "      <th>fresh</th>\n",
        "      <th>imdb</th>\n",
        "      <th>publication</th>\n",
        "      <th>quote</th>\n",
        "      <th>review_date</th>\n",
        "      <th>rtid</th>\n",
        "      <th>title</th>\n",
        "      <th>post_length</th>\n",
        "      <th>avg_word_length</th>\n",
        "      <th>avg_senti_score</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>        Derek Adams</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>       Time Out</td>\n",
        "      <td> So ingenious in concept, design and execution ...</td>\n",
        "      <td> 2009-10-04</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td> 24</td>\n",
        "      <td> 4.63</td>\n",
        "      <td> 5.385</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>    Richard Corliss</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>  TIME Magazine</td>\n",
        "      <td>                 The year's most inventive comedy.</td>\n",
        "      <td> 2008-08-31</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td>  5</td>\n",
        "      <td> 5.40</td>\n",
        "      <td> 6.115</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>        David Ansen</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>       Newsweek</td>\n",
        "      <td> A winning animated feature that has something ...</td>\n",
        "      <td> 2008-08-18</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td> 13</td>\n",
        "      <td> 5.08</td>\n",
        "      <td> 5.572</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>      Leonard Klady</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>        Variety</td>\n",
        "      <td> The film sports a provocative and appealing st...</td>\n",
        "      <td> 2008-06-09</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td> 17</td>\n",
        "      <td> 5.24</td>\n",
        "      <td> 5.588</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> Jonathan Rosenbaum</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td> Chicago Reader</td>\n",
        "      <td> An entertaining computer-generated, hyperreali...</td>\n",
        "      <td> 2008-03-10</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td> 14</td>\n",
        "      <td> 6.50</td>\n",
        "      <td> 5.744</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 53,
       "text": [
        "               critic  fresh    imdb     publication                                              quote review_date  rtid      title  post_length  avg_word_length  avg_senti_score\n",
        "0         Derek Adams  fresh  114709        Time Out  So ingenious in concept, design and execution ...  2009-10-04  9559  Toy story           24             4.63            5.385\n",
        "1     Richard Corliss  fresh  114709   TIME Magazine                  The year's most inventive comedy.  2008-08-31  9559  Toy story            5             5.40            6.115\n",
        "2         David Ansen  fresh  114709        Newsweek  A winning animated feature that has something ...  2008-08-18  9559  Toy story           13             5.08            5.572\n",
        "3       Leonard Klady  fresh  114709         Variety  The film sports a provocative and appealing st...  2008-06-09  9559  Toy story           17             5.24            5.588\n",
        "4  Jonathan Rosenbaum  fresh  114709  Chicago Reader  An entertaining computer-generated, hyperreali...  2008-03-10  9559  Toy story           14             6.50            5.744"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save dataframe to file:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rottentomatoes_prep_df.to_csv('rottentomatoes_prep_df.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load dataframe from CSV: <a name=\"rt_csv_prep_data\"></a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rottentomatoes_prep_df = pd.read_csv('rottentomatoes_prep_df.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######(<a href=\"#sf_csv_prep_data\">Stanford</a>) - <a href=\"#train_data\">RottenTomatoes</a> - (<a href=\"#nyt_csv_prep_data\">NewYorkTimes</a>)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some Statistics: <a name=\"rt_stat_prep_data\"></a> \n",
      "<br>Compare with: <a href=\"#rt_stat_get_data\">Plain</a>, <a href=\"#rt_stat_clean_data\">Clean</a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'length of set:', len(rottentomatoes_prep_df)\n",
      "print 'average postlength:', int(np.mean(rottentomatoes_prep_df.lead.apply(lambda x: len(x))))\n",
      "print 'number of positive reviews:', len(rottentomatoes_prep_df[rottentomatoes_prep_df.fresh == 'fresh'])\n",
      "print 'number of negative reviews:', len(rottentomatoes_prep_df[rottentomatoes_prep_df.fresh == 'rotten'])\n",
      "print 'max postlength', rottentomatoes_prep_df.lead.apply(lambda x: len(x)).max()\n",
      "print 'min postlength', rottentomatoes_prep_df.lead.apply(lambda x: len(x)).min()\n",
      "                            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of set: 134\n",
        "average postlength: 314\n",
        "number of positive reviews: currently unknown\n",
        "number of negative reviews: currently unknown\n",
        "max postlength 1280\n",
        "min postlength 35\n"
       ]
      }
     ],
     "prompt_number": 261
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 4.3 New York Times DB (nytimes_prep_df)\n",
      "Add feature columns:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "functions = [post_length, avg_word_length, avg_senti_score]\n",
      "\n",
      "nytimes_prep_df = make_prep_df(nytimes_clean_df, 'lead', functions)\n",
      "nytimes_prep_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save dataframe to file:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nytimes_prep_df.to_csv('nytimes_prep_df.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load dataframe from CSV: <a name=\"nyt_csv_prep_data\"></a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nytimes_prep_df = pd.read_csv('nytimes_prep_df.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######(<a href=\"#sf_csv_prep_data\">Stanford</a> - <a href=\"#train_data\">RottenTomatoes</a>) - <a href=\"#nyt_csv_prep_data\">NewYorkTimes</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some Statistics: <a name=\"nyt_stat_prep_data\"></a> \n",
      "<br>Compare with: <a href=\"#nyt_stat_get_data\">Plain</a>, <a href=\"#nyt_stat_clean_data\">Clean</a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'length of set:', len(rottentomatoes_prep_df)\n",
      "print 'average postlength:', int(np.mean(rottentomatoes_prep_df.lead.apply(lambda x: len(x))))\n",
      "print 'number of positive reviews:', 'currently unknown'\n",
      "print 'number of negative reviews:', 'currently unknown'\n",
      "print 'max postlength', rottentomatoes_prep_df.lead.apply(lambda x: len(x)).max()\n",
      "print 'min postlength', rottentomatoes_prep_df.lead.apply(lambda x: len(x)).min()\n",
      "                            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of set: 134\n",
        "average postlength: 314\n",
        "number of positive reviews: currently unknown\n",
        "number of negative reviews: currently unknown\n",
        "max postlength 1280\n",
        "min postlength 35\n"
       ]
      }
     ],
     "prompt_number": 261
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 5. Train Model <a name=\"train_data\"></a> \n",
      "\n",
      "Train different models with different data sources.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Make XY Function\n",
      "\n",
      "This function takes in the prepared dataframe source and outputs X (an array of features) and Y (an array of known scores)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# defining the make_xy() function\n",
      "# \"rating_col\" parameter is the name of the column where the ratings are;\n",
      "# can be continuous or binary values\n",
      "# features parameter is a list of the feature functions\n",
      "def make_xy(prep_data, rating_col, features):\n",
      "    \n",
      "    # using copy of dataframe just in case\n",
      "    prep_copy = prep_data.copy()\n",
      "    \n",
      "    # converting relevant columns to floats\n",
      "    \n",
      "    #map(features, lambda y:  prep_copy[y.__name__] = prep_copy[y.__name__].apply(lambda x: float(x)))\n",
      "    \n",
      "    for func in features:\n",
      "        prep_copy[func.__name__] = prep_copy[func.__name__].apply(lambda x: float(x))\n",
      "    \n",
      "    feature_array = []\n",
      "    for i in xrange(len(prep_copy)):\n",
      "        feature_list = [float(prep_copy[func.__name__][prep_copy.index == i].values[0]) for func in features]\n",
      "        #print feature_list, i\n",
      "        feature_array.append(feature_list)\n",
      "    \n",
      "    #map(features, lambda x: df_copy[x.__name__] = np.nan)\n",
      "    #map(features, lambda y: df_copy[y.__name__] = df_copy.text_col.apply(lambda x: y(x)))\n",
      "    \n",
      "    # making 2D array of features\n",
      "    x = np.array(feature_array)\n",
      "    \n",
      "    # renaming the column that contains the ratings\n",
      "    prep_copy = prep_copy.rename(columns={rating_col: 'rating_col'})\n",
      "    \n",
      "    # making numpy array of the naive happy values we made up\n",
      "    y = np.array(prep_copy.rating_col.values)\n",
      "    \n",
      "    # returning x and y in a tuple\n",
      "    return x, y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 5.1 Train Model - Low Level Features to Predict Sentimentscore - Stanford Moviedatabase \n",
      "\n",
      "This function takes in the prepared dataframe source and outputs X (an array of features) and Y (an array of known scores)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_cols = [post_length, avg_word_length, avg_senti_score]\n",
      "stanford_test_df = make_stanford_df('test')\n",
      "stanford_test_prep_df = make_prep_df(stanford_test_df.head(10), 'review', features_cols)\n",
      "\n",
      "\n",
      "stanford_prep_df = stanford_prep_df.rename(columns = {'word_count' : 'post_length'})\n",
      "\n",
      "features_train = [post_length, avg_word_length]\n",
      "Xtrain,Ytrain = make_xy(stanford_prep_df, 'rating', features_train)\n",
      "\n",
      "features_train = [post_length, avg_word_length]\n",
      "Xtest,Ytest = make_xy(stanford_test_prep_df, 'rating', features_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# making object from MultinomialNB class\n",
      "#clf = MultinomialNB()\n",
      "clf = GaussianNB()\n",
      "\n",
      "# printing fit and score\n",
      "clf.fit(Xtrain, Ytrain)\n",
      "print round(clf.score(Xtrain, Ytrain), 4)\n",
      "print round(clf.score(Xtest, Ytest), 4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "Can't handle mix of unknown and binary",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-34-47b4b0a7fe82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\base.pyc\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    292\u001b[0m         \"\"\"\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\metrics.pyc\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize)\u001b[0m\n\u001b[0;32m   1062\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1064\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_clf_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1065\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'multilabel-indicator'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\metrics.pyc\u001b[0m in \u001b[0;36m_check_clf_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         raise ValueError(\"Can't handle mix of {0} and {1}\"\n\u001b[1;32m--> 115\u001b[1;33m                          \"\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: Can't handle mix of unknown and binary"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.2141\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rottentomatoes_prep_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>critic</th>\n",
        "      <th>fresh</th>\n",
        "      <th>imdb</th>\n",
        "      <th>publication</th>\n",
        "      <th>quote</th>\n",
        "      <th>review_date</th>\n",
        "      <th>rtid</th>\n",
        "      <th>title</th>\n",
        "      <th>post_length</th>\n",
        "      <th>avg_word_length</th>\n",
        "      <th>avg_senti_score</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>        Derek Adams</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>       Time Out</td>\n",
        "      <td> So ingenious in concept, design and execution ...</td>\n",
        "      <td> 2009-10-04</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td> 24</td>\n",
        "      <td> 4.63</td>\n",
        "      <td> 5.385</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>    Richard Corliss</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>  TIME Magazine</td>\n",
        "      <td>                 The year's most inventive comedy.</td>\n",
        "      <td> 2008-08-31</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td>  5</td>\n",
        "      <td> 5.40</td>\n",
        "      <td> 6.115</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>        David Ansen</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>       Newsweek</td>\n",
        "      <td> A winning animated feature that has something ...</td>\n",
        "      <td> 2008-08-18</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td> 13</td>\n",
        "      <td> 5.08</td>\n",
        "      <td> 5.572</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>      Leonard Klady</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>        Variety</td>\n",
        "      <td> The film sports a provocative and appealing st...</td>\n",
        "      <td> 2008-06-09</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td> 17</td>\n",
        "      <td> 5.24</td>\n",
        "      <td> 5.588</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> Jonathan Rosenbaum</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td> Chicago Reader</td>\n",
        "      <td> An entertaining computer-generated, hyperreali...</td>\n",
        "      <td> 2008-03-10</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td> 14</td>\n",
        "      <td> 6.50</td>\n",
        "      <td> 5.744</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "               critic  fresh    imdb     publication                                              quote review_date  rtid      title  post_length  avg_word_length  avg_senti_score\n",
        "0         Derek Adams  fresh  114709        Time Out  So ingenious in concept, design and execution ...  2009-10-04  9559  Toy story           24             4.63            5.385\n",
        "1     Richard Corliss  fresh  114709   TIME Magazine                  The year's most inventive comedy.  2008-08-31  9559  Toy story            5             5.40            6.115\n",
        "2         David Ansen  fresh  114709        Newsweek  A winning animated feature that has something ...  2008-08-18  9559  Toy story           13             5.08            5.572\n",
        "3       Leonard Klady  fresh  114709         Variety  The film sports a provocative and appealing st...  2008-06-09  9559  Toy story           17             5.24            5.588\n",
        "4  Jonathan Rosenbaum  fresh  114709  Chicago Reader  An entertaining computer-generated, hyperreali...  2008-03-10  9559  Toy story           14             6.50            5.744"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rottentomatoes_prep_df[~rottentomatoes_prep_df['avg_senti_score'].isnull()].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>critic</th>\n",
        "      <th>fresh</th>\n",
        "      <th>imdb</th>\n",
        "      <th>publication</th>\n",
        "      <th>quote</th>\n",
        "      <th>review_date</th>\n",
        "      <th>rtid</th>\n",
        "      <th>title</th>\n",
        "      <th>post_length</th>\n",
        "      <th>avg_word_length</th>\n",
        "      <th>avg_senti_score</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>        Derek Adams</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>       Time Out</td>\n",
        "      <td> So ingenious in concept, design and execution ...</td>\n",
        "      <td> 2009-10-04</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td> 24</td>\n",
        "      <td> 4.63</td>\n",
        "      <td> 5.385</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>    Richard Corliss</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>  TIME Magazine</td>\n",
        "      <td>                 The year's most inventive comedy.</td>\n",
        "      <td> 2008-08-31</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td>  5</td>\n",
        "      <td> 5.40</td>\n",
        "      <td> 6.115</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>        David Ansen</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>       Newsweek</td>\n",
        "      <td> A winning animated feature that has something ...</td>\n",
        "      <td> 2008-08-18</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td> 13</td>\n",
        "      <td> 5.08</td>\n",
        "      <td> 5.572</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>      Leonard Klady</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>        Variety</td>\n",
        "      <td> The film sports a provocative and appealing st...</td>\n",
        "      <td> 2008-06-09</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td> 17</td>\n",
        "      <td> 5.24</td>\n",
        "      <td> 5.588</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> Jonathan Rosenbaum</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td> Chicago Reader</td>\n",
        "      <td> An entertaining computer-generated, hyperreali...</td>\n",
        "      <td> 2008-03-10</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td> 14</td>\n",
        "      <td> 6.50</td>\n",
        "      <td> 5.744</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "               critic  fresh    imdb     publication                                              quote review_date  rtid      title  post_length  avg_word_length  avg_senti_score\n",
        "0         Derek Adams  fresh  114709        Time Out  So ingenious in concept, design and execution ...  2009-10-04  9559  Toy story           24             4.63            5.385\n",
        "1     Richard Corliss  fresh  114709   TIME Magazine                  The year's most inventive comedy.  2008-08-31  9559  Toy story            5             5.40            6.115\n",
        "2         David Ansen  fresh  114709        Newsweek  A winning animated feature that has something ...  2008-08-18  9559  Toy story           13             5.08            5.572\n",
        "3       Leonard Klady  fresh  114709         Variety  The film sports a provocative and appealing st...  2008-06-09  9559  Toy story           17             5.24            5.588\n",
        "4  Jonathan Rosenbaum  fresh  114709  Chicago Reader  An entertaining computer-generated, hyperreali...  2008-03-10  9559  Toy story           14             6.50            5.744"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Your code here\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "\n",
      "features_train = [post_length, avg_word_length]\n",
      "\n",
      "\n",
      "rottentomatoes_prep_df = rottentomatoes_prep_df[~rottentomatoes_prep_df['avg_senti_score'].isnull()]\n",
      "\n",
      "\n",
      "X,Y = make_xy(rottentomatoes_prep_df, 'avg_senti_score', features_train)\n",
      "\n",
      "#get train_test_split tupel with validation and training data\n",
      "xtrain, xtest, ytrain, ytest = train_test_split(X,Y)\n",
      "\n",
      "#create multinomial classifier\n",
      "clf = MultinomialNB()\n",
      "#calculate fit with training data\n",
      "print clf.fit(xtrain, ytrain)\n",
      "\n",
      "#output valdiation accuracy\n",
      "print clf.score(xtest, ytest)\n",
      "\n",
      "print rottentomatoes_prep_df.avg_senti_score.values[:20]\n",
      "\n",
      "print round(clf.score(xtrain, ytrain),4)\n",
      "print round(clf.score(xtest, ytest),4)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
        "0.00776196636481"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 5.385  6.115  5.572  5.588  5.744  5.723  5.866  5.963  5.659  5.699\n",
        "  5.57   5.821  5.883  5.497  5.404  5.94   5.681  5.919  5.872  4.74 ]\n",
        "0.008"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.0078"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 6. Predict from Data\n",
      "\n",
      "Predict outcome of given data source.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 7. Prediction Visualization\n",
      "\n",
      "Prepare datasources with neccessary extension including required featurelist. Result will be stored in local CSV files.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "*css tweaks in this cell*\n",
      "<style>\n",
      "div.text_cell_render {\n",
      "    line-height: 150%;\n",
      "    font-size: 110%;\n",
      "    width: 800px;\n",
      "    margin-left:50px;\n",
      "    margin-right:auto;\n",
      "    }\n",
      "</style>"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}