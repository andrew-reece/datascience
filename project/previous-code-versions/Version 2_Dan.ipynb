{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "\n",
      "QUESTIONS \n",
      "\u2022\u00a0Is it possible to get better ways to track sentiment? \n",
      "    \u2022better ways to do sentiment- more emotions? (e.g., Alice Oh's work)\n",
      "    \u2022 polarized sentiment \n",
      "    \u2022 right now, simply averaging comments might reflect regression toward the mean...\n",
      "\u2022 How to use the naive bayes classifier? \n",
      "\n",
      "CODE FIXES\n",
      "\u2022\u00a0faster code for getting average word length and sentiment (e.g., using apply on dataframes?)\n",
      "\u2022\u00a0offsets and page numbers for comments \n",
      "\n",
      "TO DO\n",
      "\u2022 create a classifier for predicting post sentiment and comment sentiment\n",
      "\u2022\u00a0better ways to look at sentiment? do some research\n",
      "\u2022\u00a0topic modeling of posts and comments \n",
      "\u2022\u00a0ways to analyze how certain words are being used and how these patterns change across time (e.g., nature of racial discourse among politicians)\n",
      "\u2022 using map reduce to speed up analysis for larger sample size?\n",
      "\u2022 incorporate analysis of mentioned people, organizations, locations? \n",
      "\n",
      "\n",
      "LOOK INTO\n",
      "\u2022\u00a0NLTK tutorials: http://andybromberg.com/sentiment-analysis-python/\n",
      "\u2022 Neal Caren's sentence subject analysis\n",
      "\u2022 sentiment analysis: http://www.stanford.edu/class/cs224u/slides/cs224u-slides-02-26.pdf\n",
      "\n",
      "\n",
      "IDEAS/BRAINSTORMS\n",
      "\u2022\u00a0Creating a tool where people can examine how certain frames and ideas are received in the public \n",
      "(as measured by comments and sentiment)\n",
      "\u2022\u00a0Training machine learning algorithms based on certain professions (e.g., bankers, doctors, lawyers, professors)\n",
      "and see how these algorithms have variations in response (way to formalize institutional logics?) \n",
      "\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Not sure what we'll need exactly, so just importing all the usual suspects here\n",
      "\n",
      "import json\n",
      "import requests\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import re\n",
      "import unicodedata\n",
      "import scipy.stats as stats\n",
      "import urllib #helps you encode urls to use in NYTs community API\n",
      "from collections import defaultdict \n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "\n",
      "def myprint(obj):  \n",
      "    if hasattr(obj, '__len__') and len(obj) > 100:  \n",
      "        print '... omitted object of %s with length %d ...' % (type(obj), len(obj))  \n",
      "    else: print obj\n",
      "\n",
      "pd.set_option('display.width', 500)\n",
      "pd.set_option('display.max_columns', 30)\n",
      "\n",
      "# set some nicer defaults for matplotlib\n",
      "from matplotlib import rcParams\n",
      "\n",
      "#these colors come from colorbrewer2.org. Each is an RGB triplet\n",
      "dark2_colors = [(0.10588235294117647, 0.6196078431372549, 0.4666666666666667),\n",
      "                (0.8509803921568627, 0.37254901960784315, 0.00784313725490196),\n",
      "                (0.4588235294117647, 0.4392156862745098, 0.7019607843137254),\n",
      "                (0.9058823529411765, 0.1607843137254902, 0.5411764705882353),\n",
      "                (0.4, 0.6509803921568628, 0.11764705882352941),\n",
      "                (0.9019607843137255, 0.6705882352941176, 0.00784313725490196),\n",
      "                (0.6509803921568628, 0.4627450980392157, 0.11372549019607843),\n",
      "                (0.4, 0.4, 0.4)]\n",
      "\n",
      "rcParams['figure.figsize'] = (10, 6)\n",
      "rcParams['figure.dpi'] = 150\n",
      "rcParams['axes.color_cycle'] = dark2_colors\n",
      "rcParams['lines.linewidth'] = 2\n",
      "rcParams['axes.grid'] = False\n",
      "rcParams['axes.facecolor'] = 'white'\n",
      "rcParams['font.size'] = 14\n",
      "rcParams['patch.edgecolor'] = 'none'\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "##THIRD VERSION WITH FACETS - WORKING 11:31 PM##\n",
      "\n",
      "## NYT API keys\n",
      "api_key_article = \"851e7d0a131bee9bc01097470c238637:13:47475506\"\n",
      "api_key_community = \"519167db119ee6408c4ee51b3c391e11:0:47475506\"\n",
      "api_key_geo = \"a984ad78bf017f0ade1fcd980aa6353f:15:47475506\"\n",
      "api_key_popular = \"09dfaf288ad6c2ec46893a27ca758d41:19:47475506\"\n",
      "api_key_movies = \"e8a48f7d7731698b05267146c681c352:5:47475506\"\n",
      "api_key_semantic = \"9063b41607bbf486247b8e596a1456b8:7:47475506\"\n",
      "api_key_newswire = \"209ebb7b0ab44094970e8b39c63fea7e:2:47475506\"\n",
      "api_key_timestags = \"43b3366f288db10cb019fd532299723f:10:47475506\"\n",
      "\n",
      "## data gets tuples of (whole api return, lead paragraphs)\n",
      "data = []\n",
      "\n",
      "## just picked a few terms meant to have a fair spread in content\n",
      "terms = ['start-up']\n",
      "begindate = 20000101 #YYYMMDD\n",
      "enddate = 20131112\n",
      "#page = 10\n",
      "offset = range(3) #page numbers\n",
      "fields = 'org_facet%2C+per_facet%2C+body%2c+geo_facet'\n",
      "print \"&fields=%s\" %fields\n",
      "\n",
      "## loop through terms\n",
      "allentries = []\n",
      "for page in offset:\n",
      "    for term in terms:\n",
      "        \n",
      "        ## api request for each term\n",
      "        url = ''.join([\"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=\",term,\n",
      "                       \"&begin_date=%d\" %begindate,\n",
      "                       \"&end_date=%d\" %enddate,\n",
      "                       \"&page=%d\" %page,\n",
      "                       \"&fields=%s\" %fields,\n",
      "                       #\"&offset=%d\" %page,\n",
      "                       \"&api-key=\",api_key_article])\n",
      "        req = requests.get(url).text\n",
      "        \n",
      "        ## decode into json dicts\n",
      "        jsons = json.loads(req)\n",
      "        #print jsons\n",
      "\n",
      "        allkeys = []\n",
      "        for results in jsons['response']['docs']:\n",
      "    \n",
      "            ##Get Abstract\n",
      "            abstract = 'abstract', results['abstract']\n",
      "            #print abstract\n",
      "            #print '\\n', results['abstract']\n",
      "            \n",
      "            ##Get word count\n",
      "            word_count = 'post length', float(results['word_count'])\n",
      "            #print word_count\n",
      "            #print '\\n', jsons['response']['docs'][0]['word_count']\n",
      "                                              \n",
      "            ##Get Web Url\n",
      "            web_url = 'web_url', results['web_url']\n",
      "            #print '\\n', jsons['response']['docs'][0]['web_url']\n",
      "            \n",
      "            source = 'source', results['source']\n",
      "            \n",
      "            document_type = 'document type', results['document_type']\n",
      "            \n",
      "            #get Print_page\n",
      "            print_page = 'print_page', results['print_page']\n",
      "            #print '\\n', jsons['response']['docs'][0]['print_page']\n",
      "            \n",
      "            #get pub_date\n",
      "            pub_date = 'pub_date', results['pub_date'].encode('utf-8')\n",
      "            #print '\\n', jsons['response']['docs'][0]['pub_date'].encode('utf-8')\n",
      "            \n",
      "            ## sometimes we have weird ASCII encodings with text, so we decode to utf-8\n",
      "            #print results['lead_paragraph']\n",
      "            \n",
      "            if results['lead_paragraph'] == None:\n",
      "                #print 'None'\n",
      "                lead_paragraph = 'lead_paragraph', 'None'\n",
      "                \n",
      "            elif results['lead_paragraph'] != None:           \n",
      "                lead_paragraph = 'lead_paragraph', results['lead_paragraph']\n",
      "            \n",
      "            namelist = []\n",
      "            #get authors #there can be multiple authors, so use for loop\n",
      "            #print results\n",
      "            keys=[\"keywords\",]\n",
      "            for key in results['keywords']:\n",
      "                    if key['name'] == 'persons':\n",
      "                        keys.append(key)\n",
      "                    if key['name'] == 'organizations': \n",
      "                        keys.append(key)\n",
      "                    if key['name'] == 'glocations':\n",
      "                        keys.append(key)\n",
      "            #print keys\n",
      "            \"\"\"\n",
      "            attempt to create more robust author find, not working...\n",
      "            print '\\n',results['byline']['person']\n",
      "            if results['byline'] == None:\n",
      "                if results['byline']['person'] == None:\n",
      "                    if results['byline']['organization'] == None:\n",
      "                        namelist.append('None')\n",
      "                    else:\n",
      "                        namelist.append(results['byline']['organization'])\n",
      "                else:\n",
      "                    for person in results['byline']['person']:\n",
      "                        first= person['firstname']\n",
      "                        last = person['lastname']\n",
      "                        name = last, first\n",
      "                        namelist.append(name)\n",
      "            else:\n",
      "                for person in results['byline']['person']:\n",
      "                        first= person['firstname']\n",
      "                        last = person['lastname']\n",
      "                        name = last, first\n",
      "                        namelist.append(name)\n",
      "            \"\"\"\n",
      "                    \n",
      "                        \n",
      "                    \n",
      "            try:\n",
      "                for person in results['byline']['person']:\n",
      "                    try: \n",
      "                        first= person['firstname']\n",
      "                        last = person['lastname']\n",
      "                        name = last, first\n",
      "                        namelist.append(name)\n",
      "                    except: \n",
      "                        namelist.append('None')\n",
      "\n",
      "            except:\n",
      "                try:\n",
      "                    namelist.append(results['byline']['organization'])\n",
      "                except:\n",
      "                    namelist.append('None')\n",
      "        \n",
      "            \n",
      "            author = 'author', namelist \n",
      "                #try:\n",
      "                #   parsedict['author'].append(name)\n",
      "                #except:\n",
      "                #    parsedict['author'] = name \n",
      "\n",
      "            allkeys = lead_paragraph, web_url, author, abstract, print_page, word_count, pub_date, keys, term, source, document_type\n",
      "            \n",
      "            allentries.append(allkeys)\n",
      "        \n",
      "look = 'factory called AlleyCorp'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "&fields=org_facet%2C+per_facet%2C+body%2c+geo_facet\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##Convert Posts into dataframes \n",
      "fullxdict = defaultdict(list)\n",
      "for i,val in enumerate(allentries):\n",
      "    for x, xval in enumerate(val):\n",
      "        fullxdict[xval[0]].append(xval[1:])\n",
      "dfdict = pd.DataFrame(fullxdict)\n",
      "\n",
      "dfdict.head()\n",
      "\n",
      "\"\"\"\n",
      "\u2022 I collected a more metadata, like author, keywords to see if there might be network relationships we can create later\n",
      "\u2022 I collected source, document type, print_page as additional control variables\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>abstract</th>\n",
        "      <th>author</th>\n",
        "      <th>document type</th>\n",
        "      <th>keywords</th>\n",
        "      <th>lead_paragraph</th>\n",
        "      <th>post length</th>\n",
        "      <th>print_page</th>\n",
        "      <th>pub_date</th>\n",
        "      <th>s</th>\n",
        "      <th>source</th>\n",
        "      <th>web_url</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> (Superpedestrian announced Monday that it will...</td>\n",
        "      <td>     ([(BILTON, Nick)],)</td>\n",
        "      <td> (blogpost,)</td>\n",
        "      <td> [{u'value': u'Superpedestrian Inc', u'name': u...</td>\n",
        "      <td>                                           (None,)</td>\n",
        "      <td> (425.0,)</td>\n",
        "      <td>   (,)</td>\n",
        "      <td> (2013-10-21T20:59:33Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://bits.blogs.nytimes.com/2013/10/21/star...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> (Thomas L Friedman Op-Ed column maintains that...</td>\n",
        "      <td> ([(FRIEDMAN, Thomas)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'CASNOCHA, B...</td>\n",
        "      <td> (The rise in the unemployment rate last month ...</td>\n",
        "      <td> (892.0,)</td>\n",
        "      <td> (27,)</td>\n",
        "      <td> (2011-07-13T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2011/07/13/opinion/13f...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> (David Grubbs letter comments on Jim Windolf M...</td>\n",
        "      <td>               ([None],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'WINDOLF, JI...</td>\n",
        "      <td> (To the Editor: After reading Jim Windolf's re...</td>\n",
        "      <td>  (64.0,)</td>\n",
        "      <td>  (6,)</td>\n",
        "      <td> (2006-03-19T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://query.nytimes.com/gst/fullpage.html?re...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> (Harry Hurt III reviews book My Start-Up Life:...</td>\n",
        "      <td>      ([(HURT, Harry)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'CASNOCHA, B...</td>\n",
        "      <td> (LORD, I loved being 19. If I had the chance t...</td>\n",
        "      <td> (992.0,)</td>\n",
        "      <td>  (7,)</td>\n",
        "      <td> (2007-06-17T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2007/06/17/business/yo...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> (Across the globe, venture-capital infusions f...</td>\n",
        "      <td>      ([(WOODY, Todd)],)</td>\n",
        "      <td> (blogpost,)</td>\n",
        "      <td> [{u'rank': u'4', u'name': u'glocations', u'val...</td>\n",
        "      <td>           (Has the green tech recovery stalled?,)</td>\n",
        "      <td> (505.0,)</td>\n",
        "      <td>   (,)</td>\n",
        "      <td> (2010-10-01T15:13:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://green.blogs.nytimes.com/2010/10/01/gre...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "                                            abstract                   author document type                                           keywords                                     lead_paragraph post length print_page                 pub_date        s                 source                                            web_url\n",
        "0  (Superpedestrian announced Monday that it will...      ([(BILTON, Nick)],)   (blogpost,)  [{u'value': u'Superpedestrian Inc', u'name': u...                                            (None,)    (425.0,)        (,)  (2013-10-21T20:59:33Z,)  tart-up  (The New York Times,)  (http://bits.blogs.nytimes.com/2013/10/21/star...\n",
        "1  (Thomas L Friedman Op-Ed column maintains that...  ([(FRIEDMAN, Thomas)],)    (article,)  [{u'name': u'persons', u'value': u'CASNOCHA, B...  (The rise in the unemployment rate last month ...    (892.0,)      (27,)  (2011-07-13T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2011/07/13/opinion/13f...\n",
        "2  (David Grubbs letter comments on Jim Windolf M...                ([None],)    (article,)  [{u'name': u'persons', u'value': u'WINDOLF, JI...  (To the Editor: After reading Jim Windolf's re...     (64.0,)       (6,)  (2006-03-19T00:00:00Z,)  tart-up  (The New York Times,)  (http://query.nytimes.com/gst/fullpage.html?re...\n",
        "3  (Harry Hurt III reviews book My Start-Up Life:...       ([(HURT, Harry)],)    (article,)  [{u'name': u'persons', u'value': u'CASNOCHA, B...  (LORD, I loved being 19. If I had the chance t...    (992.0,)       (7,)  (2007-06-17T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2007/06/17/business/yo...\n",
        "4  (Across the globe, venture-capital infusions f...       ([(WOODY, Todd)],)   (blogpost,)  [{u'rank': u'4', u'name': u'glocations', u'val...            (Has the green tech recovery stalled?,)    (505.0,)        (,)  (2010-10-01T15:13:00Z,)  tart-up  (The New York Times,)  (http://green.blogs.nytimes.com/2010/10/01/gre..."
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##GET COMMENTS  WITH ALLDF\n",
      "\n",
      "urls = [i[0] for i in dfdict['web_url']]\n",
      "print urls[0]\n",
      "\n",
      "#print urls[0]\n",
      "## loop through terms\n",
      "\n",
      "allcomments = []\n",
      "\n",
      "for url in urls:\n",
      "\n",
      "    ## api request for each term\n",
      "    #print url\n",
      "    urlz = ''.join([\"http://api.nytimes.com/svc/community/v2/comments/url/exact-match.json?url=\",url,\"&api-key=\",api_key_community])\n",
      "    req = requests.get(urlz).text\n",
      "    jsons = json.loads(req)\n",
      "                    \n",
      "    num_comments = \"num comments\", jsons['results']['totalCommentsFound']\n",
      "    commentext = \"all comments\", [i['commentBody'] for i in jsons['results']['comments']]\n",
      "                \n",
      "    comments = num_comments, commentext\n",
      "    allcomments.append(comments)\n",
      "\n",
      "\n",
      "##make each entry a dictionary to make keywords easier to grab\n",
      "\n",
      "#alldict = [dict(i) for i in allcomments]\n",
      "#alldf = pd.DataFrame(alldict)\n",
      "\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://bits.blogs.nytimes.com/2013/10/21/start-up-literally-reinvents-the-bicycle-wheel/\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "##Convert Comments into dataframes\n",
      "xdict = defaultdict(list)\n",
      "for i,val in enumerate(allcomments):\n",
      "    for x, xval in enumerate(val):\n",
      "        #print xval[1]\n",
      "        xdict[xval[0]].append(xval[1])\n",
      "\n",
      "comment3df = pd.DataFrame(xdict)\n",
      "dfdict['num comments'] = comment3df['num comments']\n",
      "dfdict['all comments'] = comment3df['all comments']\n",
      "dfdict.head()\n",
      "\n",
      "\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>abstract</th>\n",
        "      <th>author</th>\n",
        "      <th>document type</th>\n",
        "      <th>keywords</th>\n",
        "      <th>lead_paragraph</th>\n",
        "      <th>post length</th>\n",
        "      <th>print_page</th>\n",
        "      <th>pub_date</th>\n",
        "      <th>s</th>\n",
        "      <th>source</th>\n",
        "      <th>web_url</th>\n",
        "      <th>num comments</th>\n",
        "      <th>all comments</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> (Superpedestrian announced Monday that it will...</td>\n",
        "      <td>     ([(BILTON, Nick)],)</td>\n",
        "      <td> (blogpost,)</td>\n",
        "      <td> [{u'value': u'Superpedestrian Inc', u'name': u...</td>\n",
        "      <td>                                           (None,)</td>\n",
        "      <td> (425.0,)</td>\n",
        "      <td>   (,)</td>\n",
        "      <td> (2013-10-21T20:59:33Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://bits.blogs.nytimes.com/2013/10/21/star...</td>\n",
        "      <td> 96</td>\n",
        "      <td> [If they are smart, they will get the actor wh...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> (Thomas L Friedman Op-Ed column maintains that...</td>\n",
        "      <td> ([(FRIEDMAN, Thomas)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'CASNOCHA, B...</td>\n",
        "      <td> (The rise in the unemployment rate last month ...</td>\n",
        "      <td> (892.0,)</td>\n",
        "      <td> (27,)</td>\n",
        "      <td> (2011-07-13T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2011/07/13/opinion/13f...</td>\n",
        "      <td> 40</td>\n",
        "      <td> [It seems to me that what we're seeing is a ch...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> (David Grubbs letter comments on Jim Windolf M...</td>\n",
        "      <td>               ([None],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'WINDOLF, JI...</td>\n",
        "      <td> (To the Editor: After reading Jim Windolf's re...</td>\n",
        "      <td>  (64.0,)</td>\n",
        "      <td>  (6,)</td>\n",
        "      <td> (2006-03-19T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://query.nytimes.com/gst/fullpage.html?re...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> (Harry Hurt III reviews book My Start-Up Life:...</td>\n",
        "      <td>      ([(HURT, Harry)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'CASNOCHA, B...</td>\n",
        "      <td> (LORD, I loved being 19. If I had the chance t...</td>\n",
        "      <td> (992.0,)</td>\n",
        "      <td>  (7,)</td>\n",
        "      <td> (2007-06-17T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2007/06/17/business/yo...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> (Across the globe, venture-capital infusions f...</td>\n",
        "      <td>      ([(WOODY, Todd)],)</td>\n",
        "      <td> (blogpost,)</td>\n",
        "      <td> [{u'rank': u'4', u'name': u'glocations', u'val...</td>\n",
        "      <td>           (Has the green tech recovery stalled?,)</td>\n",
        "      <td> (505.0,)</td>\n",
        "      <td>   (,)</td>\n",
        "      <td> (2010-10-01T15:13:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://green.blogs.nytimes.com/2010/10/01/gre...</td>\n",
        "      <td> 12</td>\n",
        "      <td> [News Flash - The boys at Big Oil and their me...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "                                            abstract                   author document type                                           keywords                                     lead_paragraph post length print_page                 pub_date        s                 source                                            web_url  num comments                                       all comments\n",
        "0  (Superpedestrian announced Monday that it will...      ([(BILTON, Nick)],)   (blogpost,)  [{u'value': u'Superpedestrian Inc', u'name': u...                                            (None,)    (425.0,)        (,)  (2013-10-21T20:59:33Z,)  tart-up  (The New York Times,)  (http://bits.blogs.nytimes.com/2013/10/21/star...            96  [If they are smart, they will get the actor wh...\n",
        "1  (Thomas L Friedman Op-Ed column maintains that...  ([(FRIEDMAN, Thomas)],)    (article,)  [{u'name': u'persons', u'value': u'CASNOCHA, B...  (The rise in the unemployment rate last month ...    (892.0,)      (27,)  (2011-07-13T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2011/07/13/opinion/13f...            40  [It seems to me that what we're seeing is a ch...\n",
        "2  (David Grubbs letter comments on Jim Windolf M...                ([None],)    (article,)  [{u'name': u'persons', u'value': u'WINDOLF, JI...  (To the Editor: After reading Jim Windolf's re...     (64.0,)       (6,)  (2006-03-19T00:00:00Z,)  tart-up  (The New York Times,)  (http://query.nytimes.com/gst/fullpage.html?re...             0                                                 []\n",
        "3  (Harry Hurt III reviews book My Start-Up Life:...       ([(HURT, Harry)],)    (article,)  [{u'name': u'persons', u'value': u'CASNOCHA, B...  (LORD, I loved being 19. If I had the chance t...    (992.0,)       (7,)  (2007-06-17T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2007/06/17/business/yo...             0                                                 []\n",
        "4  (Across the globe, venture-capital infusions f...       ([(WOODY, Todd)],)   (blogpost,)  [{u'rank': u'4', u'name': u'glocations', u'val...            (Has the green tech recovery stalled?,)    (505.0,)        (,)  (2010-10-01T15:13:00Z,)  tart-up  (The New York Times,)  (http://green.blogs.nytimes.com/2010/10/01/gre...            12  [News Flash - The boys at Big Oil and their me..."
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## read sentiment data from text file\n",
      "sentiment = pd.read_table('sentiment_data.txt', sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fullxdict['lead_paragraph']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 76,
       "text": [
        "[('None',),\n",
        " (u\"The rise in the unemployment rate last month to 9.2 percent has Democrats and Republicans reliably falling back on their respective cure-alls. It is evidence for liberals that we need more stimulus and for conservatives that we need more tax cuts to increase demand. I am sure there is truth in both, but I do not believe they are the whole story. I think something else, something new -- something that will require our kids not so much to find their next job as to invent their next job -- is also influencing today's job market more than people realize. Look at the news these days from the most dynamic sector of the U.S. economy -- Silicon Valley. Facebook is now valued near $100 billion, Twitter at $8 billion, Groupon at $30 billion, Zynga at $20 billion and LinkedIn at $8 billion. These are the fastest-growing Internet/social networking companies in the world, and here's what's scary: You could easily fit all their employees together into the 20,000 seats in Madison Square Garden, and still have room for grandma. They just don't employ a lot of people, relative to their valuations, and while they're all hiring today, they are largely looking for talented engineers.\",),\n",
        " (u\"To the Editor: After reading Jim Windolf's review of Simon Reynolds's ''Rip It Up and Start Again'' (March 5), I found myself wondering whether it's only books about pop music that leave authors exposed to charges of being ''brainy'' and using ''99-cent locutions.'' Is there another field in which authors are routinely taken to task for not condescending to their subjects? David Grubbs Brooklyn\",),\n",
        " (u\"LORD, I loved being 19. If I had the chance to do it all again, I'd start up my life at that age. For most relatively ''normal'' guys like me, life at 19 is a joyously ephemeral state of being in between. Your adolescence is not quite behind you; your adulthood is not quite at hand. You can appropriate the privileges of a grownup without facing the responsibilities. And if you're lucky, you can still put it all on your parents' tab. Or you can be Ben Casnocha, the 19-year-old author of ''My Start-Up Life: What a (Very) Young C.E.O. Learned on His Journey Through Silicon Valley'' (Jossey-Bass, $24.95). Publishing a book in his teens actually ranks as one of his more modest accomplishments. At 12, he started his first company. At 14, he founded a software company called Comcate Inc. At 17, Inc. magazine named him ''entrepreneur of the year.''\",),\n",
        " (u'Has the green tech recovery stalled?',),\n",
        " (u'On Tuesday\\xa0Marco Arment, the chief technology officer at the social networking site\\xa0Tumblr, announced that he would be leaving it to tend to a personal project: Instapaper.',),\n",
        " (u'RIP IT UP AND START AGAIN Postpunk 1978-1984. By Simon Reynolds. 416 pp. Penguin Books. Paper, $16.',),\n",
        " (u\"Michael S. Dell (of Dell Inc.) sold stamps to collectors when he was 12 and Bill Gates founded Microsoft when he was 19. Facebook, the social networking site, was the brainchild of Mark Zuckerberg, a Harvard University sophomore at the time. A study by the Global Entrepreneurship Monitor showed that the United States was unusual among developed countries in having a higher business start-up rate among its 18- to 24-year-olds than its 35- to 44-year-olds. But why has America produced so many successful young entrepreneurs? Ben Casnocha, 19, author of the new book ''My Start-Up Life: What a (Very) Young C.E.O. Learned on His Journey Through Silicon Valley,'' offers clues.\",),\n",
        " (u'THE COMEBACK Seven Stories of Women Who Went From Career to Family and Back Again',),\n",
        " (u'The United Talent Agency plans today to announce the creation of an entertainment marketing company based in New York City. Jarrod Moses, former chief of the product placement firm Alliance, is a founder. The company, to be called United Entertainment Group, will operate independently of the talent agency. The group will create advertiser-branded entertainment properties, said Peter Benedek, a partner at United Talent.',),\n",
        " (u'CRAZY LIKE A FOX The Inside Story of How Fox News Beat CNN. By Scott Collins. 242 pp. New York: Portfolio. $24.95.',),\n",
        " (u\"A light bulb went off for Christy Prunier while giving her 8-year-old daughter, Willa, a bath. The girl complained that she didn't like ''babyish'' soaps anymore. Ms. Prunier got to work, and after three years of research, introduced a line of skin care products aimed at preteenage girls. The name? Willa, of course.\",),\n",
        " (u'SOULLESS Ann Coulter and the Right-Wing Church of Hate. By Susan Estrich. 255 pp. Regan/HarperCollins Publishers. $24.95. BRAINLESS The Lies and Lunacy of Ann Coulter. By Joe Maguire. 204 pp. William Morrow/ HarperCollins Publishers. $21.95. I HATE ANN COULTER! Unanimous. Illustrated. 116 pp. Simon Spotlight Entertainment. Paper, $9.95',),\n",
        " (u'1946 Electronic Control Co. (now Unisys)J. Presper Eckert and John W. Mauchly, University of Pennsylvania professors, build first general-purpose electronic computer, Eniac, in 1945 to speedily calculate artillery paths. The next year they form the first computer company.',),\n",
        " (u\"Dear Mom and Dad, Camp is AWESOME!!! There's this really cool girl named Stephanie in my cabin, and guess what -- she has a really, REALLY cool idea for a Web site. We're going to call it lettersfromcampers.com, and we're going to offer consulting services for kids writing letters from camp on a paid subscription basis and make TONS of money.\",),\n",
        " (u\"When the New York start-up Foursquare Labs made its debut in 2009, it quickly began popularizing the idea of ''checking in,'' or using a cellphone application to tell friends that you are at a particular restaurant, bar or park. Then Facebook and Google borrowed the concept -- and even the term check in. Analysts and users alike wondered if those Internet giants would squash Foursquare like a bug.\",),\n",
        " (u'In October, when Wall Street was already wallowing in the financial crisis, many in the technology industry still thought they might be insulated from the worst of it. Sequoia Capital, the venture capital firm that backed Google, Yahoo and YouTube, scared them straight when it hastily gathered the chief executives of the 100 American companies in its portfolio for a stark wake-up call that rocked Silicon Valley as well as start-ups elsewhere.',),\n",
        " (u'Three years ago, at a news conference at Tavern on the Green restaurant that featured a free-flowing bar, former President Bill Clinton helped introduce a new Internet search engine, Accoona, which was said to be powered by innovative artificial intelligence technology. The event in Manhattan was meant to build interest in the company, founded by Marc Armand Rousso, who had promoted penny stocks and sold stamps.',),\n",
        " (u\"For those who like the idea of renting a villa but not ormolu and chintz, there's Rad Pads. This new group of properties from the British company Private World brings together a dozen modern and avant-garde houses in as many destinations, including Beijing, Bali, St. Bart's and Marrakesh. In the mix are a 50's John Lautner spread in Palm Springs and a new eco-lodge, above, by the Pritzker Prize winner Glenn Murcutt on the Great Ocean Road, on Australia's southeast coast. The villas have two to seven bedrooms and go for $2,000 to $5,000 a night. 011-44-207-723-5599; www.privateworldvillas.com. JEFFRIES BLACKERBY\",),\n",
        " (u'Garrett Camp of StumbleUpon describes what it was like to sell the company and then buy it back.',),\n",
        " (u\"Howard Yellen has recently found what promises to be his dream company: a business with a life span of no more than two years. The company, Settlement Recovery Center in San Francisco, helps small and medium-size businesses in California recover money owed them by Microsoft as part of a $1.1 billion antitrust settlement. When the funds have been distributed, Mr. Yellen will be out of business -- an outcome that suits him just fine. ''I'll help my clients get their share of the money and then -- poof -- I'll be on the next start-up,'' said Mr. Yellen, 43, who has about 20 new business ideas in his pocket. ''This is perfect.'' It is his sixth start-up in 15 years.\",),\n",
        " (u'Just four months after a much-hyped introduction, the video chat company has laid off employees and is tweaking its features.',),\n",
        " (u'Think registering your business sounds like a perfunctory and insignificant task? Think again.',),\n",
        " (u'LIKE so many other young people in Cairo, Yasmine el-Mehairy saw no future in Egypt. What she saw was a dead end. Then came Tahrir Square.',),\n",
        " (u\"IT was the sixth inning of a one-run game between the Chico Outlaws and the Fullerton Flyers when the commissioner of baseball, on his third or fourth beer, stepped into a darkened skybox to explain how he and his partners planned to grow very rich by employing rejects from major-league farm teams. Several hundred fans had gathered here on a Tuesday night earlier this summer to cheer on the Outlaws, one of six teams in the recently birthed Golden Baseball League, but its commissioner, Kevin Outcalt, was distracted. A former Silicon Valley executive who secured this post two years ago after giving the league its first $1 million, Mr. Outcalt was deep into his tale of how he met two Stanford graduate students, David Kaval and Amit Patel, who dreamed up a baseball franchise that all three men describe as an ''alternative entertainment platform.''\",),\n",
        " (u'Technology start-ups and big companies work together all the time -- refining ideas, seeking mutual advantage and accelerating the pace of development of new products and services. But these odd-couple relationships can be fraught with peril. Steve A. Stone, a veteran product manager at Microsoft, had an idea for an innovative way to identify and track digital objects across the Web. So he set up shop for a new company in his garage in suburban Seattle, and convinced a few Microsoft colleagues to join him. They began building their software, working late many nights, fueled by spaghetti and takeout Subway and Quiznos sandwiches.',),\n",
        " (u'For Gary Doan, the chief executive of a start-up technology company, timing is everything. A self-described serial entrepreneur, Mr. Doan understands the vagaries of chance and fighting hard. He founded a start-up, NeoNetworks, that went out of business in 2000, and in 2001 he started IntraDyn, a company that sells data storage technology. But the biggest battle he waged in the last decade has been against a medical condition; hepatitis C was diagnosed in 1993, a viral disease that severely damaged his liver.',),\n",
        " (u\"For Thomas L. Friedman, reading the news that General Motors and Chrysler are now lining up for another $20 billion or so in government aid - on top of the billions they've already received or requested - leaves him with the sick feeling that we are subsidizing the losers and for only one reason: because they claim that their funerals would cost more than keeping them on life support.\",),\n",
        " (u\"I'M from Calgary, Alberta. My mother was an artist and my father was an economist until they changed careers and became a design/build team. I grew up watching them build homes. My elementary school had 150 students, with one class for each grade, 1 to 9, so I was with the same kids throughout. When I entered high school, there were 1,700 students. It was a big change.\",),\n",
        " (u\"Hari Kaur has been teaching yoga for 20 years as a private instructor and at other people's studios, most recently in New York, but it was only late last year that she decided she wanted to start her own Jazz Yoga school -- the world's first, as far as she knew. What she didn't know was much about how to start and run a business. But one of her students happened to be an experienced entrepreneur who had recently started his fourth company, and he gave her some smart-sounding advice on funding, marketing and leasing a space. When she came up with more questions, he told her she ought to check out that latest business of his, which happened to be a free online service focused on ... how to start a company.\",)]"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fullxdict['abstract'][0][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 116,
       "text": [
        "u'Superpedestrian announced Monday that it will begin selling the Copenhagen Wheel, which can make any bicycle into a motorized hybrid e-bike.'"
       ]
      }
     ],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#SENTIMENT AND WORD LENGTH SCORES FOR POSTS\n",
      "\n",
      "##get average word length and avg sentiment for posts \n",
      "word_lengths = [] \n",
      "sent_scores = []\n",
      "avg_word = []\n",
      "avg_sent = []\n",
      "\n",
      "for i, entry1 in enumerate(fullxdict['lead_paragraph']):\n",
      "        print 'analyzing entry:', i\n",
      "        for i, paragraph in enumerate(entry1):\n",
      "            if paragraph != 'None':\n",
      "                for word in paragraph.split(' '):\n",
      "                    word = re.sub(\"\\W\",'',word)\n",
      "                    if len(word) > 0:\n",
      "                        word_lengths.append(len(word))\n",
      "                    for entry in sentiment.iterrows():\n",
      "                        if word == entry[1]['word']:\n",
      "                            print \"analyzing word in database:\", word\n",
      "                            sent_scores.append(entry[1]['happiness_average'])\n",
      "                avg_word.append(round(np.mean(word_lengths),3))\n",
      "                avg_sent.append(round(np.mean(sent_scores),3))    \n",
      "            \n",
      "            if paragraph == 'None': \n",
      "                print 'analyzing entry:', i\n",
      "                for sentence in fullxdict['abstract'][i]:\n",
      "                    for word in sentence.split(' '): \n",
      "                        #print word\n",
      "                        word = re.sub(\"\\W\",'',word)\n",
      "                        if len(word) > 0:\n",
      "                            #print len(word)\n",
      "                            word_lengths.append(len(word))\n",
      "                        for entry in sentiment.iterrows():\n",
      "                            if word == entry[1]['word']:\n",
      "                                print word\n",
      "                                sent_scores.append(entry[1]['happiness_average'])\n",
      "                avg_word.append(round(np.mean(word_lengths),3))\n",
      "                avg_sent.append(round(np.mean(sent_scores),3))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "analyzing entry: 0\n",
        "analyzing entry: 0\n",
        "announced"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "that"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "it"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "will"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "begin"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "selling"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "the"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "which"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "can"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "make"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "any"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "into"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "a"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "analyzing entry:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rise\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " unemployment\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rate\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " last\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " month\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " percent\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " has\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " falling\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " back\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " on\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " their\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " respective\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " is\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " evidence\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " for\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " that\n",
        "analyzing word in database: we\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " need\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " more\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " stimulus\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " for\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " conservatives\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " that\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " we\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " need\n",
        "analyzing word in database: more\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " tax\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " cuts\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database: increase\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " demand\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " am\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " sure\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " there\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " is\n",
        "analyzing word in database: truth\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " both\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " but\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " do\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " not\n",
        "analyzing word in database: believe\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " they\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " are\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " whole\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " story\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " think\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " something\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " else\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " something\n",
        "analyzing word in database: new\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " something\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " that\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " will\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " require\n",
        "analyzing word in database: our\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " kids\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " not\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " so\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " much\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " find\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " their\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " next\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " job\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " as\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " their\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " next\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " job\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " is\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " also\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " todays\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " job\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " market\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " more\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " than\n",
        "analyzing word in database: people\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " realize\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " at\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " news\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " these\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " days\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " from\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " most\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dynamic\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " sector\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " economy\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " is\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " now\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " valued\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " near\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " billion\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " at\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " billion\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " at\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " billion\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " at\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " billion\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " at\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " billion\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " are\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " networking\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " companies\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database: world\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " whats\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " scary\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " could\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " easily\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " fit\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " all\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " their\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " employees\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " together\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " into\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " seats\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " still\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " have\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " room\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " for\n",
        "analyzing word in database: grandma\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " just\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dont\n",
        "analyzing word in database: employ\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " lot\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " people\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " relative\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " their\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " while\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " theyre\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " all\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " hiring\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " today\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " they\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " are\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " largely\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " looking\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " for\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " talented\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " engineers\n",
        "analyzing entry:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " reading\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " review\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " found\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " myself\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " wondering\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " whether\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " its\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " only\n",
        "analyzing word in database: books\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " about\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " pop\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " music\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " that\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " leave\n",
        "analyzing word in database: authors\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " exposed\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " charges\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " being\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " using\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " there\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " another\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " field\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " which\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " authors\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " are\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " taken\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " task\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " for\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " not\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " their\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " subjects\n",
        "analyzing entry:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " loved\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " being\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " had\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database: chance\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " do\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " it\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " all\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " again\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " start\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " up\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " my\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " life\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " at\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " that\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " age\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " most\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " relatively\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " normal\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " guys\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " like\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " me\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " life\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " at\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " is\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " state\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " being\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " between\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " is\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " not\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " quite\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " behind\n",
        "analyzing word in database: you\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " your\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " is\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " not\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " quite\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " at\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " hand\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " can\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " appropriate\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database: privileges\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " without\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " facing\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " responsibilities\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " if\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " youre\n",
        "analyzing word in database: lucky\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " you\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " can\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " still\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " put\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " it\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " all\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " on\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " your\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " parents\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " you\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " can\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " be\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " author\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " on\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database: book\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " his\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " teens\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " actually\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ranks\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " as\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " one\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " his\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " more\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " modest\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " he\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " started\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " his\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " first\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " company\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " he\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " founded\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " software\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " company\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " called\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " magazine\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " named\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " him\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " year\n",
        "analyzing entry: 4\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database: green\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " tech\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " recovery\n",
        "analyzing entry:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " chief\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " technology\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " officer\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " at\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " social\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " networking\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " announced\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " that\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " he\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " would\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " be\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " leaving\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " it\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " tend\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " personal\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " project\n",
        "analyzing entry:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " pp\n",
        "analyzing entry:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " sold\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " when\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " he\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " was\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " founded\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " when\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " he\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " was\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " social\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " networking\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " site\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " was\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " at\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " time\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " study\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " by\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " showed\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " that\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " was\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " unusual\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " among\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " developed\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " countries\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " having\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " higher\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " business\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rate\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " among\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " its\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " than\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " its\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " why\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " has\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " produced\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " so\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " many\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " successful\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " young\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " author\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database: new\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " book\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " on\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " offers\n",
        "analyzing entry:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing entry:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " plans\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " today\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " announce\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database: creation\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " an\n",
        "analyzing word in database: entertainment\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " marketing\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " company\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " based\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " former\n",
        "analyzing word in database: chief\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " product\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " firm\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " is\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " founder\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " company\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " be\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " called\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " will\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " operate\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database: talent\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " agency\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " group\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " will\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " create\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " entertainment\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " properties\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " said\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " partner\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " at\n",
        "analyzing entry:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " pp\n",
        "analyzing entry:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " light\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " went\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " off\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " for\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " while\n",
        "analyzing word in database: giving\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " her\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " daughter\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " bath\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " girl\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " complained\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " that\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " she\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " didnt\n",
        "analyzing word in database: like\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " anymore\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " got\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " work\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " after\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " three\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " years\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database: research\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " introduced\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " line\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " skin\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " care\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " products\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " aimed\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " at\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " girls\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " name\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " course\n",
        "analyzing entry:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " pp\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " pp\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " pp\n",
        "analyzing entry:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " now\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " build\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " first\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " electronic\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " computer\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " artillery\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " next\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " year\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " they\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " form\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database: first\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " computer\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " company\n",
        "analyzing entry:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " is\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " this\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " really\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " cool\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " girl\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " named\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " my\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " guess\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " what\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " she\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " has\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " really\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " cool\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " idea\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " for\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " site\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " going\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " call\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " it\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " were\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " going\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database: offer\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " consulting\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " services\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " for\n",
        "analyzing word in database: kids\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " writing\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " letters\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " from\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " camp\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " on\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " paid\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " basis\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " make\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database: money\n",
        "analyzing entry:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 15\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " made\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " its\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " debut\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " it\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " quickly\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " began\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database: idea\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " checking\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " or\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " using\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " application\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " tell\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " friends\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " that\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " you\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " are\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " at\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " particular\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " restaurant\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " bar\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " or\n",
        "analyzing word in database: park\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " borrowed\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " concept\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " even\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " term\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " check\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " users\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " alike\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " wondered\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " if\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " those\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " giants\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " would\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " like\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " bug\n",
        "analyzing entry: 16\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " when\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " was\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " already\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " financial\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " crisis\n",
        "analyzing word in database: many\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database: technology\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " industry\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " still\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " thought\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " they\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " might\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " be\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " from\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " worst\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " it\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " venture\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " capital\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " firm\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " that\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " backed\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " scared\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " them\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " straight\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " when\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " it\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " gathered\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " chief\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " executives\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " companies\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " its\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " portfolio\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " for\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " call\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " that\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rocked\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " as\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " well\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " as\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " elsewhere\n",
        "analyzing entry: 17\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " years\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ago\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " at\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " news\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " conference\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " at\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " on\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " restaurant\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " that\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " featured\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " bar\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " former\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " helped\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " introduce\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " new\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " search\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " engine\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " which\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " was\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " said\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " be\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " by\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " artificial\n",
        "analyzing word in database: intelligence\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " technology\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " event\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " was\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " meant\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " build\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " interest\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " company\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " founded\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " by\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " who\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " had\n",
        "analyzing word in database: promoted\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " penny\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " stocks\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " sold\n",
        "analyzing entry:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 18\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " those\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " who\n",
        "analyzing word in database: like\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database: idea\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " but\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " not\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " theres\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " new\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " group\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " properties\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " from\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " company\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " brings\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " together\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dozen\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " modern\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " houses\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " as\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " many\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " including\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " mix\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " are\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " spread\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " new\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " above\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " by\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " winner\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " on\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " on\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " southeast\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " coast\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " have\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " two\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " seven\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " go\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " for\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " night\n",
        "analyzing entry:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 19\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " describes\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " what\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " it\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " was\n",
        "analyzing word in database: like\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " sell\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " company\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " then\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " buy\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " it\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " back\n",
        "analyzing entry: 20\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " has\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " recently\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " found\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " what\n",
        "analyzing word in database: promises\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " be\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " his\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dream\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " company\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " business\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " with\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database: life\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " no\n",
        "analyzing word in database: more\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " than\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " two\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " years\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " company\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " helps\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " small\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " businesses\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " recover\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " money\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " them\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " by\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " as\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " part\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " billion\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " settlement\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " funds\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " have\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " been\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " distributed\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " will\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " be\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " out\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " business\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " an\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " outcome\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " that\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " suits\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " him\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " just\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " fine\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " help\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " my\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " clients\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " get\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " their\n",
        "analyzing word in database: share\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database: money\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " then\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " be\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " on\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " next\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " said\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " who\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " has\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " about\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " new\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " business\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ideas\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " his\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " pocket\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " is\n",
        "analyzing word in database: perfect\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " is\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " his\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " sixth\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " years\n",
        "analyzing entry: 21\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " four\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " months\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " after\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " introduction\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database: video\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " chat\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " company\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " has\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " laid\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " off\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " employees\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " is\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " its\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " features\n",
        "analyzing entry:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 22\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " your\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " business\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " sounds\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " like\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " task\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " again\n",
        "analyzing entry:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 23\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " so\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " many\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " other\n",
        "analyzing word in database: young\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " people\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " saw\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " no\n",
        "analyzing word in database: future\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " she\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " saw\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " was\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dead\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " end\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " came\n",
        "analyzing entry:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 24\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " was\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " sixth\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " inning\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " game\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " between\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " when\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " commissioner\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " baseball\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " on\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " his\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " third\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " or\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " fourth\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " beer\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " stepped\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " into\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " darkened\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explain\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " how\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " he\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " his\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " partners\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " planned\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database: grow\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " very\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rich\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " by\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " from\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " farm\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " teams\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " hundred\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " fans\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " had\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " gathered\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " here\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " on\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " night\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " earlier\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " this\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " summer\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database: cheer\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " on\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " one\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " six\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " teams\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " recently\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " but\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " its\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " commissioner\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " was\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " former\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " executive\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " who\n",
        "analyzing word in database: secured\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " this\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " post\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " two\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " years\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ago\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " after\n",
        "analyzing word in database: giving\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " league\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " its\n",
        "analyzing word in database: first\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " million\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " was\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " deep\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " into\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " his\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " tale\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " how\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " he\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " met\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " two\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " graduate\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " students\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " who\n",
        "analyzing word in database: dreamed\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " up\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " baseball\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " that\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " all\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " three\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " men\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " describe\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " as\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " an\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " alternative\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " entertainment\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " platform\n",
        "analyzing entry: 25\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " big\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " companies\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " work\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " together\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " all\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " time\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ideas\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " seeking\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " mutual\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " advantage\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " pace\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database: development\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database: new\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " products\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " services\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " these\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " relationships\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " can\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " be\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " with\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " veteran\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " product\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " manager\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " at\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " had\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " an\n",
        "analyzing word in database: idea\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " for\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " an\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " way\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " identify\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " track\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " digital\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " objects\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " across\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " he\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " set\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " up\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " shop\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " for\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " new\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " company\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " his\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " garage\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " suburban\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " convinced\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " few\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " colleagues\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " join\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " him\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " began\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " building\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " their\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " software\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " working\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " late\n",
        "analyzing word in database: many\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " nights\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " by\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing entry:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 26\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " chief\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " executive\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " technology\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " company\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " timing\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " is\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " everything\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " understands\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database: chance\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " fighting\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " hard\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " founded\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " that\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " went\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " out\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " business\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " he\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " started\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " company\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " that\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " sells\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " data\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " storage\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " technology\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " biggest\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " battle\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " he\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " last\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " decade\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " has\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " been\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " against\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " medical\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " condition\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " was\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " disease\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " that\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " damaged\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " his\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " liver\n",
        "analyzing entry: 27\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " reading\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " news\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " that\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " are\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " now\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " up\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " for\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " another\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " billion\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " or\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " so\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " government\n",
        "analyzing word in database: aid\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " on\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " top\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " already\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " received\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " or\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " requested\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " leaves\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " him\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " with\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " sick\n",
        "analyzing word in database: feeling\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " that\n",
        "analyzing word in database: we\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " are\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " losers\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " for\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " only\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " one\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " reason\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " because\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " they\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " claim\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " that\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " their\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " would\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " cost\n",
        "analyzing word in database: more\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " than\n",
        "analyzing word in database: keeping\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " them\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " on\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " life\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " support\n",
        "analyzing entry:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 28\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " from\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " mother\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " was\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " an\n",
        "analyzing word in database: artist\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " my\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " father\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " was\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " an\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " economist\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " until\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " they\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " changed\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " became\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " team\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " grew\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " up\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " watching\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " them\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " build\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " homes\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " elementary\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " school\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " had\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " students\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " with\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " one\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " class\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " for\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " each\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " grade\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " so\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " was\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " with\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " same\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " kids\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " throughout\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " entered\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " high\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " school\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " there\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " were\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " students\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " was\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " big\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " change\n",
        "analyzing entry:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 29\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " has\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " been\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " teaching\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " yoga\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " for\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " years\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " as\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " private\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " at\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " other\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " peoples\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " most\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " recently\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " but\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " it\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " was\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " only\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " late\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " last\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " year\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " that\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " she\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " decided\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " she\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " wanted\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " start\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " her\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " own\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " school\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " worlds\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " first\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " as\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " far\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " as\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " she\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " knew\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " she\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " didnt\n",
        "analyzing word in database: know\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " was\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " much\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " about\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " how\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " start\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " run\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " business\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " one\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " her\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " students\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " happened\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " be\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " an\n",
        "analyzing word in database: experienced\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " who\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " had\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " recently\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " started\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " his\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " fourth\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " company\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " he\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " gave\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " her\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " some\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " advice\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " on\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " marketing\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " and\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " space\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " she\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " came\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " up\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " with\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " more\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " questions\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " he\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " told\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " her\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " she\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ought\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " check\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " out\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " that\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " latest\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " business\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " of\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " his\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " which\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " happened\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " be\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database: free\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " online\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " service\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " focused\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " on\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " how\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " start\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " a\n",
        "analyzing word in database:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " company\n"
       ]
      }
     ],
     "prompt_number": 152
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "avg_sent"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 153,
       "text": [
        "[5.426,\n",
        " 5.48,\n",
        " 5.456,\n",
        " 5.501,\n",
        " 5.509,\n",
        " 5.501,\n",
        " 5.5,\n",
        " 5.493,\n",
        " 5.49,\n",
        " 5.502,\n",
        " 5.5,\n",
        " 5.503,\n",
        " 5.495,\n",
        " 5.504,\n",
        " 5.522,\n",
        " 5.52,\n",
        " 5.494,\n",
        " 5.496,\n",
        " 5.498,\n",
        " 5.496,\n",
        " 5.507,\n",
        " 5.505,\n",
        " 5.507,\n",
        " 5.502,\n",
        " 5.504,\n",
        " 5.509,\n",
        " 5.49,\n",
        " 5.485,\n",
        " 5.49,\n",
        " 5.49]"
       ]
      }
     ],
     "prompt_number": 153
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 106,
       "text": [
        "[5.571, 5.161]"
       ]
      }
     ],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>abstract</th>\n",
        "      <th>author</th>\n",
        "      <th>document type</th>\n",
        "      <th>keywords</th>\n",
        "      <th>lead_paragraph</th>\n",
        "      <th>post length</th>\n",
        "      <th>print_page</th>\n",
        "      <th>pub_date</th>\n",
        "      <th>s</th>\n",
        "      <th>source</th>\n",
        "      <th>web_url</th>\n",
        "      <th>num comments</th>\n",
        "      <th>all comments</th>\n",
        "      <th>avg word length</th>\n",
        "      <th>avg sentiment</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td> (Superpedestrian announced Monday that it will...</td>\n",
        "      <td>                     ([(BILTON, Nick)],)</td>\n",
        "      <td> (blogpost,)</td>\n",
        "      <td> [{u'value': u'Superpedestrian Inc', u'name': u...</td>\n",
        "      <td>                                           (None,)</td>\n",
        "      <td>  (425.0,)</td>\n",
        "      <td>   (,)</td>\n",
        "      <td> (2013-10-21T20:59:33Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://bits.blogs.nytimes.com/2013/10/21/star...</td>\n",
        "      <td> 96</td>\n",
        "      <td> [If they are smart, they will get the actor wh...</td>\n",
        "      <td> 5.571</td>\n",
        "      <td> 5.426</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td> (Thomas L Friedman Op-Ed column maintains that...</td>\n",
        "      <td>                 ([(FRIEDMAN, Thomas)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'CASNOCHA, B...</td>\n",
        "      <td> (The rise in the unemployment rate last month ...</td>\n",
        "      <td>  (892.0,)</td>\n",
        "      <td> (27,)</td>\n",
        "      <td> (2011-07-13T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2011/07/13/opinion/13f...</td>\n",
        "      <td> 40</td>\n",
        "      <td> [It seems to me that what we're seeing is a ch...</td>\n",
        "      <td> 4.774</td>\n",
        "      <td> 5.480</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td> (David Grubbs letter comments on Jim Windolf M...</td>\n",
        "      <td>                               ([None],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'WINDOLF, JI...</td>\n",
        "      <td> (To the Editor: After reading Jim Windolf's re...</td>\n",
        "      <td>   (64.0,)</td>\n",
        "      <td>  (6,)</td>\n",
        "      <td> (2006-03-19T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://query.nytimes.com/gst/fullpage.html?re...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.796</td>\n",
        "      <td> 5.456</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td> (Harry Hurt III reviews book My Start-Up Life:...</td>\n",
        "      <td>                      ([(HURT, Harry)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'CASNOCHA, B...</td>\n",
        "      <td> (LORD, I loved being 19. If I had the chance t...</td>\n",
        "      <td>  (992.0,)</td>\n",
        "      <td>  (7,)</td>\n",
        "      <td> (2007-06-17T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2007/06/17/business/yo...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.628</td>\n",
        "      <td> 5.501</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td> (Across the globe, venture-capital infusions f...</td>\n",
        "      <td>                      ([(WOODY, Todd)],)</td>\n",
        "      <td> (blogpost,)</td>\n",
        "      <td> [{u'rank': u'4', u'name': u'glocations', u'val...</td>\n",
        "      <td>           (Has the green tech recovery stalled?,)</td>\n",
        "      <td>  (505.0,)</td>\n",
        "      <td>   (,)</td>\n",
        "      <td> (2010-10-01T15:13:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://green.blogs.nytimes.com/2010/10/01/gre...</td>\n",
        "      <td> 12</td>\n",
        "      <td> [News Flash - The boys at Big Oil and their me...</td>\n",
        "      <td> 4.633</td>\n",
        "      <td> 5.509</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td> (Marco Arment, the chief technology officer at...</td>\n",
        "      <td>                     ([(BILTON, Nick)],)</td>\n",
        "      <td> (blogpost,)</td>\n",
        "      <td> [{u'rank': u'5', u'name': u'organizations', u'...</td>\n",
        "      <td> (On Tuesday\u00a0Marco Arment, the chief technology...</td>\n",
        "      <td>  (394.0,)</td>\n",
        "      <td>   (,)</td>\n",
        "      <td> (2010-09-23T15:11:31Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://bits.blogs.nytimes.com/2010/09/23/inst...</td>\n",
        "      <td> 17</td>\n",
        "      <td> [Instapaper still lacks two essential tools th...</td>\n",
        "      <td> 4.677</td>\n",
        "      <td> 5.501</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td>                                               (,)</td>\n",
        "      <td>                     ([(WINDOLF, Jim)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'REYNOLDS, S...</td>\n",
        "      <td> (RIP IT UP AND START AGAIN Postpunk 1978-1984....</td>\n",
        "      <td> (1017.0,)</td>\n",
        "      <td>  (6,)</td>\n",
        "      <td> (2006-03-05T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2006/03/05/books/revie...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.668</td>\n",
        "      <td> 5.500</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> (Tyler Cowen Economic Scene column on why US h...</td>\n",
        "      <td>                     ([(COWEN, Tyler)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'CASNOCHA, B...</td>\n",
        "      <td> (Michael S. Dell (of Dell Inc.) sold stamps to...</td>\n",
        "      <td>  (971.0,)</td>\n",
        "      <td>  (3,)</td>\n",
        "      <td> (2007-06-14T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2007/06/14/business/14...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.706</td>\n",
        "      <td> 5.493</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td> (Eugenie Allen reviews book The Comeback: Seve...</td>\n",
        "      <td>                   ([(ALLEN, Eugenie)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'KELLER, EMM...</td>\n",
        "      <td> (THE COMEBACK Seven Stories of Women Who Went ...</td>\n",
        "      <td>  (914.0,)</td>\n",
        "      <td> (13,)</td>\n",
        "      <td> (2008-09-21T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2008/09/21/books/revie...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.700</td>\n",
        "      <td> 5.490</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> (United Talent Agency will announce creation o...</td>\n",
        "      <td>                               ([None],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'glocations', u'value': u'NEW YORK...</td>\n",
        "      <td> (The United Talent Agency plans today to annou...</td>\n",
        "      <td>   (63.0,)</td>\n",
        "      <td>  (5,)</td>\n",
        "      <td> (2007-09-10T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2007/09/10/business/me...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.779</td>\n",
        "      <td> 5.502</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> (David Carr reviews book Crazy Like a Fox: The...</td>\n",
        "      <td>                      ([(Carr, David)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'COLLINS, SC...</td>\n",
        "      <td> (CRAZY LIKE A FOX The Inside Story of How Fox ...</td>\n",
        "      <td> (1129.0,)</td>\n",
        "      <td> (34,)</td>\n",
        "      <td> (2004-04-18T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2004/04/18/books/from-...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.750</td>\n",
        "      <td> 5.500</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td> (Some small companies claim that larger ones a...</td>\n",
        "      <td> ([(LATTMAN, Peter), (MARTIN, Andrew)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'PRUNIER, CH...</td>\n",
        "      <td> (A light bulb went off for Christy Prunier whi...</td>\n",
        "      <td> (1315.0,)</td>\n",
        "      <td>  (1,)</td>\n",
        "      <td> (2011-09-29T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://query.nytimes.com/gst/fullpage.html?re...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.743</td>\n",
        "      <td> 5.503</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td> (Jacob Heilbrunn reviews books Soulless: Ann C...</td>\n",
        "      <td>                 ([(Heilbrunn, Jacob)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'UNANIMOUS'}...</td>\n",
        "      <td> (SOULLESS Ann Coulter and the Right-Wing Churc...</td>\n",
        "      <td> (1287.0,)</td>\n",
        "      <td> (15,)</td>\n",
        "      <td> (2006-11-26T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2006/11/26/books/Heilb...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.790</td>\n",
        "      <td> 5.495</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td> (Timeline shows significant moments in the his...</td>\n",
        "      <td>                               ([None],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> (1946 Electronic Control Co. (now Unisys)J. Pr...</td>\n",
        "      <td>  (328.0,)</td>\n",
        "      <td> (10,)</td>\n",
        "      <td> (2012-07-22T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://query.nytimes.com/gst/fullpage.html?re...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.839</td>\n",
        "      <td> 5.504</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td>                                               (,)</td>\n",
        "      <td>                   ([(Borowitz, Andy)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> (Dear Mom and Dad, Camp is AWESOME!!! There's ...</td>\n",
        "      <td>  (325.0,)</td>\n",
        "      <td> (29,)</td>\n",
        "      <td> (2000-07-13T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2000/07/13/opinion/sta...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.815</td>\n",
        "      <td> 5.522</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td> (Foursquare will introduce its largest partner...</td>\n",
        "      <td>                   ([(WORTHAM, Jenna)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'LATTMAN, PE...</td>\n",
        "      <td> (When the New York start-up Foursquare Labs ma...</td>\n",
        "      <td> (1009.0,)</td>\n",
        "      <td>  (1,)</td>\n",
        "      <td> (2011-06-23T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2011/06/23/technology/...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.813</td>\n",
        "      <td> 5.520</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td> (Many young technology companies have slashed ...</td>\n",
        "      <td>                   ([(MILLER, Claire)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'organizations', u'value': u'SEQUO...</td>\n",
        "      <td> (In October, when Wall Street was already wall...</td>\n",
        "      <td> (1119.0,)</td>\n",
        "      <td>  (1,)</td>\n",
        "      <td> (2009-04-08T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2009/04/08/technology/...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.832</td>\n",
        "      <td> 5.494</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td> (Maxim Group pulls out as underwriter of start...</td>\n",
        "      <td>                    ([(HANSELL, Saul)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'ROUSSO, MAR...</td>\n",
        "      <td> (Three years ago, at a news conference at Tave...</td>\n",
        "      <td> (1312.0,)</td>\n",
        "      <td>  (1,)</td>\n",
        "      <td> (2007-08-22T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2007/08/22/technology/...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.852</td>\n",
        "      <td> 5.496</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td>                                               (,)</td>\n",
        "      <td>              ([(Blackerby, Jeffries)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> (For those who like the idea of renting a vill...</td>\n",
        "      <td>  (100.0,)</td>\n",
        "      <td> (24,)</td>\n",
        "      <td> (2006-11-19T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://query.nytimes.com/gst/fullpage.html?re...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.855</td>\n",
        "      <td> 5.498</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td> (The Boss column features StumbleUpon chief ex...</td>\n",
        "      <td>                    ([(CAMP, Garrett)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'value': u'StumbleUpon', u'is_major': u'Y',...</td>\n",
        "      <td> (Garrett Camp of StumbleUpon describes what it...</td>\n",
        "      <td>  (660.0,)</td>\n",
        "      <td> (10,)</td>\n",
        "      <td> (2011-10-23T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2011/10/23/jobs/23boss...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.847</td>\n",
        "      <td> 5.496</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20</th>\n",
        "      <td> (Article on special breed of small-business ow...</td>\n",
        "      <td>                      ([(FIELD, Anne)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'YELLEN, HOW...</td>\n",
        "      <td> (Howard Yellen has recently found what promise...</td>\n",
        "      <td> (1178.0,)</td>\n",
        "      <td>  (6,)</td>\n",
        "      <td> (2003-12-11T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2003/12/11/business/sm...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.808</td>\n",
        "      <td> 5.507</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21</th>\n",
        "      <td>                                               (,)</td>\n",
        "      <td>                   ([(WORTHAM, Jenna)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'rank': u'3', u'name': u'persons', u'value'...</td>\n",
        "      <td> (Just four months after a much-hyped introduct...</td>\n",
        "      <td> (1466.0,)</td>\n",
        "      <td>  (1,)</td>\n",
        "      <td> (2012-10-19T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2012/10/19/technology/...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.813</td>\n",
        "      <td> 5.505</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22</th>\n",
        "      <td> (Think registering your business sounds like a...</td>\n",
        "      <td>                               ([None],)</td>\n",
        "      <td> (blogpost,)</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> (Think registering your business sounds like a...</td>\n",
        "      <td> (1192.0,)</td>\n",
        "      <td>   (,)</td>\n",
        "      <td> (2010-04-01T00:49:48Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://dealbook.nytimes.com/2010/04/01/how-to...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.826</td>\n",
        "      <td> 5.507</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23</th>\n",
        "      <td> (Six months after Egyptian uprising, business ...</td>\n",
        "      <td>                 ([(SELIGSON, Hannah)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'GERBER, SCO...</td>\n",
        "      <td> (LIKE so many other young people in Cairo, Yas...</td>\n",
        "      <td> (1794.0,)</td>\n",
        "      <td>  (1,)</td>\n",
        "      <td> (2011-07-17T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2011/07/17/business/gl...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.813</td>\n",
        "      <td> 5.502</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24</th>\n",
        "      <td> (Article on Golden Baseball League, formed two...</td>\n",
        "      <td>                     ([(RIVLIN, Gary)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'OUTCALT, KE...</td>\n",
        "      <td> (IT was the sixth inning of a one-run game bet...</td>\n",
        "      <td> (3167.0,)</td>\n",
        "      <td>  (1,)</td>\n",
        "      <td> (2006-07-09T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2006/07/09/business/yo...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.813</td>\n",
        "      <td> 5.504</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25</th>\n",
        "      <td> (Legal battle between Corbis and Infoflows is ...</td>\n",
        "      <td>                      ([(LOHR, Steve)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'GATES, BILL...</td>\n",
        "      <td> (Technology start-ups and big companies work t...</td>\n",
        "      <td> (1222.0,)</td>\n",
        "      <td>  (6,)</td>\n",
        "      <td> (2010-07-19T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2010/07/19/technology/...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.829</td>\n",
        "      <td> 5.509</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26</th>\n",
        "      <td> (Interview with Gary Doan, founder and chief e...</td>\n",
        "      <td>                    ([(FLYNN, Laurie)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'DOAN, GARY'...</td>\n",
        "      <td> (For Gary Doan, the chief executive of a start...</td>\n",
        "      <td>  (700.0,)</td>\n",
        "      <td>  (4,)</td>\n",
        "      <td> (2004-03-29T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2004/03/29/business/te...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.837</td>\n",
        "      <td> 5.490</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27</th>\n",
        "      <td> (For Thomas L. Friedman, reading the news that...</td>\n",
        "      <td>                               ([None],)</td>\n",
        "      <td> (blogpost,)</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> (For Thomas L. Friedman, reading the news that...</td>\n",
        "      <td>  (866.0,)</td>\n",
        "      <td>   (,)</td>\n",
        "      <td> (2009-02-23T06:49:48Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://dealbook.nytimes.com/2009/02/23/start-...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.830</td>\n",
        "      <td> 5.485</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28</th>\n",
        "      <td>                                               (,)</td>\n",
        "      <td>                    ([(CAMP, Garrett)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'organizations', u'value': u'STUMB...</td>\n",
        "      <td> (I'M from Calgary, Alberta. My mother was an a...</td>\n",
        "      <td>  (668.0,)</td>\n",
        "      <td> (10,)</td>\n",
        "      <td> (2011-10-23T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2011/10/23/jobs/23boss...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.809</td>\n",
        "      <td> 5.490</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29</th>\n",
        "      <td>                                               (,)</td>\n",
        "      <td>                  ([(FREEDMAN, David)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> (Hari Kaur has been teaching yoga for 20 years...</td>\n",
        "      <td> (1152.0,)</td>\n",
        "      <td>  (8,)</td>\n",
        "      <td> (2011-09-01T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://query.nytimes.com/gst/fullpage.html?re...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.775</td>\n",
        "      <td> 5.490</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 154,
       "text": [
        "                                             abstract                                   author document type                                           keywords                                     lead_paragraph post length print_page                 pub_date        s                 source                                            web_url  num comments                                       all comments  avg word length  avg sentiment\n",
        "0   (Superpedestrian announced Monday that it will...                      ([(BILTON, Nick)],)   (blogpost,)  [{u'value': u'Superpedestrian Inc', u'name': u...                                            (None,)    (425.0,)        (,)  (2013-10-21T20:59:33Z,)  tart-up  (The New York Times,)  (http://bits.blogs.nytimes.com/2013/10/21/star...            96  [If they are smart, they will get the actor wh...            5.571          5.426\n",
        "1   (Thomas L Friedman Op-Ed column maintains that...                  ([(FRIEDMAN, Thomas)],)    (article,)  [{u'name': u'persons', u'value': u'CASNOCHA, B...  (The rise in the unemployment rate last month ...    (892.0,)      (27,)  (2011-07-13T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2011/07/13/opinion/13f...            40  [It seems to me that what we're seeing is a ch...            4.774          5.480\n",
        "2   (David Grubbs letter comments on Jim Windolf M...                                ([None],)    (article,)  [{u'name': u'persons', u'value': u'WINDOLF, JI...  (To the Editor: After reading Jim Windolf's re...     (64.0,)       (6,)  (2006-03-19T00:00:00Z,)  tart-up  (The New York Times,)  (http://query.nytimes.com/gst/fullpage.html?re...             0                                                 []            4.796          5.456\n",
        "3   (Harry Hurt III reviews book My Start-Up Life:...                       ([(HURT, Harry)],)    (article,)  [{u'name': u'persons', u'value': u'CASNOCHA, B...  (LORD, I loved being 19. If I had the chance t...    (992.0,)       (7,)  (2007-06-17T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2007/06/17/business/yo...             0                                                 []            4.628          5.501\n",
        "4   (Across the globe, venture-capital infusions f...                       ([(WOODY, Todd)],)   (blogpost,)  [{u'rank': u'4', u'name': u'glocations', u'val...            (Has the green tech recovery stalled?,)    (505.0,)        (,)  (2010-10-01T15:13:00Z,)  tart-up  (The New York Times,)  (http://green.blogs.nytimes.com/2010/10/01/gre...            12  [News Flash - The boys at Big Oil and their me...            4.633          5.509\n",
        "5   (Marco Arment, the chief technology officer at...                      ([(BILTON, Nick)],)   (blogpost,)  [{u'rank': u'5', u'name': u'organizations', u'...  (On Tuesday\u00a0Marco Arment, the chief technology...    (394.0,)        (,)  (2010-09-23T15:11:31Z,)  tart-up  (The New York Times,)  (http://bits.blogs.nytimes.com/2010/09/23/inst...            17  [Instapaper still lacks two essential tools th...            4.677          5.501\n",
        "6                                                 (,)                      ([(WINDOLF, Jim)],)    (article,)  [{u'name': u'persons', u'value': u'REYNOLDS, S...  (RIP IT UP AND START AGAIN Postpunk 1978-1984....   (1017.0,)       (6,)  (2006-03-05T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2006/03/05/books/revie...             0                                                 []            4.668          5.500\n",
        "7   (Tyler Cowen Economic Scene column on why US h...                      ([(COWEN, Tyler)],)    (article,)  [{u'name': u'persons', u'value': u'CASNOCHA, B...  (Michael S. Dell (of Dell Inc.) sold stamps to...    (971.0,)       (3,)  (2007-06-14T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2007/06/14/business/14...             0                                                 []            4.706          5.493\n",
        "8   (Eugenie Allen reviews book The Comeback: Seve...                    ([(ALLEN, Eugenie)],)    (article,)  [{u'name': u'persons', u'value': u'KELLER, EMM...  (THE COMEBACK Seven Stories of Women Who Went ...    (914.0,)      (13,)  (2008-09-21T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2008/09/21/books/revie...             0                                                 []            4.700          5.490\n",
        "9   (United Talent Agency will announce creation o...                                ([None],)    (article,)  [{u'name': u'glocations', u'value': u'NEW YORK...  (The United Talent Agency plans today to annou...     (63.0,)       (5,)  (2007-09-10T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2007/09/10/business/me...             0                                                 []            4.779          5.502\n",
        "10  (David Carr reviews book Crazy Like a Fox: The...                       ([(Carr, David)],)    (article,)  [{u'name': u'persons', u'value': u'COLLINS, SC...  (CRAZY LIKE A FOX The Inside Story of How Fox ...   (1129.0,)      (34,)  (2004-04-18T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2004/04/18/books/from-...             0                                                 []            4.750          5.500\n",
        "11  (Some small companies claim that larger ones a...  ([(LATTMAN, Peter), (MARTIN, Andrew)],)    (article,)  [{u'name': u'persons', u'value': u'PRUNIER, CH...  (A light bulb went off for Christy Prunier whi...   (1315.0,)       (1,)  (2011-09-29T00:00:00Z,)  tart-up  (The New York Times,)  (http://query.nytimes.com/gst/fullpage.html?re...             0                                                 []            4.743          5.503\n",
        "12  (Jacob Heilbrunn reviews books Soulless: Ann C...                  ([(Heilbrunn, Jacob)],)    (article,)  [{u'name': u'persons', u'value': u'UNANIMOUS'}...  (SOULLESS Ann Coulter and the Right-Wing Churc...   (1287.0,)      (15,)  (2006-11-26T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2006/11/26/books/Heilb...             0                                                 []            4.790          5.495\n",
        "13  (Timeline shows significant moments in the his...                                ([None],)    (article,)                                                 []  (1946 Electronic Control Co. (now Unisys)J. Pr...    (328.0,)      (10,)  (2012-07-22T00:00:00Z,)  tart-up  (The New York Times,)  (http://query.nytimes.com/gst/fullpage.html?re...             0                                                 []            4.839          5.504\n",
        "14                                                (,)                    ([(Borowitz, Andy)],)    (article,)                                                 []  (Dear Mom and Dad, Camp is AWESOME!!! There's ...    (325.0,)      (29,)  (2000-07-13T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2000/07/13/opinion/sta...             0                                                 []            4.815          5.522\n",
        "15  (Foursquare will introduce its largest partner...                    ([(WORTHAM, Jenna)],)    (article,)  [{u'name': u'persons', u'value': u'LATTMAN, PE...  (When the New York start-up Foursquare Labs ma...   (1009.0,)       (1,)  (2011-06-23T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2011/06/23/technology/...             0                                                 []            4.813          5.520\n",
        "16  (Many young technology companies have slashed ...                    ([(MILLER, Claire)],)    (article,)  [{u'name': u'organizations', u'value': u'SEQUO...  (In October, when Wall Street was already wall...   (1119.0,)       (1,)  (2009-04-08T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2009/04/08/technology/...             0                                                 []            4.832          5.494\n",
        "17  (Maxim Group pulls out as underwriter of start...                     ([(HANSELL, Saul)],)    (article,)  [{u'name': u'persons', u'value': u'ROUSSO, MAR...  (Three years ago, at a news conference at Tave...   (1312.0,)       (1,)  (2007-08-22T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2007/08/22/technology/...             0                                                 []            4.852          5.496\n",
        "18                                                (,)               ([(Blackerby, Jeffries)],)    (article,)                                                 []  (For those who like the idea of renting a vill...    (100.0,)      (24,)  (2006-11-19T00:00:00Z,)  tart-up  (The New York Times,)  (http://query.nytimes.com/gst/fullpage.html?re...             0                                                 []            4.855          5.498\n",
        "19  (The Boss column features StumbleUpon chief ex...                     ([(CAMP, Garrett)],)    (article,)  [{u'value': u'StumbleUpon', u'is_major': u'Y',...  (Garrett Camp of StumbleUpon describes what it...    (660.0,)      (10,)  (2011-10-23T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2011/10/23/jobs/23boss...             0                                                 []            4.847          5.496\n",
        "20  (Article on special breed of small-business ow...                       ([(FIELD, Anne)],)    (article,)  [{u'name': u'persons', u'value': u'YELLEN, HOW...  (Howard Yellen has recently found what promise...   (1178.0,)       (6,)  (2003-12-11T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2003/12/11/business/sm...             0                                                 []            4.808          5.507\n",
        "21                                                (,)                    ([(WORTHAM, Jenna)],)    (article,)  [{u'rank': u'3', u'name': u'persons', u'value'...  (Just four months after a much-hyped introduct...   (1466.0,)       (1,)  (2012-10-19T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2012/10/19/technology/...             0                                                 []            4.813          5.505\n",
        "22  (Think registering your business sounds like a...                                ([None],)   (blogpost,)                                                 []  (Think registering your business sounds like a...   (1192.0,)        (,)  (2010-04-01T00:49:48Z,)  tart-up  (The New York Times,)  (http://dealbook.nytimes.com/2010/04/01/how-to...             0                                                 []            4.826          5.507\n",
        "23  (Six months after Egyptian uprising, business ...                  ([(SELIGSON, Hannah)],)    (article,)  [{u'name': u'persons', u'value': u'GERBER, SCO...  (LIKE so many other young people in Cairo, Yas...   (1794.0,)       (1,)  (2011-07-17T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2011/07/17/business/gl...             0                                                 []            4.813          5.502\n",
        "24  (Article on Golden Baseball League, formed two...                      ([(RIVLIN, Gary)],)    (article,)  [{u'name': u'persons', u'value': u'OUTCALT, KE...  (IT was the sixth inning of a one-run game bet...   (3167.0,)       (1,)  (2006-07-09T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2006/07/09/business/yo...             0                                                 []            4.813          5.504\n",
        "25  (Legal battle between Corbis and Infoflows is ...                       ([(LOHR, Steve)],)    (article,)  [{u'name': u'persons', u'value': u'GATES, BILL...  (Technology start-ups and big companies work t...   (1222.0,)       (6,)  (2010-07-19T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2010/07/19/technology/...             0                                                 []            4.829          5.509\n",
        "26  (Interview with Gary Doan, founder and chief e...                     ([(FLYNN, Laurie)],)    (article,)  [{u'name': u'persons', u'value': u'DOAN, GARY'...  (For Gary Doan, the chief executive of a start...    (700.0,)       (4,)  (2004-03-29T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2004/03/29/business/te...             0                                                 []            4.837          5.490\n",
        "27  (For Thomas L. Friedman, reading the news that...                                ([None],)   (blogpost,)                                                 []  (For Thomas L. Friedman, reading the news that...    (866.0,)        (,)  (2009-02-23T06:49:48Z,)  tart-up  (The New York Times,)  (http://dealbook.nytimes.com/2009/02/23/start-...             0                                                 []            4.830          5.485\n",
        "28                                                (,)                     ([(CAMP, Garrett)],)    (article,)  [{u'name': u'organizations', u'value': u'STUMB...  (I'M from Calgary, Alberta. My mother was an a...    (668.0,)      (10,)  (2011-10-23T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2011/10/23/jobs/23boss...             0                                                 []            4.809          5.490\n",
        "29                                                (,)                   ([(FREEDMAN, David)],)    (article,)                                                 []  (Hari Kaur has been teaching yoga for 20 years...   (1152.0,)       (8,)  (2011-09-01T00:00:00Z,)  tart-up  (The New York Times,)  (http://query.nytimes.com/gst/fullpage.html?re...             0                                                 []            4.775          5.490"
       ]
      }
     ],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xdict['all comments'][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 179,
       "text": [
        "[u'If they are smart, they will get the actor who played Andy Botwin to do their promos!  I miss both him and \"Andy\" - genius humor and prophetic as you point out!',\n",
        " u'Thank You !<br/>I could not figure out why it din\\'t sound so \"new\" to me.',\n",
        " u\"I've lived, off and on, with only a bicycle for transportation, for the last 34 years. Out of those 34 years, I've had a truck for 7 and a motorcycle for 10. So for the other 17 years, I had only a bicycle (in hilly Central Texas....)<br/>After a rollerskate kneedrop at the age of 55, surgery, and the onset of arthritis, I thought my biking days were over. I read about a company called Clean Republics that manufactures a kit (A wheel with an electric motor, silent; some connecting wires, a trigger switch, and a lithium battery that hangs under the rear of the seat.)<br/>It changed my life. I have a motorcycle now (no car or truck) and this ebike. I mounted the front wheel onto my Fireman's Texas Cruzer and never looked back. I live in a very small town 35 miles north of Austin, and use my bike to run all my errands and in town visiting. On one Sunday afternoon when the buses didn't run, stranded in Austin with my bike, I took a deep breath and headed north. I had to refuel the batter for a bit at Starbucks in Cedar Park, but I made it home before dark and in one piece. I pedaled with it, of course, all the way, but would never have made it without the electric wheel. Mine can go too fast for my comfort, but I do enjoy buzzing the 10 year old boys who can't figure out how that old lady is lapping them.\",\n",
        " u\"Don't mopeds take gas?  Well, duh . . .\",\n",
        " u'The worst weight on a bicycle is in fact rotating weight, as racers know...',\n",
        " u'This seems like an interesting idea, and it would definitely make it easier to ride longer distances, but at that point, why not just buy a moped? I also wonder how efficient it is. It gets its charge from braking downhill and pedaling in reverse, but no one pedals in reverse on a regular basis, leaving downhill riding as its only source of energy. And since you can\\u2019t plug it in to charge it, you better be sure you have a good charge all the time. It would not end well if you were pedaling up a steep hill with little to no exertion when BAM and the motor shuts off, causing you to fall back off the bike.',\n",
        " u'Back in the day, I experimented with a home brew E-bike.  Ford starter motor and a 60 lb. marine 12V battery in a \"Bob\" one wheel trailer.  Zero to 40 in a flash.  Motor overheated after a half mile tho\\' , since starter motors aren\\'t too efficient.  Great fun while the belt lasted.<br/><br/>The \"Wheel\" looks like it uses a pancake motor, which is the way to go, efficiency wise.  Lots of Chinese versions out there.',\n",
        " u'while the hovding helmet is horribly expensive and only serves once!',\n",
        " u'and this is not the only invention that will turn bicycle rides into a safer and more comfortable experience. I have recently reviewed three more gadgets for bikes: <a href=\"http://www.digital-commute.com/3-bicycle-gadgets-safe-light-ride-future/\" title=\"http://www.digital-commute.com/3-bicycle-gadgets-safe-light-ride-future/\" target=\"_blank\">http://www.digital-commute.com/3-bicycle-gadgets-safe-light-ride-future/</a>',\n",
        " u'Analog! Like AM radio, dude! Sheesh. ',\n",
        " u'At mile 16 it will implode.  This whole story is full of beans. Just buy a Specialized Turbo.  ',\n",
        " u'Thanks but the \"goat\" is clearly a dog and the \"bike\" is an actual motorcycle (not just a moped) replete with front suspension and headlight.',\n",
        " u'This is a difficult article to follow, as shown by many of the comments.<br/><br/>First, nothing so sensational as reinvention is happening here. It is a potential improvement on existing hybrid bicycle power technology, but nothing more (unless you consider adding the gimmick of an app as revolutionary). From a business strategy standpoint, it falls in the category of \"better mousetrap\".<br/><br/>Second, missing is basic technical information of obvious concern to riders, like weight, charging options, and that nagging \"wheel will last for 15 miles\" statement. And, of course, the anticipated retail price.<br/><br/>Third, is it designed for San Francisco streets? Or is there only enough \"e\" to handle the bumps of Brooklyn hills? Not looking for specifics - just need a basic idea of how much better this fantastic MIT invention is than the existing hybrid e-bikes out there since it really doesn\\'t sound that much different.<br/><br/>Most importantly, how does someone who obviously didn\\'t bother to do a single bit of research on the subject, get such a poorly written article (with an absurd headline) published in the NY Times? ',\n",
        " u'Quote also mentions GREAT distances that are quiet large\". Isn\\'t that a redundancy? The pedals may be efficient but his grammar is not.',\n",
        " u\"I doubt that this is intended for occasional long distance bicycle riders.  This sort of technology will encourage those who might ride to work if it weren't for a challenging terrain.  Sure, it won't be as serious an exercise choice but it could get some exercising more often.  I doubt my daughter that rode across the US for MS last year would get one but I might.  I have considered getting a power assisted bike in the past.  Not sure how different or how improved this technology would be.  \",\n",
        " u\"Gee, going downhill is most fun when not using the brakes. Where I ride in suburban Chicago there are plenty of trails through Forest Preserves and the like where the terrain might give you a 1/2 mile uphill ride followed by the downhill ride but not so steep that I need to break from, maybe a 20mph segment. If I don't brake do I lose regenerating power and thus shorten the battery life?\",\n",
        " u\"As a long time, and occasional long distance, bicycle rider, I do not think I would want to be always pedaling at the same cadence. Besides being boring, I don't feel it would be as physically beneficial to my body. But then again, I also refuse to use cruise control when I'm driving.\",\n",
        " u'Yes! The article describes the recharge!',\n",
        " u'Similar technology has been available for wheelchairs for years, and it is truly fantastic, particularly for sore shoulders, long distances, etc. Price is breathtaking though. <a href=\"http://www.frankmobility.com/e-motion.php\" title=\"http://www.frankmobility.com/e-motion.php\" target=\"_blank\">http://www.frankmobility.com/e-motion.php</a>',\n",
        " u'Well, as far as direction, going up &amp; down the road works for me, too<br/><br/>The design, perhaps, needs a charge option, where one need not ride to re-charge.',\n",
        " u'At our bike shop in NYC, we hear the \"twin terrors\" of biking all the time: A) it will get stolen and B) I\\'m afraid of getting hit by a car. I\\'m not sure I\\'ve ever heard \"I don\\'t have the stamina,\" even from elderly customers, because the \"analog\" bicycle (as opposed to the \"digital\" automobile?) is a wonderfully efficient machine and humans have powerful thigh muscles. <br/><br/>The good news is that \"twin terror\" A can be mostly solved by simply using a good lock (the vast majority of New Yorkers use flimsy locks, making it a field day for bike thieves). Solving \"terror B\" will require the help of the government, but at least there is massive room for improvement, given that the NYPD currently makes zero effort to curb reckless driving and bicycling infrastructure is just getting off the ground in most places. ',\n",
        " u'\"distances that are quiet large\"? I think you meant to quote him as saying \"quite large.\"',\n",
        " u'I\\'ve got to agree with you. We need to always remind people of the safety and congestion benefits of moving urban drivers from cars to bicycles.<br/>and such strange writing. The analog quote you provide certainly seems strange to me, I think the writer believes analog means not electronic.<br/>Similarly, \"The company said the wheel will last for 15 miles in each direction and will fit on most standard bicycles.\" is also strange. Presumably this is a statement about battery life, but it isn\\'t written that way. And no comment from the author about how variable this should be for riders of varying weights on varying terrain. And 15 miles in each direction allows you to ride 60 miles if you break it into 4 different directions?',\n",
        " u'\"Reinvents the Wheel\" is a bit sensationalist. Slipping an electric motor into \"an existing analog product: the bicycle\" has been done since the 1800s. It sounds like the only major difference between this and any standard pedal-assist e-bike kit (\"The China Wheel\") is that the battery is built into the wheel. That might make it look more iPhone-y, but where are you supposed to plug it in to recharge it? With a standard e-bike, you can yank out the battery and bring it inside to charge and even have multiple batteries that you swap out. Recharging through braking (which is also common with current e-bike kits) only prolongs the battery life a bit. Call me a skeptic, but am I missing something? <br/><br/>Regardless, any effort to promote and grow the market for e-bikes is a good thing. Electric-assist bicycles are a great solution for transportation in city areas and their widespread adoption should be encouraged.',\n",
        " u'At some level, it\\'s like those bicycles I used to drive on my summer vacation trips to the ancestral village in Odisha where they had these little little mechanism brushing against the rear wheel which generated electricity to light up a bulb at the front of the bicycle.<br/><br/>It was very handy during the evenings of course as villages in India do not have paved roads or street lights. Shows how \\'important\\' even a full moon can be to provide that little bit of light.<br/><br/>And the moon shines more brightly during these October/November months, does not it?<br/><br/>Ah. The bicycle mechanism is called a \\'dynamo\\', right? My Elec. engg. knowledge sucks, I guess.<br/><br/>:-)<br/><br/>Anyway, those were like 20 years ago. Now a days I don\\'t think people in villages drive that many bicycles. Many have become \\'rich\\' and graduated to 100 cc two-wheelers from Hero Honda and Bajaj.<br/><br/>India is a crazy land of course where an ENTIRE family of five can \\'adjust\\' on a rather flimsy looking bike.<br/><br/>Here\\'s a photo of such a family apparently travelling on some important \\'mission.\\'<br/><br/>Don\\'t miss the goat in the bag.<br/><br/>:-)<br/><br/><a href=\"http://explainingindia.blogspot.in/2012/06/top-10-crazy-facts-about-india.html\" title=\"http://explainingindia.blogspot.in/2012/06/top-10-crazy-facts-about-india.html\" target=\"_blank\">http://explainingindia.blogspot.in/2012/06/top-10-crazy-facts-about-indi...</a>']"
       ]
      }
     ],
     "prompt_number": 179
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "commentsinpost = [(val) for (i, val) in enumerate(xdict['all comments'])]\n",
      "\n",
      "commentsinpost[3] >0 \n",
      "    \n",
      "xdict['all comments'][0]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 206,
       "text": [
        "[u'If they are smart, they will get the actor who played Andy Botwin to do their promos!  I miss both him and \"Andy\" - genius humor and prophetic as you point out!',\n",
        " u'Thank You !<br/>I could not figure out why it din\\'t sound so \"new\" to me.',\n",
        " u\"I've lived, off and on, with only a bicycle for transportation, for the last 34 years. Out of those 34 years, I've had a truck for 7 and a motorcycle for 10. So for the other 17 years, I had only a bicycle (in hilly Central Texas....)<br/>After a rollerskate kneedrop at the age of 55, surgery, and the onset of arthritis, I thought my biking days were over. I read about a company called Clean Republics that manufactures a kit (A wheel with an electric motor, silent; some connecting wires, a trigger switch, and a lithium battery that hangs under the rear of the seat.)<br/>It changed my life. I have a motorcycle now (no car or truck) and this ebike. I mounted the front wheel onto my Fireman's Texas Cruzer and never looked back. I live in a very small town 35 miles north of Austin, and use my bike to run all my errands and in town visiting. On one Sunday afternoon when the buses didn't run, stranded in Austin with my bike, I took a deep breath and headed north. I had to refuel the batter for a bit at Starbucks in Cedar Park, but I made it home before dark and in one piece. I pedaled with it, of course, all the way, but would never have made it without the electric wheel. Mine can go too fast for my comfort, but I do enjoy buzzing the 10 year old boys who can't figure out how that old lady is lapping them.\",\n",
        " u\"Don't mopeds take gas?  Well, duh . . .\",\n",
        " u'The worst weight on a bicycle is in fact rotating weight, as racers know...',\n",
        " u'This seems like an interesting idea, and it would definitely make it easier to ride longer distances, but at that point, why not just buy a moped? I also wonder how efficient it is. It gets its charge from braking downhill and pedaling in reverse, but no one pedals in reverse on a regular basis, leaving downhill riding as its only source of energy. And since you can\\u2019t plug it in to charge it, you better be sure you have a good charge all the time. It would not end well if you were pedaling up a steep hill with little to no exertion when BAM and the motor shuts off, causing you to fall back off the bike.',\n",
        " u'Back in the day, I experimented with a home brew E-bike.  Ford starter motor and a 60 lb. marine 12V battery in a \"Bob\" one wheel trailer.  Zero to 40 in a flash.  Motor overheated after a half mile tho\\' , since starter motors aren\\'t too efficient.  Great fun while the belt lasted.<br/><br/>The \"Wheel\" looks like it uses a pancake motor, which is the way to go, efficiency wise.  Lots of Chinese versions out there.',\n",
        " u'while the hovding helmet is horribly expensive and only serves once!',\n",
        " u'and this is not the only invention that will turn bicycle rides into a safer and more comfortable experience. I have recently reviewed three more gadgets for bikes: <a href=\"http://www.digital-commute.com/3-bicycle-gadgets-safe-light-ride-future/\" title=\"http://www.digital-commute.com/3-bicycle-gadgets-safe-light-ride-future/\" target=\"_blank\">http://www.digital-commute.com/3-bicycle-gadgets-safe-light-ride-future/</a>',\n",
        " u'Analog! Like AM radio, dude! Sheesh. ',\n",
        " u'At mile 16 it will implode.  This whole story is full of beans. Just buy a Specialized Turbo.  ',\n",
        " u'Thanks but the \"goat\" is clearly a dog and the \"bike\" is an actual motorcycle (not just a moped) replete with front suspension and headlight.',\n",
        " u'This is a difficult article to follow, as shown by many of the comments.<br/><br/>First, nothing so sensational as reinvention is happening here. It is a potential improvement on existing hybrid bicycle power technology, but nothing more (unless you consider adding the gimmick of an app as revolutionary). From a business strategy standpoint, it falls in the category of \"better mousetrap\".<br/><br/>Second, missing is basic technical information of obvious concern to riders, like weight, charging options, and that nagging \"wheel will last for 15 miles\" statement. And, of course, the anticipated retail price.<br/><br/>Third, is it designed for San Francisco streets? Or is there only enough \"e\" to handle the bumps of Brooklyn hills? Not looking for specifics - just need a basic idea of how much better this fantastic MIT invention is than the existing hybrid e-bikes out there since it really doesn\\'t sound that much different.<br/><br/>Most importantly, how does someone who obviously didn\\'t bother to do a single bit of research on the subject, get such a poorly written article (with an absurd headline) published in the NY Times? ',\n",
        " u'Quote also mentions GREAT distances that are quiet large\". Isn\\'t that a redundancy? The pedals may be efficient but his grammar is not.',\n",
        " u\"I doubt that this is intended for occasional long distance bicycle riders.  This sort of technology will encourage those who might ride to work if it weren't for a challenging terrain.  Sure, it won't be as serious an exercise choice but it could get some exercising more often.  I doubt my daughter that rode across the US for MS last year would get one but I might.  I have considered getting a power assisted bike in the past.  Not sure how different or how improved this technology would be.  \",\n",
        " u\"Gee, going downhill is most fun when not using the brakes. Where I ride in suburban Chicago there are plenty of trails through Forest Preserves and the like where the terrain might give you a 1/2 mile uphill ride followed by the downhill ride but not so steep that I need to break from, maybe a 20mph segment. If I don't brake do I lose regenerating power and thus shorten the battery life?\",\n",
        " u\"As a long time, and occasional long distance, bicycle rider, I do not think I would want to be always pedaling at the same cadence. Besides being boring, I don't feel it would be as physically beneficial to my body. But then again, I also refuse to use cruise control when I'm driving.\",\n",
        " u'Yes! The article describes the recharge!',\n",
        " u'Similar technology has been available for wheelchairs for years, and it is truly fantastic, particularly for sore shoulders, long distances, etc. Price is breathtaking though. <a href=\"http://www.frankmobility.com/e-motion.php\" title=\"http://www.frankmobility.com/e-motion.php\" target=\"_blank\">http://www.frankmobility.com/e-motion.php</a>',\n",
        " u'Well, as far as direction, going up &amp; down the road works for me, too<br/><br/>The design, perhaps, needs a charge option, where one need not ride to re-charge.',\n",
        " u'At our bike shop in NYC, we hear the \"twin terrors\" of biking all the time: A) it will get stolen and B) I\\'m afraid of getting hit by a car. I\\'m not sure I\\'ve ever heard \"I don\\'t have the stamina,\" even from elderly customers, because the \"analog\" bicycle (as opposed to the \"digital\" automobile?) is a wonderfully efficient machine and humans have powerful thigh muscles. <br/><br/>The good news is that \"twin terror\" A can be mostly solved by simply using a good lock (the vast majority of New Yorkers use flimsy locks, making it a field day for bike thieves). Solving \"terror B\" will require the help of the government, but at least there is massive room for improvement, given that the NYPD currently makes zero effort to curb reckless driving and bicycling infrastructure is just getting off the ground in most places. ',\n",
        " u'\"distances that are quiet large\"? I think you meant to quote him as saying \"quite large.\"',\n",
        " u'I\\'ve got to agree with you. We need to always remind people of the safety and congestion benefits of moving urban drivers from cars to bicycles.<br/>and such strange writing. The analog quote you provide certainly seems strange to me, I think the writer believes analog means not electronic.<br/>Similarly, \"The company said the wheel will last for 15 miles in each direction and will fit on most standard bicycles.\" is also strange. Presumably this is a statement about battery life, but it isn\\'t written that way. And no comment from the author about how variable this should be for riders of varying weights on varying terrain. And 15 miles in each direction allows you to ride 60 miles if you break it into 4 different directions?',\n",
        " u'\"Reinvents the Wheel\" is a bit sensationalist. Slipping an electric motor into \"an existing analog product: the bicycle\" has been done since the 1800s. It sounds like the only major difference between this and any standard pedal-assist e-bike kit (\"The China Wheel\") is that the battery is built into the wheel. That might make it look more iPhone-y, but where are you supposed to plug it in to recharge it? With a standard e-bike, you can yank out the battery and bring it inside to charge and even have multiple batteries that you swap out. Recharging through braking (which is also common with current e-bike kits) only prolongs the battery life a bit. Call me a skeptic, but am I missing something? <br/><br/>Regardless, any effort to promote and grow the market for e-bikes is a good thing. Electric-assist bicycles are a great solution for transportation in city areas and their widespread adoption should be encouraged.',\n",
        " u'At some level, it\\'s like those bicycles I used to drive on my summer vacation trips to the ancestral village in Odisha where they had these little little mechanism brushing against the rear wheel which generated electricity to light up a bulb at the front of the bicycle.<br/><br/>It was very handy during the evenings of course as villages in India do not have paved roads or street lights. Shows how \\'important\\' even a full moon can be to provide that little bit of light.<br/><br/>And the moon shines more brightly during these October/November months, does not it?<br/><br/>Ah. The bicycle mechanism is called a \\'dynamo\\', right? My Elec. engg. knowledge sucks, I guess.<br/><br/>:-)<br/><br/>Anyway, those were like 20 years ago. Now a days I don\\'t think people in villages drive that many bicycles. Many have become \\'rich\\' and graduated to 100 cc two-wheelers from Hero Honda and Bajaj.<br/><br/>India is a crazy land of course where an ENTIRE family of five can \\'adjust\\' on a rather flimsy looking bike.<br/><br/>Here\\'s a photo of such a family apparently travelling on some important \\'mission.\\'<br/><br/>Don\\'t miss the goat in the bag.<br/><br/>:-)<br/><br/><a href=\"http://explainingindia.blogspot.in/2012/06/top-10-crazy-facts-about-india.html\" title=\"http://explainingindia.blogspot.in/2012/06/top-10-crazy-facts-about-india.html\" target=\"_blank\">http://explainingindia.blogspot.in/2012/06/top-10-crazy-facts-about-indi...</a>']"
       ]
      }
     ],
     "prompt_number": 206
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n"
       ]
      }
     ],
     "prompt_number": 222
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#SENTIMENT AND WORD LENGTH SCORES FOR COMMENTS\n",
      "cword_lengths = []\n",
      "csent_scores = []\n",
      "cavg_word = []\n",
      "cavg_sent = []\n",
      "\n",
      "for i, commentsinpost in enumerate(xdict['all comments']):\n",
      "    if commentsinpost != []:\n",
      "        for comment in commentsinpost:\n",
      "            print \"analyzing post:\", i\n",
      "            for word in comment.split(' '):\n",
      "                if len(word) >0:\n",
      "                    cword_lengths.append(len(word))\n",
      "                for x, entry in sentiment.iterrows():\n",
      "                    if word == entry['word']:\n",
      "                        #print \"analyzing word in database:\", word\n",
      "                        csent_scores.append(entry['happiness_average'])\n",
      "        ##averge for article\n",
      "        cavg_sent.append((i, round(np.mean(csent_scores),3))) #link article index to scores and lengths\n",
      "        cavg_word.append((i, round(np.mean(cword_lengths),3)))   \n",
      "\n",
      "    else:\n",
      "        print \"missing comments:\", i\n",
      "        cavg_sent.append((i,0))\n",
      "        cavg_word.append((i,0))\n",
      "        \n",
      "\n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "analyzing post: 0\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "missing comments:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "missing comments: 3\n",
        "analyzing post: 4\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "analyzing post:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "missing comments:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "missing comments: 7\n",
        "missing comments: 8\n",
        "missing comments: 9\n",
        "missing comments: 10\n",
        "missing comments: 11\n",
        "missing comments: 12\n",
        "missing comments: 13\n",
        "missing comments: 14\n",
        "missing comments: 15\n",
        "missing comments: 16\n",
        "missing comments: 17\n",
        "missing comments: 18\n",
        "missing comments: 19\n",
        "missing comments: 20\n",
        "missing comments: 21\n",
        "missing comments: 22\n",
        "missing comments: 23\n",
        "missing comments: 24\n",
        "missing comments: 25\n",
        "missing comments: 26\n",
        "missing comments: 27\n",
        "missing comments: 28\n",
        "missing comments: 29\n"
       ]
      }
     ],
     "prompt_number": 223
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cavg_sent"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 224,
       "text": [
        "[(0, 5.347),\n",
        " (1, 5.398),\n",
        " (2, 0),\n",
        " (3, 0),\n",
        " (4, 5.377),\n",
        " (5, 5.374),\n",
        " (6, 0),\n",
        " (7, 0),\n",
        " (8, 0),\n",
        " (9, 0),\n",
        " (10, 0),\n",
        " (11, 0),\n",
        " (12, 0),\n",
        " (13, 0),\n",
        " (14, 0),\n",
        " (15, 0),\n",
        " (16, 0),\n",
        " (17, 0),\n",
        " (18, 0),\n",
        " (19, 0),\n",
        " (20, 0),\n",
        " (21, 0),\n",
        " (22, 0),\n",
        " (23, 0),\n",
        " (24, 0),\n",
        " (25, 0),\n",
        " (26, 0),\n",
        " (27, 0),\n",
        " (28, 0),\n",
        " (29, 0)]"
       ]
      }
     ],
     "prompt_number": 224
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##COMBINES COMMENTS ATTRIBUTES WITH EXISTING DATAFRAME FOR COMMENTS##\n",
      "\n",
      "alldf3 = dfdict.copy()\n",
      "\n",
      "tindex = [i[0] for i in cavg_sent]\n",
      "tvalue = [i[1] for i in cavg_sent]\n",
      "#cavgdf = pd.DataFrame(cavg_sent, index = cavg_sent[0])\n",
      "\n",
      "tindex1 = [i[0] for i in cavg_word]\n",
      "tvalue1 = [i[1] for i in cavg_word]\n",
      "\n",
      "cdf = pd.DataFrame(tvalue, index= tindex, columns=['avg comment sentiment'])\n",
      "cdf1 = pd.DataFrame(tvalue1, index= tindex1, columns=['avg comment word length'])\n",
      "\n",
      "\n",
      "##ADDS ARTICLE SENTIMENT AND WORD LENGTH INTO EXISTING DATAFRAME \n",
      "dfdict['avg word length'] = avg_word\n",
      "dfdict['avg sentiment'] = avg_sent \n",
      "trimmed_post_df = dfdict[dfdict['post length'] > 1]\n",
      "trimmed_post_df = dfdict[dfdict['avg word length'] > 0]\n",
      "trimmed_post_df = dfdict[dfdict['avg sentiment'] >0]\n",
      "trimmed_post_df = trimmed_post_df.fillna(value=0)\n",
      "trimmed_post_df\n",
      "\n",
      "trimmed_post_df['post length'] = [i[0] for i in trimmed_post_df['post length']]\n",
      "trimmed_post_df['post length']\n",
      "trimmed_post_df = trimmed_post_df.join(cdf)\n",
      "trimmed_post_df = trimmed_post_df.join(cdf1)\n",
      "trimmed_post_df\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>abstract</th>\n",
        "      <th>author</th>\n",
        "      <th>document type</th>\n",
        "      <th>keywords</th>\n",
        "      <th>lead_paragraph</th>\n",
        "      <th>post length</th>\n",
        "      <th>print_page</th>\n",
        "      <th>pub_date</th>\n",
        "      <th>s</th>\n",
        "      <th>source</th>\n",
        "      <th>web_url</th>\n",
        "      <th>num comments</th>\n",
        "      <th>all comments</th>\n",
        "      <th>avg word length</th>\n",
        "      <th>avg sentiment</th>\n",
        "      <th>avg comment sentiment</th>\n",
        "      <th>avg comment word length</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td> (Superpedestrian announced Monday that it will...</td>\n",
        "      <td>                     ([(BILTON, Nick)],)</td>\n",
        "      <td> (blogpost,)</td>\n",
        "      <td> [{u'value': u'Superpedestrian Inc', u'name': u...</td>\n",
        "      <td>                                           (None,)</td>\n",
        "      <td>  425</td>\n",
        "      <td>   (,)</td>\n",
        "      <td> (2013-10-21T20:59:33Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://bits.blogs.nytimes.com/2013/10/21/star...</td>\n",
        "      <td> 96</td>\n",
        "      <td> [If they are smart, they will get the actor wh...</td>\n",
        "      <td> 5.571</td>\n",
        "      <td> 5.426</td>\n",
        "      <td> 5.347</td>\n",
        "      <td> 5.094</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td> (Thomas L Friedman Op-Ed column maintains that...</td>\n",
        "      <td>                 ([(FRIEDMAN, Thomas)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'CASNOCHA, B...</td>\n",
        "      <td> (The rise in the unemployment rate last month ...</td>\n",
        "      <td>  892</td>\n",
        "      <td> (27,)</td>\n",
        "      <td> (2011-07-13T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2011/07/13/opinion/13f...</td>\n",
        "      <td> 40</td>\n",
        "      <td> [It seems to me that what we're seeing is a ch...</td>\n",
        "      <td> 4.774</td>\n",
        "      <td> 5.480</td>\n",
        "      <td> 5.398</td>\n",
        "      <td> 4.980</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td> (David Grubbs letter comments on Jim Windolf M...</td>\n",
        "      <td>                               ([None],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'WINDOLF, JI...</td>\n",
        "      <td> (To the Editor: After reading Jim Windolf's re...</td>\n",
        "      <td>   64</td>\n",
        "      <td>  (6,)</td>\n",
        "      <td> (2006-03-19T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://query.nytimes.com/gst/fullpage.html?re...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.796</td>\n",
        "      <td> 5.456</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td> (Harry Hurt III reviews book My Start-Up Life:...</td>\n",
        "      <td>                      ([(HURT, Harry)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'CASNOCHA, B...</td>\n",
        "      <td> (LORD, I loved being 19. If I had the chance t...</td>\n",
        "      <td>  992</td>\n",
        "      <td>  (7,)</td>\n",
        "      <td> (2007-06-17T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2007/06/17/business/yo...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.628</td>\n",
        "      <td> 5.501</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td> (Across the globe, venture-capital infusions f...</td>\n",
        "      <td>                      ([(WOODY, Todd)],)</td>\n",
        "      <td> (blogpost,)</td>\n",
        "      <td> [{u'rank': u'4', u'name': u'glocations', u'val...</td>\n",
        "      <td>           (Has the green tech recovery stalled?,)</td>\n",
        "      <td>  505</td>\n",
        "      <td>   (,)</td>\n",
        "      <td> (2010-10-01T15:13:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://green.blogs.nytimes.com/2010/10/01/gre...</td>\n",
        "      <td> 12</td>\n",
        "      <td> [News Flash - The boys at Big Oil and their me...</td>\n",
        "      <td> 4.633</td>\n",
        "      <td> 5.509</td>\n",
        "      <td> 5.377</td>\n",
        "      <td> 5.022</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td> (Marco Arment, the chief technology officer at...</td>\n",
        "      <td>                     ([(BILTON, Nick)],)</td>\n",
        "      <td> (blogpost,)</td>\n",
        "      <td> [{u'rank': u'5', u'name': u'organizations', u'...</td>\n",
        "      <td> (On Tuesday\u00a0Marco Arment, the chief technology...</td>\n",
        "      <td>  394</td>\n",
        "      <td>   (,)</td>\n",
        "      <td> (2010-09-23T15:11:31Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://bits.blogs.nytimes.com/2010/09/23/inst...</td>\n",
        "      <td> 17</td>\n",
        "      <td> [Instapaper still lacks two essential tools th...</td>\n",
        "      <td> 4.677</td>\n",
        "      <td> 5.501</td>\n",
        "      <td> 5.374</td>\n",
        "      <td> 4.977</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td>                                               (,)</td>\n",
        "      <td>                     ([(WINDOLF, Jim)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'REYNOLDS, S...</td>\n",
        "      <td> (RIP IT UP AND START AGAIN Postpunk 1978-1984....</td>\n",
        "      <td> 1017</td>\n",
        "      <td>  (6,)</td>\n",
        "      <td> (2006-03-05T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2006/03/05/books/revie...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.668</td>\n",
        "      <td> 5.500</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> (Tyler Cowen Economic Scene column on why US h...</td>\n",
        "      <td>                     ([(COWEN, Tyler)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'CASNOCHA, B...</td>\n",
        "      <td> (Michael S. Dell (of Dell Inc.) sold stamps to...</td>\n",
        "      <td>  971</td>\n",
        "      <td>  (3,)</td>\n",
        "      <td> (2007-06-14T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2007/06/14/business/14...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.706</td>\n",
        "      <td> 5.493</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td> (Eugenie Allen reviews book The Comeback: Seve...</td>\n",
        "      <td>                   ([(ALLEN, Eugenie)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'KELLER, EMM...</td>\n",
        "      <td> (THE COMEBACK Seven Stories of Women Who Went ...</td>\n",
        "      <td>  914</td>\n",
        "      <td> (13,)</td>\n",
        "      <td> (2008-09-21T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2008/09/21/books/revie...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.700</td>\n",
        "      <td> 5.490</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> (United Talent Agency will announce creation o...</td>\n",
        "      <td>                               ([None],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'glocations', u'value': u'NEW YORK...</td>\n",
        "      <td> (The United Talent Agency plans today to annou...</td>\n",
        "      <td>   63</td>\n",
        "      <td>  (5,)</td>\n",
        "      <td> (2007-09-10T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2007/09/10/business/me...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.779</td>\n",
        "      <td> 5.502</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> (David Carr reviews book Crazy Like a Fox: The...</td>\n",
        "      <td>                      ([(Carr, David)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'COLLINS, SC...</td>\n",
        "      <td> (CRAZY LIKE A FOX The Inside Story of How Fox ...</td>\n",
        "      <td> 1129</td>\n",
        "      <td> (34,)</td>\n",
        "      <td> (2004-04-18T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2004/04/18/books/from-...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.750</td>\n",
        "      <td> 5.500</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td> (Some small companies claim that larger ones a...</td>\n",
        "      <td> ([(LATTMAN, Peter), (MARTIN, Andrew)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'PRUNIER, CH...</td>\n",
        "      <td> (A light bulb went off for Christy Prunier whi...</td>\n",
        "      <td> 1315</td>\n",
        "      <td>  (1,)</td>\n",
        "      <td> (2011-09-29T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://query.nytimes.com/gst/fullpage.html?re...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.743</td>\n",
        "      <td> 5.503</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td> (Jacob Heilbrunn reviews books Soulless: Ann C...</td>\n",
        "      <td>                 ([(Heilbrunn, Jacob)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'UNANIMOUS'}...</td>\n",
        "      <td> (SOULLESS Ann Coulter and the Right-Wing Churc...</td>\n",
        "      <td> 1287</td>\n",
        "      <td> (15,)</td>\n",
        "      <td> (2006-11-26T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2006/11/26/books/Heilb...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.790</td>\n",
        "      <td> 5.495</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td> (Timeline shows significant moments in the his...</td>\n",
        "      <td>                               ([None],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> (1946 Electronic Control Co. (now Unisys)J. Pr...</td>\n",
        "      <td>  328</td>\n",
        "      <td> (10,)</td>\n",
        "      <td> (2012-07-22T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://query.nytimes.com/gst/fullpage.html?re...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.839</td>\n",
        "      <td> 5.504</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td>                                               (,)</td>\n",
        "      <td>                   ([(Borowitz, Andy)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> (Dear Mom and Dad, Camp is AWESOME!!! There's ...</td>\n",
        "      <td>  325</td>\n",
        "      <td> (29,)</td>\n",
        "      <td> (2000-07-13T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2000/07/13/opinion/sta...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.815</td>\n",
        "      <td> 5.522</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td> (Foursquare will introduce its largest partner...</td>\n",
        "      <td>                   ([(WORTHAM, Jenna)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'LATTMAN, PE...</td>\n",
        "      <td> (When the New York start-up Foursquare Labs ma...</td>\n",
        "      <td> 1009</td>\n",
        "      <td>  (1,)</td>\n",
        "      <td> (2011-06-23T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2011/06/23/technology/...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.813</td>\n",
        "      <td> 5.520</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td> (Many young technology companies have slashed ...</td>\n",
        "      <td>                   ([(MILLER, Claire)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'organizations', u'value': u'SEQUO...</td>\n",
        "      <td> (In October, when Wall Street was already wall...</td>\n",
        "      <td> 1119</td>\n",
        "      <td>  (1,)</td>\n",
        "      <td> (2009-04-08T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2009/04/08/technology/...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.832</td>\n",
        "      <td> 5.494</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td> (Maxim Group pulls out as underwriter of start...</td>\n",
        "      <td>                    ([(HANSELL, Saul)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'ROUSSO, MAR...</td>\n",
        "      <td> (Three years ago, at a news conference at Tave...</td>\n",
        "      <td> 1312</td>\n",
        "      <td>  (1,)</td>\n",
        "      <td> (2007-08-22T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2007/08/22/technology/...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.852</td>\n",
        "      <td> 5.496</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td>                                               (,)</td>\n",
        "      <td>              ([(Blackerby, Jeffries)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> (For those who like the idea of renting a vill...</td>\n",
        "      <td>  100</td>\n",
        "      <td> (24,)</td>\n",
        "      <td> (2006-11-19T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://query.nytimes.com/gst/fullpage.html?re...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.855</td>\n",
        "      <td> 5.498</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td> (The Boss column features StumbleUpon chief ex...</td>\n",
        "      <td>                    ([(CAMP, Garrett)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'value': u'StumbleUpon', u'is_major': u'Y',...</td>\n",
        "      <td> (Garrett Camp of StumbleUpon describes what it...</td>\n",
        "      <td>  660</td>\n",
        "      <td> (10,)</td>\n",
        "      <td> (2011-10-23T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2011/10/23/jobs/23boss...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.847</td>\n",
        "      <td> 5.496</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20</th>\n",
        "      <td> (Article on special breed of small-business ow...</td>\n",
        "      <td>                      ([(FIELD, Anne)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'YELLEN, HOW...</td>\n",
        "      <td> (Howard Yellen has recently found what promise...</td>\n",
        "      <td> 1178</td>\n",
        "      <td>  (6,)</td>\n",
        "      <td> (2003-12-11T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2003/12/11/business/sm...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.808</td>\n",
        "      <td> 5.507</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21</th>\n",
        "      <td>                                               (,)</td>\n",
        "      <td>                   ([(WORTHAM, Jenna)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'rank': u'3', u'name': u'persons', u'value'...</td>\n",
        "      <td> (Just four months after a much-hyped introduct...</td>\n",
        "      <td> 1466</td>\n",
        "      <td>  (1,)</td>\n",
        "      <td> (2012-10-19T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2012/10/19/technology/...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.813</td>\n",
        "      <td> 5.505</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22</th>\n",
        "      <td> (Think registering your business sounds like a...</td>\n",
        "      <td>                               ([None],)</td>\n",
        "      <td> (blogpost,)</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> (Think registering your business sounds like a...</td>\n",
        "      <td> 1192</td>\n",
        "      <td>   (,)</td>\n",
        "      <td> (2010-04-01T00:49:48Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://dealbook.nytimes.com/2010/04/01/how-to...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.826</td>\n",
        "      <td> 5.507</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23</th>\n",
        "      <td> (Six months after Egyptian uprising, business ...</td>\n",
        "      <td>                 ([(SELIGSON, Hannah)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'GERBER, SCO...</td>\n",
        "      <td> (LIKE so many other young people in Cairo, Yas...</td>\n",
        "      <td> 1794</td>\n",
        "      <td>  (1,)</td>\n",
        "      <td> (2011-07-17T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2011/07/17/business/gl...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.813</td>\n",
        "      <td> 5.502</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24</th>\n",
        "      <td> (Article on Golden Baseball League, formed two...</td>\n",
        "      <td>                     ([(RIVLIN, Gary)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'OUTCALT, KE...</td>\n",
        "      <td> (IT was the sixth inning of a one-run game bet...</td>\n",
        "      <td> 3167</td>\n",
        "      <td>  (1,)</td>\n",
        "      <td> (2006-07-09T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2006/07/09/business/yo...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.813</td>\n",
        "      <td> 5.504</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25</th>\n",
        "      <td> (Legal battle between Corbis and Infoflows is ...</td>\n",
        "      <td>                      ([(LOHR, Steve)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'GATES, BILL...</td>\n",
        "      <td> (Technology start-ups and big companies work t...</td>\n",
        "      <td> 1222</td>\n",
        "      <td>  (6,)</td>\n",
        "      <td> (2010-07-19T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2010/07/19/technology/...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.829</td>\n",
        "      <td> 5.509</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26</th>\n",
        "      <td> (Interview with Gary Doan, founder and chief e...</td>\n",
        "      <td>                    ([(FLYNN, Laurie)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'persons', u'value': u'DOAN, GARY'...</td>\n",
        "      <td> (For Gary Doan, the chief executive of a start...</td>\n",
        "      <td>  700</td>\n",
        "      <td>  (4,)</td>\n",
        "      <td> (2004-03-29T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2004/03/29/business/te...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.837</td>\n",
        "      <td> 5.490</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27</th>\n",
        "      <td> (For Thomas L. Friedman, reading the news that...</td>\n",
        "      <td>                               ([None],)</td>\n",
        "      <td> (blogpost,)</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> (For Thomas L. Friedman, reading the news that...</td>\n",
        "      <td>  866</td>\n",
        "      <td>   (,)</td>\n",
        "      <td> (2009-02-23T06:49:48Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://dealbook.nytimes.com/2009/02/23/start-...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.830</td>\n",
        "      <td> 5.485</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28</th>\n",
        "      <td>                                               (,)</td>\n",
        "      <td>                    ([(CAMP, Garrett)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td> [{u'name': u'organizations', u'value': u'STUMB...</td>\n",
        "      <td> (I'M from Calgary, Alberta. My mother was an a...</td>\n",
        "      <td>  668</td>\n",
        "      <td> (10,)</td>\n",
        "      <td> (2011-10-23T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://www.nytimes.com/2011/10/23/jobs/23boss...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.809</td>\n",
        "      <td> 5.490</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29</th>\n",
        "      <td>                                               (,)</td>\n",
        "      <td>                  ([(FREEDMAN, David)],)</td>\n",
        "      <td>  (article,)</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> (Hari Kaur has been teaching yoga for 20 years...</td>\n",
        "      <td> 1152</td>\n",
        "      <td>  (8,)</td>\n",
        "      <td> (2011-09-01T00:00:00Z,)</td>\n",
        "      <td> tart-up</td>\n",
        "      <td> (The New York Times,)</td>\n",
        "      <td> (http://query.nytimes.com/gst/fullpage.html?re...</td>\n",
        "      <td>  0</td>\n",
        "      <td>                                                []</td>\n",
        "      <td> 4.775</td>\n",
        "      <td> 5.490</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 242,
       "text": [
        "                                             abstract                                   author document type                                           keywords                                     lead_paragraph  post length print_page                 pub_date        s                 source                                            web_url  num comments                                       all comments  avg word length  avg sentiment  avg comment sentiment  avg comment word length\n",
        "0   (Superpedestrian announced Monday that it will...                      ([(BILTON, Nick)],)   (blogpost,)  [{u'value': u'Superpedestrian Inc', u'name': u...                                            (None,)          425        (,)  (2013-10-21T20:59:33Z,)  tart-up  (The New York Times,)  (http://bits.blogs.nytimes.com/2013/10/21/star...            96  [If they are smart, they will get the actor wh...            5.571          5.426                  5.347                    5.094\n",
        "1   (Thomas L Friedman Op-Ed column maintains that...                  ([(FRIEDMAN, Thomas)],)    (article,)  [{u'name': u'persons', u'value': u'CASNOCHA, B...  (The rise in the unemployment rate last month ...          892      (27,)  (2011-07-13T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2011/07/13/opinion/13f...            40  [It seems to me that what we're seeing is a ch...            4.774          5.480                  5.398                    4.980\n",
        "2   (David Grubbs letter comments on Jim Windolf M...                                ([None],)    (article,)  [{u'name': u'persons', u'value': u'WINDOLF, JI...  (To the Editor: After reading Jim Windolf's re...           64       (6,)  (2006-03-19T00:00:00Z,)  tart-up  (The New York Times,)  (http://query.nytimes.com/gst/fullpage.html?re...             0                                                 []            4.796          5.456                  0.000                    0.000\n",
        "3   (Harry Hurt III reviews book My Start-Up Life:...                       ([(HURT, Harry)],)    (article,)  [{u'name': u'persons', u'value': u'CASNOCHA, B...  (LORD, I loved being 19. If I had the chance t...          992       (7,)  (2007-06-17T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2007/06/17/business/yo...             0                                                 []            4.628          5.501                  0.000                    0.000\n",
        "4   (Across the globe, venture-capital infusions f...                       ([(WOODY, Todd)],)   (blogpost,)  [{u'rank': u'4', u'name': u'glocations', u'val...            (Has the green tech recovery stalled?,)          505        (,)  (2010-10-01T15:13:00Z,)  tart-up  (The New York Times,)  (http://green.blogs.nytimes.com/2010/10/01/gre...            12  [News Flash - The boys at Big Oil and their me...            4.633          5.509                  5.377                    5.022\n",
        "5   (Marco Arment, the chief technology officer at...                      ([(BILTON, Nick)],)   (blogpost,)  [{u'rank': u'5', u'name': u'organizations', u'...  (On Tuesday\u00a0Marco Arment, the chief technology...          394        (,)  (2010-09-23T15:11:31Z,)  tart-up  (The New York Times,)  (http://bits.blogs.nytimes.com/2010/09/23/inst...            17  [Instapaper still lacks two essential tools th...            4.677          5.501                  5.374                    4.977\n",
        "6                                                 (,)                      ([(WINDOLF, Jim)],)    (article,)  [{u'name': u'persons', u'value': u'REYNOLDS, S...  (RIP IT UP AND START AGAIN Postpunk 1978-1984....         1017       (6,)  (2006-03-05T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2006/03/05/books/revie...             0                                                 []            4.668          5.500                  0.000                    0.000\n",
        "7   (Tyler Cowen Economic Scene column on why US h...                      ([(COWEN, Tyler)],)    (article,)  [{u'name': u'persons', u'value': u'CASNOCHA, B...  (Michael S. Dell (of Dell Inc.) sold stamps to...          971       (3,)  (2007-06-14T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2007/06/14/business/14...             0                                                 []            4.706          5.493                  0.000                    0.000\n",
        "8   (Eugenie Allen reviews book The Comeback: Seve...                    ([(ALLEN, Eugenie)],)    (article,)  [{u'name': u'persons', u'value': u'KELLER, EMM...  (THE COMEBACK Seven Stories of Women Who Went ...          914      (13,)  (2008-09-21T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2008/09/21/books/revie...             0                                                 []            4.700          5.490                  0.000                    0.000\n",
        "9   (United Talent Agency will announce creation o...                                ([None],)    (article,)  [{u'name': u'glocations', u'value': u'NEW YORK...  (The United Talent Agency plans today to annou...           63       (5,)  (2007-09-10T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2007/09/10/business/me...             0                                                 []            4.779          5.502                  0.000                    0.000\n",
        "10  (David Carr reviews book Crazy Like a Fox: The...                       ([(Carr, David)],)    (article,)  [{u'name': u'persons', u'value': u'COLLINS, SC...  (CRAZY LIKE A FOX The Inside Story of How Fox ...         1129      (34,)  (2004-04-18T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2004/04/18/books/from-...             0                                                 []            4.750          5.500                  0.000                    0.000\n",
        "11  (Some small companies claim that larger ones a...  ([(LATTMAN, Peter), (MARTIN, Andrew)],)    (article,)  [{u'name': u'persons', u'value': u'PRUNIER, CH...  (A light bulb went off for Christy Prunier whi...         1315       (1,)  (2011-09-29T00:00:00Z,)  tart-up  (The New York Times,)  (http://query.nytimes.com/gst/fullpage.html?re...             0                                                 []            4.743          5.503                  0.000                    0.000\n",
        "12  (Jacob Heilbrunn reviews books Soulless: Ann C...                  ([(Heilbrunn, Jacob)],)    (article,)  [{u'name': u'persons', u'value': u'UNANIMOUS'}...  (SOULLESS Ann Coulter and the Right-Wing Churc...         1287      (15,)  (2006-11-26T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2006/11/26/books/Heilb...             0                                                 []            4.790          5.495                  0.000                    0.000\n",
        "13  (Timeline shows significant moments in the his...                                ([None],)    (article,)                                                 []  (1946 Electronic Control Co. (now Unisys)J. Pr...          328      (10,)  (2012-07-22T00:00:00Z,)  tart-up  (The New York Times,)  (http://query.nytimes.com/gst/fullpage.html?re...             0                                                 []            4.839          5.504                  0.000                    0.000\n",
        "14                                                (,)                    ([(Borowitz, Andy)],)    (article,)                                                 []  (Dear Mom and Dad, Camp is AWESOME!!! There's ...          325      (29,)  (2000-07-13T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2000/07/13/opinion/sta...             0                                                 []            4.815          5.522                  0.000                    0.000\n",
        "15  (Foursquare will introduce its largest partner...                    ([(WORTHAM, Jenna)],)    (article,)  [{u'name': u'persons', u'value': u'LATTMAN, PE...  (When the New York start-up Foursquare Labs ma...         1009       (1,)  (2011-06-23T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2011/06/23/technology/...             0                                                 []            4.813          5.520                  0.000                    0.000\n",
        "16  (Many young technology companies have slashed ...                    ([(MILLER, Claire)],)    (article,)  [{u'name': u'organizations', u'value': u'SEQUO...  (In October, when Wall Street was already wall...         1119       (1,)  (2009-04-08T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2009/04/08/technology/...             0                                                 []            4.832          5.494                  0.000                    0.000\n",
        "17  (Maxim Group pulls out as underwriter of start...                     ([(HANSELL, Saul)],)    (article,)  [{u'name': u'persons', u'value': u'ROUSSO, MAR...  (Three years ago, at a news conference at Tave...         1312       (1,)  (2007-08-22T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2007/08/22/technology/...             0                                                 []            4.852          5.496                  0.000                    0.000\n",
        "18                                                (,)               ([(Blackerby, Jeffries)],)    (article,)                                                 []  (For those who like the idea of renting a vill...          100      (24,)  (2006-11-19T00:00:00Z,)  tart-up  (The New York Times,)  (http://query.nytimes.com/gst/fullpage.html?re...             0                                                 []            4.855          5.498                  0.000                    0.000\n",
        "19  (The Boss column features StumbleUpon chief ex...                     ([(CAMP, Garrett)],)    (article,)  [{u'value': u'StumbleUpon', u'is_major': u'Y',...  (Garrett Camp of StumbleUpon describes what it...          660      (10,)  (2011-10-23T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2011/10/23/jobs/23boss...             0                                                 []            4.847          5.496                  0.000                    0.000\n",
        "20  (Article on special breed of small-business ow...                       ([(FIELD, Anne)],)    (article,)  [{u'name': u'persons', u'value': u'YELLEN, HOW...  (Howard Yellen has recently found what promise...         1178       (6,)  (2003-12-11T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2003/12/11/business/sm...             0                                                 []            4.808          5.507                  0.000                    0.000\n",
        "21                                                (,)                    ([(WORTHAM, Jenna)],)    (article,)  [{u'rank': u'3', u'name': u'persons', u'value'...  (Just four months after a much-hyped introduct...         1466       (1,)  (2012-10-19T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2012/10/19/technology/...             0                                                 []            4.813          5.505                  0.000                    0.000\n",
        "22  (Think registering your business sounds like a...                                ([None],)   (blogpost,)                                                 []  (Think registering your business sounds like a...         1192        (,)  (2010-04-01T00:49:48Z,)  tart-up  (The New York Times,)  (http://dealbook.nytimes.com/2010/04/01/how-to...             0                                                 []            4.826          5.507                  0.000                    0.000\n",
        "23  (Six months after Egyptian uprising, business ...                  ([(SELIGSON, Hannah)],)    (article,)  [{u'name': u'persons', u'value': u'GERBER, SCO...  (LIKE so many other young people in Cairo, Yas...         1794       (1,)  (2011-07-17T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2011/07/17/business/gl...             0                                                 []            4.813          5.502                  0.000                    0.000\n",
        "24  (Article on Golden Baseball League, formed two...                      ([(RIVLIN, Gary)],)    (article,)  [{u'name': u'persons', u'value': u'OUTCALT, KE...  (IT was the sixth inning of a one-run game bet...         3167       (1,)  (2006-07-09T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2006/07/09/business/yo...             0                                                 []            4.813          5.504                  0.000                    0.000\n",
        "25  (Legal battle between Corbis and Infoflows is ...                       ([(LOHR, Steve)],)    (article,)  [{u'name': u'persons', u'value': u'GATES, BILL...  (Technology start-ups and big companies work t...         1222       (6,)  (2010-07-19T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2010/07/19/technology/...             0                                                 []            4.829          5.509                  0.000                    0.000\n",
        "26  (Interview with Gary Doan, founder and chief e...                     ([(FLYNN, Laurie)],)    (article,)  [{u'name': u'persons', u'value': u'DOAN, GARY'...  (For Gary Doan, the chief executive of a start...          700       (4,)  (2004-03-29T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2004/03/29/business/te...             0                                                 []            4.837          5.490                  0.000                    0.000\n",
        "27  (For Thomas L. Friedman, reading the news that...                                ([None],)   (blogpost,)                                                 []  (For Thomas L. Friedman, reading the news that...          866        (,)  (2009-02-23T06:49:48Z,)  tart-up  (The New York Times,)  (http://dealbook.nytimes.com/2009/02/23/start-...             0                                                 []            4.830          5.485                  0.000                    0.000\n",
        "28                                                (,)                     ([(CAMP, Garrett)],)    (article,)  [{u'name': u'organizations', u'value': u'STUMB...  (I'M from Calgary, Alberta. My mother was an a...          668      (10,)  (2011-10-23T00:00:00Z,)  tart-up  (The New York Times,)  (http://www.nytimes.com/2011/10/23/jobs/23boss...             0                                                 []            4.809          5.490                  0.000                    0.000\n",
        "29                                                (,)                   ([(FREEDMAN, David)],)    (article,)                                                 []  (Hari Kaur has been teaching yoga for 20 years...         1152       (8,)  (2011-09-01T00:00:00Z,)  tart-up  (The New York Times,)  (http://query.nytimes.com/gst/fullpage.html?re...             0                                                 []            4.775          5.490                  0.000                    0.000"
       ]
      }
     ],
     "prompt_number": 242
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "30\n",
        "30\n"
       ]
      }
     ],
     "prompt_number": 247
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## pearsonr() gives a tuple of (Pearson zero-order correlation, p-value)\n",
      "\n",
      "## here we print out the correlation matrix for avg word length, post length, and avg sentiment\n",
      "## (not very pretty though - better to output in a readable table, a la SPSS)\n",
      "\n",
      "print 'avg word length : post length'\n",
      "print stats.pearsonr(trimmed_post_df['avg word length'].values, trimmed_post_df['post length'].values)\n",
      "\n",
      "print 'avg word length : avg sentiment'\n",
      "print stats.pearsonr(trimmed_post_df['avg word length'].values, trimmed_post_df['avg sentiment'].values)\n",
      "\n",
      "print 'post length : avg sentiment'\n",
      "print stats.pearsonr(trimmed_post_df['post length'].values, trimmed_post_df['avg sentiment'].values)\n",
      "\n",
      "print 'post sentiment : comment sentiment'\n",
      "print stats.pearsonr(trimmed_post_df['avg sentiment'].values, trimmed_post_df['avg comment sentiment'].values)\n",
      "\n",
      "print 'post sentiment : number of comments'\n",
      "print stats.pearsonr(trimmed_post_df['avg sentiment'].values, trimmed_post_df['num comments'].values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "avg word length : post length\n",
        "(-0.11148510542724749, 0.55752899342081141)\n",
        "avg word length : avg sentiment\n",
        "(-0.67929985333911092, 3.6645694504399884e-05)\n",
        "post length : avg sentiment\n",
        "(0.25421426547162002, 0.17522081494158098)\n",
        "post sentiment : comment sentiment\n",
        "(-0.37375606600616207, 0.041894551875980325)\n",
        "post sentiment : number of comments\n",
        "(-0.72380513190304052, 6.1713307306139193e-06)\n"
       ]
      }
     ],
     "prompt_number": 244
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "\n",
      "leads = trimmed_post_df['lead_paragraph']\n",
      "DV = trimmed_post_df['avg sentiment']\n",
      "\n",
      "def make_xy(text, DV, vectorizer=None):\n",
      "    if vectorizer is not None:\n",
      "        vect = vectorizer\n",
      "    else:    \n",
      "        vect = CountVectorizer(min_df=0)\n",
      "    fitvectorizer = vect.fit(text)\n",
      "    bagofwords = vect.transform(text)\n",
      "    sawords = bagofwords.tocsc()\n",
      "    return sawords, DV\n",
      "\n",
      "X, Y = make_xy(leads, DV, vectorizer=None)\n",
      "                                  \n",
      "#SPLIT TRAINING SET INTO TWO GROUPS\n",
      "\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "\n",
      "#get train_test_split tupel with validation and training data\n",
      "xtrain, xtest, ytrain, ytest = train_test_split(X,Y)\n",
      "\n",
      "#create multinomial classifier\n",
      "clf = MultinomialNB()\n",
      "#calculate fit with training data\n",
      "print clf.fit(xtrain, ytrain)\n",
      "#output valdiation accuracy\n",
      "print clf.score(xtest, ytest)\n",
      "print clf.score(xtrain, ytrain)\n",
      "\n",
      "#CROSS VALIDATION WITH LOG LIKELIHOOD\n",
      "def log_likelihood(clf, x, y):\n",
      "    #get expected P(rotten),P(fresh)\n",
      "    probabilities = clf.predict_log_proba(x)\n",
      "    #print probabilities\n",
      "    #get the P(fresh) column\n",
      "    xfreshprobs = probabilities[:,1]\n",
      "    xrottenprobs = probabilities[:,0]\n",
      "    \n",
      "    pfresh = xfreshprobs[y==1]\n",
      "    protten = xrottenprobs[y==0]\n",
      "    \n",
      "    pfreshsum = sum(pfresh)\n",
      "    \n",
      "    prottensum = sum(protten)\n",
      "    \n",
      "    result = pfreshsum + prottensum\n",
      "    return result\n",
      "\n",
      "print log_likelihood(clf, X, Y)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import KFold\n",
      "\n",
      "def cv_score(clf, x, y, score_func):\n",
      "    \"\"\"\n",
      "    Uses 5-fold cross validation to estimate a score of a classifier\n",
      "    \n",
      "    Inputs\n",
      "    ------\n",
      "    clf : Classifier object\n",
      "    x : Input feature vector\n",
      "    y : Input class labels\n",
      "    score_func : Function like log_likelihood, that takes (clf, x, y) as input,\n",
      "                 and returns a score\n",
      "                 \n",
      "    Returns\n",
      "    -------\n",
      "    The average score obtained by randomly splitting (x, y) into training and \n",
      "    test sets, fitting on the training set, and evaluating score_func on the test set\n",
      "    \n",
      "    Examples\n",
      "    cv_score(clf, x, y, log_likelihood)\n",
      "    \"\"\"\n",
      "    result = 0\n",
      "    nfold = 5\n",
      "    for train, test in KFold(y.size, nfold): # split data into train/test groups, 5 times\n",
      "        clf.fit(x[train], y[train]) # fit\n",
      "        result += score_func(clf, x[test], y[test]) # evaluate score function on held-out data\n",
      "    return result / nfold # average\n",
      "\n",
      "print cv_score(clf, X, Y, log_likelihood)\n",
      "\n",
      "# as a side note, this function is builtin to the newest version of sklearn. We could just write\n",
      "# sklearn.cross_validation.cross_val_score(clf, x, y, scorer=log_likelihood).\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#the grid of parameters to search over\n",
      "alphas = [0, .1, 1, 5, 10, 50]\n",
      "min_dfs = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
      "\n",
      "#Find the best value for alpha and min_df, and the best classifier\n",
      "best_alpha = None\n",
      "best_min_df = None\n",
      "max_loglike = -np.inf\n",
      "\n",
      "resultframe = pd.DataFrame()\n",
      "\n",
      "for alpha in alphas:\n",
      "    #print alpha\n",
      "    for min_df in min_dfs:         \n",
      "        vectorizer = CountVectorizer(min_df = min_df)       \n",
      "        X, Y = make_xy(critics, vectorizer)\n",
      "        #xtrain, xtest, ytrain, ytest = train_test_split(X,Y)\n",
      "        #create multinomial classifier\n",
      "        clf = MultinomialNB(alpha=alpha, class_prior=None, fit_prior=True)#alpha = alpha)\n",
      "        score = cv_score(clf, X, Y, log_likelihood)\n",
      "        #score = cv_score(clf, xtrain, ytrain, log_likelihood)\n",
      "        tempdict = {'alpha': alpha, 'min_df': min_df, 'score': score}\n",
      "        \n",
      "        #print min_df\n",
      "        #print score\n",
      "        #print pd.DataFrame(tempdict)\n",
      "        resultframe = resultframe.append(pd.DataFrame([tempdict]), ignore_index=True)\n",
      "        \n",
      "#print resultframe.sort(columns=['score'], ascending = True).head(19)\n",
      "#print resultframe.sort(columns=['score'], ascending = False).head(19)\n",
      "        \n",
      "resultrow = resultframe[np.isfinite(resultframe['score'])].sort(columns=['score'], ascending = False).head(1)\n",
      "\n",
      "best_alpha = resultrow.alpha.values[0]\n",
      "best_min_df = resultrow.min_df.values[0]\n",
      "max_loglike = resultrow.score.values[0]\n",
      "\n",
      "print best_alpha\n",
      "print best_min_df\n",
      "print max_loglike\n",
      "\n",
      "print resultrow\n",
      "        \n",
      "        \n",
      "        #your code here\n",
      "##WHICH WORDS BEST PREDICT HIGHER SENTIMENT? \n",
      "\n",
      "# Your code here\n",
      "wordbag = vectorizer.get_feature_names()\n",
      "xvals = np.eye(len(wordbag))\n",
      "yvals = clf.predict_proba(xvals)\n",
      "\n",
      "#print map(str,wordbag)\n",
      "\n",
      "probframe = pd.DataFrame(index = map(str,wordbag))\n",
      "probframe['rotten'] = yvals[:,0]\n",
      "probframe['fresh'] = yvals[:,1]\n",
      "\n",
      "print pd.DataFrame(probframe['rotten']).sort(columns = ['rotten'], ascending = False).head(10)\n",
      "print pd.DataFrame(probframe['fresh']).sort(columns = ['fresh'], ascending = False).head(10)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}