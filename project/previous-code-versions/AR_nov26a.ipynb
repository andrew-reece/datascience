{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "-- css --\n",
      "\n",
      "<style>\n",
      "div.text_cell_render {\n",
      "    line-height: 150%;\n",
      "    font-size: 110%;\n",
      "    width: 800px;\n",
      "    margin-left:50px;\n",
      "    margin-right:auto;\n",
      "    }\n",
      "    \n",
      "div.Andrew {\n",
      "    margin: 20px;\n",
      "    padding: 20px;\n",
      "    color: maroon;\n",
      "    background-color: rgb(233,233,233);\n",
      "    font-family: calibri;\n",
      "    font-size: 14pt;\n",
      "}\n",
      "</style>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "<div class=Andrew>\n",
      "    What: Development playground for CS109 final project\n",
      "    <br /><br />\n",
      "Who: Andrew Reece, Daniel Wu, Javier Pineda, Baris Baloglu\n",
      "    <br /><br />\n",
      "Uses: code snippets from HW2, HW3\n",
      "</div>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Not sure what we'll need exactly, so just importing all the usual suspects here\n",
      "\n",
      "import json\n",
      "import requests\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import re\n",
      "import scipy.stats as stats\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn import linear_model\n",
      "\n",
      "pd.set_option('display.width', 500)\n",
      "pd.set_option('display.max_columns', 30)\n",
      "\n",
      "# set some nicer defaults for matplotlib\n",
      "from matplotlib import rcParams\n",
      "\n",
      "#these colors come from colorbrewer2.org. Each is an RGB triplet\n",
      "dark2_colors = [(0.10588235294117647, 0.6196078431372549, 0.4666666666666667),\n",
      "                (0.8509803921568627, 0.37254901960784315, 0.00784313725490196),\n",
      "                (0.4588235294117647, 0.4392156862745098, 0.7019607843137254),\n",
      "                (0.9058823529411765, 0.1607843137254902, 0.5411764705882353),\n",
      "                (0.4, 0.6509803921568628, 0.11764705882352941),\n",
      "                (0.9019607843137255, 0.6705882352941176, 0.00784313725490196),\n",
      "                (0.6509803921568628, 0.4627450980392157, 0.11372549019607843),\n",
      "                (0.4, 0.4, 0.4)]\n",
      "\n",
      "rcParams['figure.figsize'] = (10, 6)\n",
      "rcParams['figure.dpi'] = 150\n",
      "rcParams['axes.color_cycle'] = dark2_colors\n",
      "rcParams['lines.linewidth'] = 2\n",
      "rcParams['axes.grid'] = False\n",
      "rcParams['axes.facecolor'] = 'white'\n",
      "rcParams['font.size'] = 14\n",
      "rcParams['patch.edgecolor'] = 'none'\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div class=\"Andrew\">\n",
      "For now we're using the NYT developer API. \n",
      "<br /><br />\n",
      "It doesn't give full article text, but we can get headline and lead paragraph.\n",
      "<br /><br />\n",
      "The code below only uses the main \"Article\" API.  \n",
      "<br />\n",
      "But I've posted API keys for other types of APIs offered by NYT.\n",
      "</div>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "## NYT API keys\n",
      "api_key_article = \"851e7d0a131bee9bc01097470c238637:13:47475506\"\n",
      "api_key_community = \"519167db119ee6408c4ee51b3c391e11:0:47475506\"\n",
      "api_key_geo = \"a984ad78bf017f0ade1fcd980aa6353f:15:47475506\"\n",
      "api_key_popular = \"09dfaf288ad6c2ec46893a27ca758d41:19:47475506\"\n",
      "api_key_movies = \"e8a48f7d7731698b05267146c681c352:5:47475506\"\n",
      "api_key_semantic = \"9063b41607bbf486247b8e596a1456b8:7:47475506\"\n",
      "api_key_newswire = \"209ebb7b0ab44094970e8b39c63fea7e:2:47475506\"\n",
      "api_key_timestags = \"43b3366f288db10cb019fd532299723f:10:47475506\"\n",
      "\n",
      "\n",
      "begindate = \"19900101\" #YYYYMMDD\n",
      "enddate = \"20131112\" #YYYYMMDD\n",
      "\n",
      "\n",
      "## just picked a few terms meant to have a fair spread in content\n",
      "terms = ['china', 'debt', 'obama', 'elections', 'fashion', 'business','art','theater','science']\n",
      "\n",
      "# intially an empty dataframe\n",
      "data_df = pd.DataFrame()\n",
      "\n",
      "## loop through terms\n",
      "for term in terms:\n",
      "    \n",
      "    ## api request for each term\n",
      "    url = ''.join([\"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=\", term,\n",
      "                   \"&begin_date=\", begindate, \n",
      "                   \"&end_date=\", enddate,\n",
      "                   \"&api-key=\",api_key_article])\n",
      "                   \n",
      "    req = requests.get(url).text\n",
      "    \n",
      "    ## decode into json dicts\n",
      "    jsons = json.loads(req)\n",
      "    \n",
      "    ## loop through each article returned from API request\n",
      "    for doc in jsons['response']['docs']:\n",
      "\n",
      "        # making dataframe; a term will appear in multiple rows\n",
      "        doc_df = pd.DataFrame([term], columns = ['term'])\n",
      "        \n",
      "        # alternative way of dealing with none-types\n",
      "        if json.dumps(doc['abstract']) != 'null':\n",
      "            \n",
      "            # encode weird ascii stuff\n",
      "            abstract = [doc['abstract'].encode('utf-8')]\n",
      "            \n",
      "            # making dataframe and adding abstracts\n",
      "            doc_df['abstract'] = abstract\n",
      "            \n",
      "        # this way we take all data, and we can do away with what we don't want later    \n",
      "        else:\n",
      "            abstract = np.nan\n",
      "            doc_df['abstract'] = abstract\n",
      "            \n",
      "        # can add an if-else clause for anything you want to get, then add to doc_df\n",
      "        if json.dumps(doc['lead_paragraph']) != 'null':\n",
      "            \n",
      "            lead = [doc['lead_paragraph'].encode('utf-8')]\n",
      "            doc_df['lead'] = lead\n",
      "            \n",
      "        else:\n",
      "            lead = np.nan\n",
      "            doc_df['lead'] = lead\n",
      "        \n",
      "        data_df = pd.concat([data_df, doc_df]).reset_index(drop=True)\n",
      "        \n",
      "leads = list(data_df.lead)\n",
      "#print leads\n",
      "data_df\n",
      "        \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "//anaconda/python.app/Contents/lib/python2.7/site-packages/pandas/core/config.py:570: DeprecationWarning: height has been deprecated.\n",
        "\n",
        "  warnings.warn(d.msg, DeprecationWarning)\n"
       ]
      },
      {
       "html": [
        "<pre>\n",
        "&lt;class 'pandas.core.frame.DataFrame'&gt;\n",
        "Int64Index: 90 entries, 0 to 89\n",
        "Data columns (total 3 columns):\n",
        "abstract    39  non-null values\n",
        "lead        86  non-null values\n",
        "term        90  non-null values\n",
        "dtypes: object(3)\n",
        "</pre>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 90 entries, 0 to 89\n",
        "Data columns (total 3 columns):\n",
        "abstract    39  non-null values\n",
        "lead        86  non-null values\n",
        "term        90  non-null values\n",
        "dtypes: object(3)"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div class=\"Andrew\">\n",
      "Below is an example of the structure of our list data[]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## can search for lead paragraph for a particular term \n",
      "## just need to add .values so pandas knows it's not looking for an index\n",
      "\n",
      "print data_df.lead[data_df.term == 'debt'].values[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "It\u2019s another case of ideology posing as economic analysis.\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div class=\"Andrew\">\n",
      "Now we'll pull in sentiment analysis data.  \n",
      "<br />This is the database being used at <a href=\"http://onehappybird.com\">onehappybird.com.\n",
      "</a></div>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## read sentiment data from text file\n",
      "sentiment = pd.read_table('sentiment_data.txt', sep='\\t')\n",
      "\n",
      "## have a look\n",
      "sentiment.head()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "//anaconda/python.app/Contents/lib/python2.7/site-packages/pandas/core/config.py:570: DeprecationWarning: height has been deprecated.\n",
        "\n",
        "  warnings.warn(d.msg, DeprecationWarning)\n",
        "//anaconda/python.app/Contents/lib/python2.7/site-packages/pandas/core/config.py:570: DeprecationWarning: height has been deprecated.\n",
        "\n",
        "  warnings.warn(d.msg, DeprecationWarning)\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>word</th>\n",
        "      <th>happiness_rank</th>\n",
        "      <th>happiness_average</th>\n",
        "      <th>happiness_standard_deviation</th>\n",
        "      <th>twitter_rank</th>\n",
        "      <th>google_rank</th>\n",
        "      <th>nyt_rank</th>\n",
        "      <th>lyrics_rank</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  laughter</td>\n",
        "      <td> 1</td>\n",
        "      <td> 8.50</td>\n",
        "      <td> 0.9313</td>\n",
        "      <td> 3600</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1728</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> happiness</td>\n",
        "      <td> 2</td>\n",
        "      <td> 8.44</td>\n",
        "      <td> 0.9723</td>\n",
        "      <td> 1853</td>\n",
        "      <td> 2458</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 1230</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>      love</td>\n",
        "      <td> 3</td>\n",
        "      <td> 8.42</td>\n",
        "      <td> 1.1082</td>\n",
        "      <td>   25</td>\n",
        "      <td>  317</td>\n",
        "      <td>  328</td>\n",
        "      <td>   23</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>     happy</td>\n",
        "      <td> 4</td>\n",
        "      <td> 8.30</td>\n",
        "      <td> 0.9949</td>\n",
        "      <td>   65</td>\n",
        "      <td> 1372</td>\n",
        "      <td> 1313</td>\n",
        "      <td>  375</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>   laughed</td>\n",
        "      <td> 5</td>\n",
        "      <td> 8.26</td>\n",
        "      <td> 1.1572</td>\n",
        "      <td> 3334</td>\n",
        "      <td> 3542</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 2332</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "        word  happiness_rank  happiness_average  happiness_standard_deviation  twitter_rank  google_rank  nyt_rank  lyrics_rank\n",
        "0   laughter               1               8.50                        0.9313          3600          NaN       NaN         1728\n",
        "1  happiness               2               8.44                        0.9723          1853         2458       NaN         1230\n",
        "2       love               3               8.42                        1.1082            25          317       328           23\n",
        "3      happy               4               8.30                        0.9949            65         1372      1313          375\n",
        "4    laughed               5               8.26                        1.1572          3334         3542       NaN         2332"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div class=\"Andrew\">\n",
      "Eventually we'll want to run the analysis on all lead paragraphs, across all search terms. \n",
      "<br /><br />\n",
      "For now, we'll narrow it down to paragraphs from just one search term, to keep it simple.\n",
      "</div>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## for now, set 'leads' variable as lead paragraphs for second search term ('debt')\n",
      "leads = list(data_df.lead)\n",
      "##print leads\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## these three lists are our bins for collecting data on each lead paragraph\n",
      "avg_word = []\n",
      "post_length = []\n",
      "avg_sent = []\n",
      "avg_hard = []\n",
      "avg_dyn = []\n",
      "wordbag = set()\n",
      "\n",
      "\n",
      "\n",
      "## loop through lead paragraphs\n",
      "for item in leads:\n",
      "    \n",
      "    ## outer_sent_hard collects words with sentiment ratings more extreme than a hard-coded dispersion from the mean\n",
      "    ## eg. if mean is 5.2 and we set hard dispersion to be 1.0, then outer_sent_hard collects words with sentiment\n",
      "    ##     at <4.2 and >6.2.  \n",
      "    outer_sent_hard = set()\n",
      "    \n",
      "    ## outer_sent_dyn collects words with sentiment ratings more extreme than a dynamically assessed dispersion\n",
      "    ## eg. if range is 2.0 to 8.0 and dynamic dispersion is set at 10% of total range\n",
      "    ##     then outer_sent_dyn collects words with sentiment more extreme than .1(6.0) from mean sentiment in corpus.\n",
      "    ##     ie. with mean 5.2, collect words with sentiment <4.6 and >5.8\n",
      "    outer_sent_dyn = set()\n",
      "    \n",
      "    \n",
      "    ## AR (nov 25):\n",
      "    ## this is where we might want to exclude bodies of text with fewer than 1000 words\n",
      "    ## (according to our sentiment analysis guy, <1000 words is when the analytic power starts to drop off)\n",
      "    ## \n",
      "    ## i'm not sure that will really fly with the nyt api though, as we only get lead paragraphs.\n",
      "    if (isinstance(item, float)):\n",
      "        continue\n",
      "    words_df = pd.DataFrame(item.split(' '), columns=['words'])\n",
      "    words_df['words'] = words_df.words.apply(lambda x: re.sub(\"\\W\", '', x))\n",
      "    ## gets bag of words for the entire corpus\n",
      "    wordbag |= set(words_df['words'].values)\n",
      "    words_df['word_length'] = words_df.words.apply(lambda x: len(x))\n",
      "    \n",
      "    words_df = words_df[words_df.word_length > 0]\n",
      "    \n",
      "    wdct = len(words_df)\n",
      "    word_lengths = list(words_df.word_length.values)\n",
      "    \n",
      "    words_df['in_sentiment'] = False\n",
      "    words_df['in_sentiment'][words_df.words.isin(sentiment.word)] = True\n",
      "    \n",
      "    # 'happiness average' is the same as 'sentiment score'\n",
      "    words_df['happiness_avg'] = np.nan\n",
      "    words_df['happiness_avg'][words_df.in_sentiment == True] = words_df.words[words_df.in_sentiment == True].apply(lambda x: \n",
      "            float(sentiment.happiness_average[sentiment.word == x].values))\n",
      "                                                     \n",
      "    # NOTE: the average word length here is including words not in the sentiment df\n",
      "    # maybe these words shouldn't be included in this calculation?\n",
      "    \n",
      "    ## AR (Nov 25): I think it's okay, as we're not attempting to draw a direct connection between the length\n",
      "    ##                  of each individual word and its sentiment, but rather the overall length of words in the post\n",
      "    ##                  and the overall sentiment that we can assess.  Even so, we can run it both ways and see if\n",
      "    ##                  it makes a big difference.\n",
      "    avg_word_length = round(np.mean(words_df.word_length.values), 2)\n",
      "    avg_sent_score = round(np.mean(words_df.happiness_avg[np.isfinite(words_df.happiness_avg)].values), 3)\n",
      "    \n",
      "    ## these vars are for assessing dynamic evaluation of our excluded middle vlaues\n",
      "    ##\n",
      "    ## sent_min: lowest sentiment score in this corpus\n",
      "    sent_min = words_df['happiness_avg'].min(axis=0)\n",
      "    \n",
      "    print 'sent_min:',sent_min\n",
      "    ## sent_max: highest sentiment score in this corpus\n",
      "    sent_max = words_df['happiness_avg'].max(axis=0)\n",
      "    \n",
      "    print 'sent_max:',sent_max\n",
      "    ## sent_range: difference between max and min\n",
      "    sent_range = sent_max - sent_min\n",
      "    \n",
      "    print 'sent_range:',sent_range\n",
      "    ## range_constant: multiply sent_range by this number to get the dispersion from the mean we want to exclude\n",
      "    ##                (this could be done using stdev, or by hard-coding a percentage, as I've done here)\n",
      "    ## \n",
      "    ## for now, use 20%.\n",
      "    range_constant = 0.2\n",
      "    dispersion = range_constant * sent_range\n",
      "    \n",
      "    ## lower/upper boundaries for hard-coded exclusion\n",
      "    hard_exclude_min = avg_sent_score - 1\n",
      "    hard_exclude_max = avg_sent_score + 1\n",
      "    \n",
      "    ## lower and upper boundaries for dynamic exclusion\n",
      "    dyn_exclude_min = avg_sent_score - dispersion\n",
      "    dyn_exclude_max = avg_sent_score + dispersion\n",
      "    \n",
      "    print 'dispersion constant:', dispersion, 'away from mean:',avg_sent_score\n",
      "    print 'so...exclude values between',dyn_exclude_min,'and',dyn_exclude_max\n",
      "    print 'in the hard-coded case, exclude values between',hard_exclude_min,'and',hard_exclude_max\n",
      "    print '\\n\\n' \n",
      "    ## go through all the words in a corpus\n",
      "    ## filter by either hard or dynamic dispersion from mean\n",
      "    ## store the words we want in new arrays\n",
      "    for row in words_df.iterrows():\n",
      "        ## print row[1]\n",
      "        datum = row[1]\n",
      "        \n",
      "        ##\n",
      "        ##\n",
      "        ## what is the nan problem?\n",
      "        ##\n",
      "        ##\n",
      "        \n",
      "        if ((datum['happiness_avg'] > hard_exclude_max) or (datum['happiness_avg'] < hard_exclude_min)):\n",
      "            \n",
      "            outer_sent_hard.add(datum['happiness_avg'])\n",
      "            \n",
      "        if ((datum['happiness_avg'] > dyn_exclude_max) or (datum['happiness_avg'] < dyn_exclude_min)):\n",
      "            \n",
      "            outer_sent_dyn.add(datum['happiness_avg'])\n",
      "    \n",
      "    ## print 'outer_sent_hard:',outer_sent_hard\n",
      "    avg_hard_score = round(np.mean(list(outer_sent_hard)),3)\n",
      "    avg_dyn_score = round(np.mean(list(outer_sent_dyn)),3)\n",
      "    \n",
      "    ## post length is the word count\n",
      "    post_length.append(wdct)    \n",
      "    \n",
      "    ## append averages of word lengths and sentiment scores to bins\n",
      "    avg_word.append(avg_word_length)\n",
      "    avg_sent.append(avg_sent_score)\n",
      "    avg_dyn.append(avg_dyn_score)\n",
      " \n",
      "    ## in some rare instances, max dispersion in actual data is less than hard-coded range, so literally no values are captured\n",
      "    ## however excluding those sets from the master list causes problems later when we want a dataframe\n",
      "    ## so keep them in as NaN for now and exclude later.\n",
      "    avg_hard.append(avg_hard_score)\n",
      "    \n",
      "print avg_word\n",
      "print avg_sent\n",
      "print avg_hard\n",
      "print avg_dyn\n",
      "print post_length\n",
      "print '\\n\\n'\n",
      "\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sent_min: 4.94\n",
        "sent_max: 7.64\n",
        "sent_range: 2.7\n",
        "dispersion constant: 0.54 away from mean: 5.532\n",
        "so...exclude values between 4.992 and 6.072\n",
        "in the hard-coded case, exclude values between 4.532 and 6.532\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 1.54\n",
        "sent_max: 7.32\n",
        "sent_range: 5.78\n",
        "dispersion constant: 1.156 away from mean: 4.935\n",
        "so...exclude values between 3.779 and 6.091\n",
        "in the hard-coded case, exclude values between 3.935 and 5.935\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.54\n",
        "sent_max: 7.32\n",
        "sent_range: 5.78\n",
        "dispersion constant: 1.156 away from mean: 4.935\n",
        "so...exclude values between 3.779 and 6.091\n",
        "in the hard-coded case, exclude values between 3.935 and 5.935\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 2.82\n",
        "sent_max: 7.38\n",
        "sent_range: 4.56\n",
        "dispersion constant: 0.912 away from mean: 5.41\n",
        "so...exclude values between 4.498 and 6.322\n",
        "in the hard-coded case, exclude values between 4.41 and 6.41\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 2.88\n",
        "sent_max: 7.7\n",
        "sent_range: 4.82\n",
        "dispersion constant: 0.964 away from mean: 5.557\n",
        "so...exclude values between 4.593 and 6.521\n",
        "in the hard-coded case, exclude values between 4.557 and 6.557\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4.74\n",
        "sent_max: 6.68\n",
        "sent_range: 1.94\n",
        "dispersion constant: 0.388 away from mean: 5.542\n",
        "so...exclude values between 5.154 and 5.93\n",
        "in the hard-coded case, exclude values between 4.542 and 6.542\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 3.52\n",
        "sent_max: 6.32\n",
        "sent_range: 2.8\n",
        "dispersion constant: 0.56 away from mean: 5.119\n",
        "so...exclude values between 4.559 and 5.679\n",
        "in the hard-coded case, exclude values between 4.119 and 6.119\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 2.98\n",
        "sent_max: 6.82\n",
        "sent_range: 3.84\n",
        "dispersion constant: 0.768 away from mean: 5.384\n",
        "so...exclude values between 4.616 and 6.152\n",
        "in the hard-coded case, exclude values between 4.384 and 6.384\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.98\n",
        "sent_max: 6.44\n",
        "sent_range: 3.46\n",
        "dispersion constant: 0.692 away from mean: 5.169\n",
        "so...exclude values between 4.477 and 5.861\n",
        "in the hard-coded case, exclude values between 4.169 and 6.169\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 4.94\n",
        "sent_max: 5.82\n",
        "sent_range: 0.88\n",
        "dispersion constant: 0.176 away from mean: 5.337\n",
        "so...exclude values between 5.161 and 5.513\n",
        "in the hard-coded case, exclude values between 4.337 and 6.337\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 2.7\n",
        "sent_max: 7.4\n",
        "sent_range: 4.7\n",
        "dispersion constant: 0.94 away from mean: 5.127\n",
        "so...exclude values between 4.187 and 6.067\n",
        "in the hard-coded case, exclude values between 4.127 and 6.127\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 3.28\n",
        "sent_max: 7.56\n",
        "sent_range: 4.28\n",
        "dispersion constant: 0.856 away from mean: 5.129\n",
        "so...exclude values between 4.273 and 5.985\n",
        "in the hard-coded case, exclude values between 4.129 and 6.129\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4.94\n",
        "sent_max: 5.5\n",
        "sent_range: 0.56\n",
        "dispersion constant: 0.112 away from mean: 5.076\n",
        "so...exclude values between 4.964 and 5.188\n",
        "in the hard-coded case, exclude values between 4.076 and 6.076\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 4.98\n",
        "sent_max: 6.52\n",
        "sent_range: 1.54\n",
        "dispersion constant: 0.308 away from mean: 5.602\n",
        "so...exclude values between 5.294 and 5.91\n",
        "in the hard-coded case, exclude values between 4.602 and 6.602\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 4.22\n",
        "sent_max: 7.38\n",
        "sent_range: 3.16\n",
        "dispersion constant: 0.632 away from mean: 5.328\n",
        "so...exclude values between 4.696 and 5.96\n",
        "in the hard-coded case, exclude values between 4.328 and 6.328\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.8\n",
        "sent_max: 7.94\n",
        "sent_range: 6.14\n",
        "dispersion constant: 1.228 away from mean: 5.278\n",
        "so...exclude values between 4.05 and 6.506\n",
        "in the hard-coded case, exclude values between 4.278 and 6.278\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4.22\n",
        "sent_max: 7.38\n",
        "sent_range: 3.16\n",
        "dispersion constant: 0.632 away from mean: 5.301\n",
        "so...exclude values between 4.669 and 5.933\n",
        "in the hard-coded case, exclude values between 4.301 and 6.301\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.82\n",
        "sent_max: 7.98\n",
        "sent_range: 5.16\n",
        "dispersion constant: 1.032 away from mean: 5.332\n",
        "so...exclude values between 4.3 and 6.364\n",
        "in the hard-coded case, exclude values between 4.332 and 6.332\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 2.7\n",
        "sent_max: 5.56\n",
        "sent_range: 2.86\n",
        "dispersion constant: 0.572 away from mean: 4.954\n",
        "so...exclude values between 4.382 and 5.526\n",
        "in the hard-coded case, exclude values between 3.954 and 5.954\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 3.16\n",
        "sent_max: 7.22\n",
        "sent_range: 4.06\n",
        "dispersion constant: 0.812 away from mean: 5.292\n",
        "so...exclude values between 4.48 and 6.104\n",
        "in the hard-coded case, exclude values between 4.292 and 6.292\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.86\n",
        "sent_max: 6.74\n",
        "sent_range: 4.88\n",
        "dispersion constant: 0.976 away from mean: 5.349\n",
        "so...exclude values between 4.373 and 6.325\n",
        "in the hard-coded case, exclude values between 4.349 and 6.349\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.48\n",
        "sent_max: 7.56\n",
        "sent_range: 5.08\n",
        "dispersion constant: 1.016 away from mean: 5.544\n",
        "so...exclude values between 4.528 and 6.56\n",
        "in the hard-coded case, exclude values between 4.544 and 6.544\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 4.74\n",
        "sent_max: 6.38\n",
        "sent_range: 1.64\n",
        "dispersion constant: 0.328 away from mean: 5.412\n",
        "so...exclude values between 5.084 and 5.74\n",
        "in the hard-coded case, exclude values between 4.412 and 6.412\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.42\n",
        "sent_max: 6.52\n",
        "sent_range: 4.1\n",
        "dispersion constant: 0.82 away from mean: 5.034\n",
        "so...exclude values between 4.214 and 5.854\n",
        "in the hard-coded case, exclude values between 4.034 and 6.034\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 4.52\n",
        "sent_max: 6.0\n",
        "sent_range: 1.48\n",
        "dispersion constant: 0.296 away from mean: 5.276\n",
        "so...exclude values between 4.98 and 5.572\n",
        "in the hard-coded case, exclude values between 4.276 and 6.276\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 2.78\n",
        "sent_max: 7.26\n",
        "sent_range: 4.48\n",
        "dispersion constant: 0.896 away from mean: 5.239\n",
        "so...exclude values between 4.343 and 6.135\n",
        "in the hard-coded case, exclude values between 4.239 and 6.239\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.55\n",
        "sent_max: 6.86\n",
        "sent_range: 4.31\n",
        "dispersion constant: 0.862 away from mean: 5.018\n",
        "so...exclude values between 4.156 and 5.88\n",
        "in the hard-coded case, exclude values between 4.018 and 6.018\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 4.92\n",
        "sent_max: 7.72\n",
        "sent_range: 2.8\n",
        "dispersion constant: 0.56 away from mean: 5.474\n",
        "so...exclude values between 4.914 and 6.034\n",
        "in the hard-coded case, exclude values between 4.474 and 6.474\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.62\n",
        "sent_max: 6.68\n",
        "sent_range: 4.06\n",
        "dispersion constant: 0.812 away from mean: 5.349\n",
        "so...exclude values between 4.537 and 6.161\n",
        "in the hard-coded case, exclude values between 4.349 and 6.349\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4.08\n",
        "sent_max: 6.88\n",
        "sent_range: 2.8\n",
        "dispersion constant: 0.56 away from mean: 5.205\n",
        "so...exclude values between 4.645 and 5.765\n",
        "in the hard-coded case, exclude values between 4.205 and 6.205\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 4.06\n",
        "sent_max: 6.82\n",
        "sent_range: 2.76\n",
        "dispersion constant: 0.552 away from mean: 5.295\n",
        "so...exclude values between 4.743 and 5.847\n",
        "in the hard-coded case, exclude values between 4.295 and 6.295\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.02\n",
        "sent_max: 6.76\n",
        "sent_range: 4.74\n",
        "dispersion constant: 0.948 away from mean: 4.948\n",
        "so...exclude values between 4.0 and 5.896\n",
        "in the hard-coded case, exclude values between 3.948 and 5.948\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 4.12\n",
        "sent_max: 8.1\n",
        "sent_range: 3.98\n",
        "dispersion constant: 0.796 away from mean: 5.396\n",
        "so...exclude values between 4.6 and 6.192\n",
        "in the hard-coded case, exclude values between 4.396 and 6.396\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.12\n",
        "sent_max: 7.98\n",
        "sent_range: 4.86\n",
        "dispersion constant: 0.972 away from mean: 5.43\n",
        "so...exclude values between 4.458 and 6.402\n",
        "in the hard-coded case, exclude values between 4.43 and 6.43\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 4.94\n",
        "sent_max: 8.1\n",
        "sent_range: 3.16\n",
        "dispersion constant: 0.632 away from mean: 6.048\n",
        "so...exclude values between 5.416 and 6.68\n",
        "in the hard-coded case, exclude values between 5.048 and 7.048\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 4.76\n",
        "sent_max: 6.02\n",
        "sent_range: 1.26\n",
        "dispersion constant: 0.252 away from mean: 5.38\n",
        "so...exclude values between 5.128 and 5.632\n",
        "in the hard-coded case, exclude values between 4.38 and 6.38\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.1\n",
        "sent_max: 6.96\n",
        "sent_range: 3.86\n",
        "dispersion constant: 0.772 away from mean: 5.271\n",
        "so...exclude values between 4.499 and 6.043\n",
        "in the hard-coded case, exclude values between 4.271 and 6.271\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 4.98\n",
        "sent_max: 5.68\n",
        "sent_range: 0.7\n",
        "dispersion constant: 0.14 away from mean: 5.344\n",
        "so...exclude values between 5.204 and 5.484\n",
        "in the hard-coded case, exclude values between 4.344 and 6.344\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 4.98\n",
        "sent_max: 6.88\n",
        "sent_range: 1.9\n",
        "dispersion constant: 0.38 away from mean: 6.153\n",
        "so...exclude values between 5.773 and 6.533\n",
        "in the hard-coded case, exclude values between 5.153 and 7.153\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.5\n",
        "sent_max: 8.42\n",
        "sent_range: 5.92\n",
        "dispersion constant: 1.184 away from mean: 5.683\n",
        "so...exclude values between 4.499 and 6.867\n",
        "in the hard-coded case, exclude values between 4.683 and 6.683\n",
        "\n",
        "\n",
        "\n",
        "sent_min: nan\n",
        "sent_max: nan\n",
        "sent_range: nan\n",
        "dispersion constant: nan away from mean: nan\n",
        "so...exclude values between nan and nan\n",
        "in the hard-coded case, exclude values between nan and nan\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.1\n",
        "sent_max: 8.02\n",
        "sent_range: 5.92\n",
        "dispersion constant: 1.184 away from mean: 5.467\n",
        "so...exclude values between 4.283 and 6.651\n",
        "in the hard-coded case, exclude values between 4.467 and 6.467\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 3.86\n",
        "sent_max: 6.52\n",
        "sent_range: 2.66\n",
        "dispersion constant: 0.532 away from mean: 5.351\n",
        "so...exclude values between 4.819 and 5.883\n",
        "in the hard-coded case, exclude values between 4.351 and 6.351\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.76\n",
        "sent_max: 7.42\n",
        "sent_range: 3.66\n",
        "dispersion constant: 0.732 away from mean: 5.564\n",
        "so...exclude values between 4.832 and 6.296\n",
        "in the hard-coded case, exclude values between 4.564 and 6.564\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.06\n",
        "sent_max: 8.3\n",
        "sent_range: 6.24\n",
        "dispersion constant: 1.248 away from mean: 5.5\n",
        "so...exclude values between 4.252 and 6.748\n",
        "in the hard-coded case, exclude values between 4.5 and 6.5\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 4.9\n",
        "sent_max: 5.24\n",
        "sent_range: 0.34\n",
        "dispersion constant: 0.068 away from mean: 5.085\n",
        "so...exclude values between 5.017 and 5.153\n",
        "in the hard-coded case, exclude values between 4.085 and 6.085\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4.02\n",
        "sent_max: 7.64\n",
        "sent_range: 3.62\n",
        "dispersion constant: 0.724 away from mean: 5.639\n",
        "so...exclude values between 4.915 and 6.363\n",
        "in the hard-coded case, exclude values between 4.639 and 6.639\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 4.9\n",
        "sent_max: 6.36\n",
        "sent_range: 1.46\n",
        "dispersion constant: 0.292 away from mean: 5.78\n",
        "so...exclude values between 5.488 and 6.072\n",
        "in the hard-coded case, exclude values between 4.78 and 6.78\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 4.9\n",
        "sent_max: 6.36\n",
        "sent_range: 1.46\n",
        "dispersion constant: 0.292 away from mean: 5.78\n",
        "so...exclude values between 5.488 and 6.072\n",
        "in the hard-coded case, exclude values between 4.78 and 6.78\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.22\n",
        "sent_max: 7.26\n",
        "sent_range: 4.04\n",
        "dispersion constant: 0.808 away from mean: 5.374\n",
        "so...exclude values between 4.566 and 6.182\n",
        "in the hard-coded case, exclude values between 4.374 and 6.374\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.64\n",
        "sent_max: 7.48\n",
        "sent_range: 4.84\n",
        "dispersion constant: 0.968 away from mean: 5.35\n",
        "so...exclude values between 4.382 and 6.318\n",
        "in the hard-coded case, exclude values between 4.35 and 6.35\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.22\n",
        "sent_max: 7.02\n",
        "sent_range: 3.8\n",
        "dispersion constant: 0.76 away from mean: 5.184\n",
        "so...exclude values between 4.424 and 5.944\n",
        "in the hard-coded case, exclude values between 4.184 and 6.184\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.96\n",
        "sent_max: 7.56\n",
        "sent_range: 4.6\n",
        "dispersion constant: 0.92 away from mean: 5.377\n",
        "so...exclude values between 4.457 and 6.297\n",
        "in the hard-coded case, exclude values between 4.377 and 6.377\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 4.74\n",
        "sent_max: 7.52\n",
        "sent_range: 2.78\n",
        "dispersion constant: 0.556 away from mean: 5.601\n",
        "so...exclude values between 5.045 and 6.157\n",
        "in the hard-coded case, exclude values between 4.601 and 6.601\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.84\n",
        "sent_max: 7.38\n",
        "sent_range: 5.54\n",
        "dispersion constant: 1.108 away from mean: 5.257\n",
        "so...exclude values between 4.149 and 6.365\n",
        "in the hard-coded case, exclude values between 4.257 and 6.257\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.66\n",
        "sent_max: 7.56\n",
        "sent_range: 3.9\n",
        "dispersion constant: 0.78 away from mean: 5.465\n",
        "so...exclude values between 4.685 and 6.245\n",
        "in the hard-coded case, exclude values between 4.465 and 6.465\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 2.54\n",
        "sent_max: 6.66\n",
        "sent_range: 4.12\n",
        "dispersion constant: 0.824 away from mean: 5.346\n",
        "so...exclude values between 4.522 and 6.17\n",
        "in the hard-coded case, exclude values between 4.346 and 6.346\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 4.82\n",
        "sent_max: 6.58\n",
        "sent_range: 1.76\n",
        "dispersion constant: 0.352 away from mean: 5.336\n",
        "so...exclude values between 4.984 and 5.688\n",
        "in the hard-coded case, exclude values between 4.336 and 6.336\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.28\n",
        "sent_max: 7.08\n",
        "sent_range: 3.8\n",
        "dispersion constant: 0.76 away from mean: 5.33\n",
        "so...exclude values between 4.57 and 6.09\n",
        "in the hard-coded case, exclude values between 4.33 and 6.33\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.24\n",
        "sent_max: 7.56\n",
        "sent_range: 5.32\n",
        "dispersion constant: 1.064 away from mean: 5.423\n",
        "so...exclude values between 4.359 and 6.487\n",
        "in the hard-coded case, exclude values between 4.423 and 6.423\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.56\n",
        "sent_max: 7.22\n",
        "sent_range: 4.66\n",
        "dispersion constant: 0.932 away from mean: 5.279\n",
        "so...exclude values between 4.347 and 6.211\n",
        "in the hard-coded case, exclude values between 4.279 and 6.279\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 4.98\n",
        "sent_max: 4.98\n",
        "sent_range: 0.0\n",
        "dispersion constant: 0.0 away from mean: 4.98\n",
        "so...exclude values between 4.98 and 4.98\n",
        "in the hard-coded case, exclude values between 3.98 and 5.98\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.92\n",
        "sent_max: 6.86\n",
        "sent_range: 3.94\n",
        "dispersion constant: 0.788 away from mean: 5.277\n",
        "so...exclude values between 4.489 and 6.065\n",
        "in the hard-coded case, exclude values between 4.277 and 6.277\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.76\n",
        "sent_max: 8.1\n",
        "sent_range: 5.34\n",
        "dispersion constant: 1.068 away from mean: 5.341\n",
        "so...exclude values between 4.273 and 6.409\n",
        "in the hard-coded case, exclude values between 4.341 and 6.341\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 3.38\n",
        "sent_max: 7.56\n",
        "sent_range: 4.18\n",
        "dispersion constant: 0.836 away from mean: 5.451\n",
        "so...exclude values between 4.615 and 6.287\n",
        "in the hard-coded case, exclude values between 4.451 and 6.451\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 4.98\n",
        "sent_max: 4.98\n",
        "sent_range: 0.0\n",
        "dispersion constant: 0.0 away from mean: 4.98\n",
        "so...exclude values between 4.98 and 4.98\n",
        "in the hard-coded case, exclude values between 3.98 and 5.98\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.08\n",
        "sent_max: 7.24\n",
        "sent_range: 4.16\n",
        "dispersion constant: 0.832 away from mean: 5.163\n",
        "so...exclude values between 4.331 and 5.995\n",
        "in the hard-coded case, exclude values between 4.163 and 6.163\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 4.94\n",
        "sent_max: 8.42\n",
        "sent_range: 3.48\n",
        "dispersion constant: 0.696 away from mean: 5.711\n",
        "so...exclude values between 5.015 and 6.407\n",
        "in the hard-coded case, exclude values between 4.711 and 6.711\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 4.94\n",
        "sent_max: 6.06\n",
        "sent_range: 1.12\n",
        "dispersion constant: 0.224 away from mean: 5.428\n",
        "so...exclude values between 5.204 and 5.652\n",
        "in the hard-coded case, exclude values between 4.428 and 6.428\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.86\n",
        "sent_max: 5.78\n",
        "sent_range: 1.92\n",
        "dispersion constant: 0.384 away from mean: 5.203\n",
        "so...exclude values between 4.819 and 5.587\n",
        "in the hard-coded case, exclude values between 4.203 and 6.203\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 4.98\n",
        "sent_max: 7.14\n",
        "sent_range: 2.16\n",
        "dispersion constant: 0.432 away from mean: 5.528\n",
        "so...exclude values between 5.096 and 5.96\n",
        "in the hard-coded case, exclude values between 4.528 and 6.528\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 4.9\n",
        "sent_max: 5.94\n",
        "sent_range: 1.04\n",
        "dispersion constant: 0.208 away from mean: 5.307\n",
        "so...exclude values between 5.099 and 5.515\n",
        "in the hard-coded case, exclude values between 4.307 and 6.307\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 4.94\n",
        "sent_max: 6.68\n",
        "sent_range: 1.74\n",
        "dispersion constant: 0.348 away from mean: 5.518\n",
        "so...exclude values between 5.17 and 5.866\n",
        "in the hard-coded case, exclude values between 4.518 and 6.518\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4.9\n",
        "sent_max: 6.02\n",
        "sent_range: 1.12\n",
        "dispersion constant: 0.224 away from mean: 5.366\n",
        "so...exclude values between 5.142 and 5.59\n",
        "in the hard-coded case, exclude values between 4.366 and 6.366\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 4.94\n",
        "sent_max: 6.44\n",
        "sent_range: 1.5\n",
        "dispersion constant: 0.3 away from mean: 5.304\n",
        "so...exclude values between 5.004 and 5.604\n",
        "in the hard-coded case, exclude values between 4.304 and 6.304\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 4.9\n",
        "sent_max: 5.5\n",
        "sent_range: 0.6\n",
        "dispersion constant: 0.12 away from mean: 5.15\n",
        "so...exclude values between 5.03 and 5.27\n",
        "in the hard-coded case, exclude values between 4.15 and 6.15\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 5.18\n",
        "sent_max: 6.02\n",
        "sent_range: 0.84\n",
        "dispersion constant: 0.168 away from mean: 5.713\n",
        "so...exclude values between 5.545 and 5.881\n",
        "in the hard-coded case, exclude values between 4.713 and 6.713\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 2.98\n",
        "sent_max: 6.0\n",
        "sent_range: 3.02\n",
        "dispersion constant: 0.604 away from mean: 5.059\n",
        "so...exclude values between 4.455 and 5.663\n",
        "in the hard-coded case, exclude values between 4.059 and 6.059\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 5.22\n",
        "sent_max: 7.5\n",
        "sent_range: 2.28\n",
        "dispersion constant: 0.456 away from mean: 6.427\n",
        "so...exclude values between 5.971 and 6.883\n",
        "in the hard-coded case, exclude values between 5.427 and 7.427\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.34\n",
        "sent_max: 6.82\n",
        "sent_range: 3.48\n",
        "dispersion constant: 0.696 away from mean: 5.312\n",
        "so...exclude values between 4.616 and 6.008\n",
        "in the hard-coded case, exclude values between 4.312 and 6.312\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 2.54\n",
        "sent_max: 7.14\n",
        "sent_range: 4.6\n",
        "dispersion constant: 0.92 away from mean: 5.297\n",
        "so...exclude values between 4.377 and 6.217\n",
        "in the hard-coded case, exclude values between 4.297 and 6.297\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 4.22\n",
        "sent_max: 7.3\n",
        "sent_range: 3.08\n",
        "dispersion constant: 0.616 away from mean: 5.754\n",
        "so...exclude values between 5.138 and 6.37\n",
        "in the hard-coded case, exclude values between 4.754 and 6.754\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.56\n",
        "sent_max: 8.02\n",
        "sent_range: 6.46\n",
        "dispersion constant: 1.292 away from mean: 5.091\n",
        "so...exclude values between 3.799 and 6.383\n",
        "in the hard-coded case, exclude values between 4.091 and 6.091\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.98\n",
        "sent_max: 8.02\n",
        "sent_range: 6.04\n",
        "dispersion constant: 1.208 away from mean: 5.439\n",
        "so...exclude values between 4.231 and 6.647\n",
        "in the hard-coded case, exclude values between 4.439 and 6.439\n",
        "\n",
        "\n",
        "\n",
        "sent_min: 4.6\n",
        "sent_max: 7.68\n",
        "sent_range: 3.08\n",
        "dispersion constant: 0.616 away from mean: 5.869\n",
        "so...exclude values between 5.253 and 6.485\n",
        "in the hard-coded case, exclude values between 4.869 and 6.869\n",
        "\n",
        "\n",
        "\n",
        "sent_min:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.64\n",
        "sent_max: 8.02\n",
        "sent_range: 4.38\n",
        "dispersion constant: 0.876 away from mean: 5.6\n",
        "so...exclude values between 4.724 and 6.476\n",
        "in the hard-coded case, exclude values between 4.6 and 6.6\n",
        "\n",
        "\n",
        "\n",
        "[5.03, 4.64, 4.64, 4.11, 5.15, 4.78, 5.14, 5.43, 5.82, 5.33, 5.06, 4.69, 4.83, 5.15, 4.44, 4.7, 4.51, 4.29, 4.13, 5.29, 5.14, 4.49, 4.04, 4.9, 4.43, 4.29, 4.64, 4.67, 5.1, 5.72, 4.17, 5.19, 5.39, 4.52, 6.48, 4.96, 4.53, 4.77, 5.4, 4.43, 4.94, 5.09, 4.24, 4.98, 4.39, 5.03, 4.53, 5.0, 5.0, 4.63, 5.24, 5.14, 5.25, 5.52, 4.54, 4.97, 6.68, 5.13, 4.75, 4.03, 4.5, 5.07, 4.51, 3.94, 4.13, 3.86, 4.78, 4.7, 5.69, 4.74, 5.52, 4.71, 4.5, 5.73, 4.45, 4.38, 5.67, 5.06, 6.88, 4.5, 5.08, 6.14, 4.43, 4.88, 5.27, 5.31]\n",
        "[5.532, 4.935, 4.935, 5.41, 5.557, 5.542, 5.119, 5.384, 5.169, 5.337, 5.127, 5.129, 5.076, 5.602, 5.328, 5.278, 5.301, 5.332, 4.954, 5.292, 5.349, 5.544, 5.412, 5.034, 5.276, 5.239, 5.018, 5.474, 5.349, 5.205, 5.295, 4.948, 5.396, 5.43, 6.048, 5.38, 5.271, 5.344, 6.153, 5.683, nan, 5.467, 5.351, 5.564, 5.5, 5.085, 5.639, 5.78, 5.78, 5.374, 5.35, 5.184, 5.377, 5.601, 5.257, 5.465, 5.346, 5.336, 5.33, 5.423, 5.279, 4.98, 5.277, 5.341, 5.451, 4.98, 5.163, 5.711, 5.428, 5.203, 5.528, 5.307, 5.518, 5.366, 5.304, 5.15, 5.713, 5.059, 6.427, 5.312, 5.297, 5.754, 5.091, 5.439, 5.869, 5.6]\n",
        "[7.28, 4.7, 4.7, 5.573, 6.146, 6.62, 4.6, 5.487, 5.247, nan, 4.815, 4.727, nan, nan, 5.987, 5.421, 6.28, 5.506, 2.7, 5.245, 4.153, 5.615, nan, 4.36, nan, 4.345, 4.902, 7.72, 5.083, 5.616, 5.847, 4.39, 6.11, 5.592, 6.032, nan, 4.592, nan, 4.98, 6.366, nan, 5.813, 5.58, 6.361, 5.973, nan, 6.481, nan, nan, 6.098, 5.372, 5.275, 5.422, 7.031, 5.252, 6.123, 5.267, 6.58, 6.005, 5.51, 5.222, nan, 5.488, 5.244, 5.407, nan, 4.647, 7.82, nan, 3.86, 6.98, nan, 6.68, nan, 6.44, nan, nan, 2.98, 6.36, 5.396, 5.537, 6.385, 4.897, 5.913, 6.14, 6.464]\n",
        "[6.172, 4.493, 4.493, 5.573, 6.146, 5.691, 5.092, 5.487, 5.247, 5.395, 4.815, 5.058, 5.22, 5.713, 5.987, 5.515, 5.98, 5.506, 4.13, 5.64, 4.153, 5.615, 5.422, 4.674, 5.32, 4.712, 4.902, 6.7, 5.293, 5.208, 5.52, 4.39, 6.11, 5.592, 6.142, 5.383, 5.112, 5.273, 6.153, 6.626, nan, 5.811, 5.712, 6.361, 6.437, 5.085, 6.039, 5.78, 5.78, 5.982, 5.372, 5.188, 5.418, 6.378, 5.252, 6.123, 5.505, 5.613, 6.005, 5.435, 5.477, nan, 5.593, 5.244, 5.534, nan, 4.768, 6.4, 5.48, 5.152, 5.995, 5.273, 5.853, 5.46, 5.453, 5.127, 5.713, 4.49, 6.393, 5.54, 5.637, 6.09, 4.926, 5.851, 5.594, 6.372]\n",
        "[31, 36, 36, 9, 27, 27, 28, 23, 28, 9, 17, 29, 46, 13, 36, 218, 142, 122, 8, 24, 28, 113, 27, 63, 30, 42, 22, 40, 98, 60, 40, 31, 23, 169, 23, 23, 135, 31, 15, 103, 51, 280, 45, 167, 77, 32, 80, 6, 6, 112, 100, 44, 209, 54, 57, 94, 25, 24, 65, 139, 177, 15, 82, 77, 46, 14, 49, 23, 16, 27, 25, 17, 24, 15, 11, 13, 6, 16, 16, 24, 24, 21, 60, 110, 11, 209]\n",
        "\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Avg sentiment (no exclusion):',stats.nanmean(avg_sent)\n",
      "print 'Avg sentiment (hard-code 1.0 spread exclusion):', stats.nanmean(avg_hard)\n",
      "print 'Avg sentiment (dynamic 20% exclusion):', stats.nanmean(avg_dyn)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Avg sentiment (no exclusion): 5.3758\n",
        "Avg sentiment (hard-code 1.0 spread exclusion): 5.56970588235\n",
        "Avg sentiment (dynamic 20% exclusion): 5.52221686747\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div class=\"Andrew\">\n",
      "Pandas dataframes make it easy to collect and reference the vectors we're creating.\n",
      "</div>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## make a pandas df out of these vectors for easy reference/manipulation\n",
      "post_df = pd.DataFrame(data={'avg word length':avg_word, \n",
      "                             'post length':post_length, \n",
      "                             'avg_sent_all':avg_sent,\n",
      "                             'avg_sent_hard':avg_hard,\n",
      "                             'avg_sent_dyn':avg_dyn})\n",
      "\n",
      "## some posts may get entered when technically they're not posts...just 0-length strings.  so exclude those.\n",
      "## we can probably get rid of these earlier on...\n",
      "trimmed_post_df = post_df[post_df['post length'] > 1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div class=\"Andrew\">\n",
      "We can do simple Pearson's correlation statistics to see whether there's any relationship between our variables of interest.\n",
      "</div>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## remove list-wise all rows with NaN\n",
      "nonan_df = trimmed_post_df.copy()\n",
      "nonan_df = nonan_df.dropna()\n",
      "\n",
      "## put values into better-named variables\n",
      "word_len = nonan_df['avg word length'].values\n",
      "post_len = nonan_df['post length'].values\n",
      "sentiment_all = nonan_df['avg_sent_all'].values\n",
      "sentiment_hard = nonan_df['avg_sent_hard'].values\n",
      "sentiment_dynamic = nonan_df['avg_sent_dyn'].values\n",
      "\n",
      "## get z-scores of sentiment vectors\n",
      "sentiment_all_Z = stats.mstats.zscore(sentiment_all)\n",
      "sentiment_hard_Z = stats.mstats.zscore(sentiment_hard)\n",
      "sentiment_dynamic_Z = stats.mstats.zscore(sentiment_dynamic)\n",
      "\n",
      "## pearsonr() gives a tuple of (Pearson zero-order correlation, p-value)\n",
      "\n",
      "## here we print out the correlation matrix for avg word length, post length, and avg sentiment\n",
      "## (not very pretty though - better to output in a readable table, a la SPSS)\n",
      "\n",
      "print 'avg word length : post length'\n",
      "word_post = stats.pearsonr(word_len, post_len)\n",
      "print 'Correlation coefficient:', round(word_post[0],3)\n",
      "print 'P-value:', round(word_post[1],3)\n",
      "print '\\n\\n'\n",
      "\n",
      "print 'word length : avg sentiment'\n",
      "word_sent_all = stats.pearsonr(word_len, sentiment_all)\n",
      "print 'Correlation coefficient:', round(word_sent_all[0],3)\n",
      "print 'P-value:', round(word_sent_all[1],3)\n",
      "\n",
      "print '\\n'\n",
      "\n",
      "print 'word length : abs val sentiment z-scores [no-exclude]'\n",
      "word_sent_all_z = stats.pearsonr(word_len, np.absolute(sentiment_all_Z))\n",
      "print 'Correlation coefficient:', round(word_sent_all_z[0],3)\n",
      "print 'P-value:', round(word_sent_all_z[1],3)\n",
      "\n",
      "print '\\n'\n",
      "\n",
      "print 'post length : avg sentiment'\n",
      "post_sent_all = stats.pearsonr(post_len, sentiment_all)\n",
      "print 'Correlation coefficient:', round(post_sent_all[0],3)\n",
      "print 'P-value:', round(post_sent_all[1],3)\n",
      "\n",
      "print '\\n'\n",
      "\n",
      "print 'post length : abs val sentiment z-scores [no-exclude]'\n",
      "post_sent_all_z = stats.pearsonr(post_len, np.absolute(sentiment_all_Z))\n",
      "print 'Correlation coefficient:', round(post_sent_all_z[0],3)\n",
      "print 'P-value:', round(post_sent_all_z[1],3)\n",
      "print '\\n\\n'\n",
      "\n",
      "\n",
      "print 'word length : avg sentiment hard-coded'\n",
      "word_sent_hard = stats.pearsonr(word_len, sentiment_hard)\n",
      "print 'Correlation coefficient:', round(word_sent_hard[0],3)\n",
      "print 'P-value:', round(word_sent_hard[1],3)\n",
      "\n",
      "print '\\n'\n",
      "\n",
      "print 'word length : abs val sentiment z-scores [hard-exclude]'\n",
      "word_sent_hard_z = stats.pearsonr(word_len, np.absolute(sentiment_hard_Z))\n",
      "print 'Correlation coefficient:', round(word_sent_hard_z[0],3)\n",
      "print 'P-value:', round(word_sent_hard_z[1],3)\n",
      "\n",
      "print '\\n'\n",
      "\n",
      "print 'post length : avg sentiment hard-coded'\n",
      "post_sent_hard = stats.pearsonr(post_len, sentiment_hard)\n",
      "print 'Correlation coefficient:', round(post_sent_hard[0],3)\n",
      "print 'P-value:', round(post_sent_hard[1],3)\n",
      "\n",
      "print '\\n'\n",
      "\n",
      "print 'post length : abs val sentiment z-scores [hard-exclude]'\n",
      "post_sent_hard_z = stats.pearsonr(post_len, np.absolute(sentiment_hard_Z))\n",
      "print 'Correlation coefficient:', round(post_sent_hard_z[0],3)\n",
      "print 'P-value:', round(post_sent_hard_z[1],3)\n",
      "\n",
      "print '\\n'\n",
      "\n",
      "print '\\n\\n'\n",
      "\n",
      "print 'avg word length : avg sentiment dynamically-coded'\n",
      "word_sent_dyn = stats.pearsonr(word_len, sentiment_dynamic)\n",
      "print 'Correlation coefficient:', round(word_sent_dyn[0],3)\n",
      "print 'P-value:', round(word_sent_dyn[1],3)\n",
      "\n",
      "print '\\n'\n",
      "\n",
      "print 'word length : abs val sentiment z-scores [dynamic-exclude]'\n",
      "word_sent_dyn_z = stats.pearsonr(word_len, np.absolute(sentiment_dynamic_Z))\n",
      "print 'Correlation coefficient:', round(word_sent_dyn_z[0],3)\n",
      "print 'P-value:', round(word_sent_dyn_z[1],3)\n",
      "\n",
      "print '\\n'\n",
      "\n",
      "print 'post length : avg sentiment dynamically-coded'\n",
      "post_sent_dyn = stats.pearsonr(post_len, sentiment_dynamic)\n",
      "print 'Correlation coefficient:', round(post_sent_dyn[0],3)\n",
      "print 'P-value:', round(post_sent_dyn[1],3)\n",
      "\n",
      "print '\\n'\n",
      "\n",
      "print 'post length : abs val sentiment z-scores [dynamic-exclude]'\n",
      "post_sent_dyn_z = stats.pearsonr(post_len, np.absolute(sentiment_dynamic_Z))\n",
      "print 'Correlation coefficient:', round(post_sent_dyn_z[0],3)\n",
      "print 'P-value:', round(post_sent_dyn_z[1],3)\n",
      "\n",
      "print '\\n'\n",
      "\n",
      "\n",
      "## plt.scatter(word_len, np.absolute(sentiment_hard_Z))\n",
      "## plt.show()\n",
      "plt.scatter(post_len, np.absolute(sentiment_hard_Z))\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "avg word length : post length\n",
        "Correlation coefficient: -0.18\n",
        "P-value: 0.142\n",
        "\n",
        "\n",
        "\n",
        "word length : avg sentiment\n",
        "Correlation coefficient: 0.425\n",
        "P-value: 0.0\n",
        "\n",
        "\n",
        "word length : abs val sentiment z-scores [no-exclude]\n",
        "Correlation coefficient: 0.43\n",
        "P-value: 0.0\n",
        "\n",
        "\n",
        "post length : avg sentiment\n",
        "Correlation coefficient: 0.023\n",
        "P-value: 0.853\n",
        "\n",
        "\n",
        "post length : abs val sentiment z-scores [no-exclude]\n",
        "Correlation coefficient: -0.319\n",
        "P-value: 0.008\n",
        "\n",
        "\n",
        "\n",
        "word length : avg sentiment hard-coded\n",
        "Correlation coefficient: 0.15\n",
        "P-value: 0.223\n",
        "\n",
        "\n",
        "word length : abs val sentiment z-scores [hard-exclude]\n",
        "Correlation coefficient: 0.007\n",
        "P-value: 0.954\n",
        "\n",
        "\n",
        "post length : avg sentiment hard-coded\n",
        "Correlation coefficient: 0.096\n",
        "P-value: 0.434\n",
        "\n",
        "\n",
        "post length : abs val sentiment z-scores [hard-exclude]\n",
        "Correlation coefficient: -0.33\n",
        "P-value: 0.006\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "avg word length : avg sentiment dynamically-coded\n",
        "Correlation coefficient: 0.195\n",
        "P-value: 0.111\n",
        "\n",
        "\n",
        "word length : abs val sentiment z-scores [dynamic-exclude]\n",
        "Correlation coefficient: 0.085\n",
        "P-value: 0.491\n",
        "\n",
        "\n",
        "post length : avg sentiment dynamically-coded\n",
        "Correlation coefficient: 0.191\n",
        "P-value: 0.119\n",
        "\n",
        "\n",
        "post length : abs val sentiment z-scores [dynamic-exclude]\n",
        "Correlation coefficient: -0.206\n",
        "P-value: 0.092\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div class=\"Andrew\">\n",
      "<b>Nov 19, initial observations</b>\n",
      "<br /><br />\n",
      "It looks like word length and sentiment is trending toward a significant positive correlation, and possibly post length and avg sentiment heading towards a negative.  \n",
      "<br />\n",
      "    It's a really small sample compared to our entire corpus, so best to retain some skepticism...next is to run on a dozen or so major search terms and look at the aggregate correlations.</div>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div class=\"Andrew\">\n",
      "<b>Nov 26 update (after our meeting):</b>\n",
      "<br /><br />\n",
      "One thing I overlooked in the initial round of correlations was that we're missing information on some of our original hypotheses.  (Not to say these can't change, but still.)  We had initially predicted that word length would increase as sentiment became more extreme - in both directions.  So, people who are fired up speak/write in shorter words.  Right now, the correlation coefficient only considers a unidirectional trend - going from negative sentiment (low scores) to positive sentiment (high scores).  Same thing with word length.  \n",
      "<br />\n",
      "I'm going to try and reroute some of these correlations to better account for these predictions.  I think the way to do this is to convert sentiment values in a given article into z-scores, then compile a vector of absolute values of these scores and regress these scores on predictors.\n",
      "<br /><br />\n",
      "We're using several keywords now, but still picked somewhat arbitrarily.  Next step is to get most popular media keywords off of mediacloud.\n",
      "\n",
      "</div>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##\n",
      "## regression attempt using sklearn\n",
      "##\n",
      "\n",
      "print hard['avg word length'].values\n",
      "clf = linear_model.LinearRegression()\n",
      "clf.fit([hard['avg word length'].values, hard['post length'].values], hard['avg_sent_hard'].values)\n",
      "print clf.coef_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "incompatible dimensions",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-10-4f5b82f7147f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mhard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg word length'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg word length'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'post length'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_sent_hard'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/python.app/Contents/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, n_jobs)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresidues_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingular_\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m                 \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/python.app/Contents/lib/python2.7/site-packages/scipy/linalg/basic.pyc\u001b[0m in \u001b[0;36mlstsq\u001b[0;34m(a, b, cond, overwrite_a, overwrite_b, check_finite)\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0mnrhs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'incompatible dimensions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m     \u001b[0mgelss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lapack_funcs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gelss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: incompatible dimensions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[]\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Everything below is pasted from HW3...it's where we want to go next.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = leads\n",
      "print \"Original text is\\n\", '\\n'.join(text)\n",
      "\n",
      "vectorizer = CountVectorizer(min_df=0)\n",
      "\n",
      "# call `fit` to build the vocabulary\n",
      "vectorizer.fit(text)\n",
      "\n",
      "# call `transform` to convert text to a bag of words\n",
      "x = vectorizer.transform(text)\n",
      "\n",
      "# CountVectorizer uses a sparse array to save memory, but it's easier in this assignment to \n",
      "# convert back to a \"normal\" numpy array\n",
      "x = x.tocsc()\n",
      "\n",
      "#print\n",
      "#print \"Transformed text vector is \\n\", x\n",
      "\n",
      "# `get_feature_names` tracks which word is associated with each column of the transformed x\n",
      "print\n",
      "print \"Words for each feature:\"\n",
      "print vectorizer.get_feature_names()\n",
      "\n",
      "# Notice that the bag of words treatment doesn't preserve information about the *order* of words, \n",
      "# just their frequency"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Original text is\n",
        "The sky is falling! The sky is falling. When it comes to all the talk of economic catastrophe, why are these disaster fantasies taken so seriously?\n",
        "It\u2019s another case of ideology posing as economic analysis.\n",
        "The International Paper Company, manufacturing subsidiary of the International Paper and Power Company, reported yesterday a net loss of $2,413,866 for 1934, after $595.849 profit from bonds redeemed in the year. This compared with a net loss of $4,430,528, after profit of $913,937 from bonds redeemed, in 1933.\n",
        "Will inflation phobia tear Europe apart after the establishment of a common currency was supposed to unite the Continent?\n",
        "After being sentenced in April 1982 to 15 years to life in prison for killing a waiter in Manhattan, Jack Henry Abbott was found liable for monetary damages sought by the victim's widow. A State Supreme Court justice ordered a civil trial to determine how much money the widow, Ricci Adan, should get.\n",
        "few years threatened the developing countries and the world financial system, suddenly over? Or is it just taking a holiday? William R. Rhodes of Citicorp, who has been head of the committee of banks negotiating with the Latin American countries over the rescheduling of their debts, warns against complacency that ''the debt bomb has been defused.'' ''That characterization is too strong,'' he said at a conference on the third world at Duke University this week. ''The reality is that a great deal remains to be done before these countries get back on the road to the growth they have enjoyed in the past.''\n",
        "So much treasure, so much waste. Italy is a cautionary tale of problems unfixed and pessimism unredeemed.\n",
        "In 2008, a year when the global financial system was falling apart and markets panicked, these investors didn\u2019t. How three big risks, taken by three firms, turned to gold.\n",
        "\n",
        "Words for each feature:\n",
        "[u'15', u'1933', u'1934', u'1982', u'2008', u'413', u'430', u'528', u'595', u'849', u'866', u'913', u'937', u'abbott', u'adan', u'after', u'against', u'all', u'american', u'analysis', u'and', u'another', u'apart', u'april', u'are', u'as', u'at', u'back', u'banks', u'be', u'been', u'before', u'being', u'big', u'bomb', u'bonds', u'by', u'case', u'catastrophe', u'cautionary', u'characterization', u'citicorp', u'civil', u'comes', u'committee', u'common', u'company', u'compared', u'complacency', u'conference', u'continent', u'countries', u'court', u'currency', u'damages', u'deal', u'debt', u'debts', u'defused', u'determine', u'developing', u'didn', u'disaster', u'done', u'duke', u'economic', u'enjoyed', u'establishment', u'europe', u'falling', u'fantasies', u'few', u'financial', u'firms', u'for', u'found', u'from', u'get', u'global', u'gold', u'great', u'growth', u'has', u'have', u'he', u'head', u'henry', u'holiday', u'how', u'ideology', u'in', u'inflation', u'international', u'investors', u'is', u'it', u'italy', u'jack', u'just', u'justice', u'killing', u'latin', u'liable', u'life', u'loss', u'manhattan', u'manufacturing', u'markets', u'monetary', u'money', u'much', u'negotiating', u'net', u'of', u'on', u'or', u'ordered', u'over', u'panicked', u'paper', u'past', u'pessimism', u'phobia', u'posing', u'power', u'prison', u'problems', u'profit', u'reality', u'redeemed', u'remains', u'reported', u'rescheduling', u'rhodes', u'ricci', u'risks', u'road', u'said', u'sentenced', u'seriously', u'should', u'sky', u'so', u'sought', u'state', u'strong', u'subsidiary', u'suddenly', u'supposed', u'supreme', u'system', u'taken', u'taking', u'tale', u'talk', u'tear', u'that', u'the', u'their', u'these', u'they', u'third', u'this', u'threatened', u'three', u'to', u'too', u'treasure', u'trial', u'turned', u'unfixed', u'unite', u'university', u'unredeemed', u'victim', u'waiter', u'warns', u'was', u'waste', u'week', u'when', u'who', u'why', u'widow', u'will', u'william', u'with', u'world', u'year', u'years', u'yesterday']\n"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_xy(pa, vectorizer=None):\n",
      "    #Your code here    \n",
      "\n",
      "    X = []\n",
      "    Y = []\n",
      "    \n",
      "    # if no vectorizer is passed to function, create one with min_df=0\n",
      "    if vectorizer == None:\n",
      "        \n",
      "        vectorizer = CountVectorizer(min_df=0)\n",
      "    \n",
      "    # fit vectorizer to entire quote repertoire\n",
      "    vectorizer.fit(critics.quote)\n",
      "    # make bag of words from quotes\n",
      "    X = vectorizer.transform(critics.quote)\n",
      "    \n",
      "    # convert fresh/rotten (strings) to 1/0 ints\n",
      "    for idx, q in enumerate(critics['quote']):\n",
      "        \n",
      "        fresh = critics['fresh'].irow(idx)\n",
      "        if fresh == 'fresh':\n",
      "            val = 1\n",
      "        elif fresh == 'rotten':\n",
      "            val = 0\n",
      "        Y.append(val)\n",
      "    \n",
      "    # return X/Y\n",
      "    # X can stay as a scarce array for now, Y covert from list to numpy array\n",
      "    return X,np.asarray(Y)\n",
      "\n",
      "X, Y = make_xy(critics)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 91,
       "text": [
        "\"def make_xy(pa, vectorizer=None):\\n    #Your code here    \\n\\n    X = []\\n    Y = []\\n    \\n    # if no vectorizer is passed to function, create one with min_df=0\\n    if vectorizer == None:\\n        \\n        vectorizer = CountVectorizer(min_df=0)\\n    \\n    # fit vectorizer to entire quote repertoire\\n    vectorizer.fit(critics.quote)\\n    # make bag of words from quotes\\n    X = vectorizer.transform(critics.quote)\\n    \\n    # convert fresh/rotten (strings) to 1/0 ints\\n    for idx, q in enumerate(critics['quote']):\\n        \\n        fresh = critics['fresh'].irow(idx)\\n        if fresh == 'fresh':\\n            val = 1\\n        elif fresh == 'rotten':\\n            val = 0\\n        Y.append(val)\\n    \\n    # return X/Y\\n    # X can stay as a scarce array for now, Y covert from list to numpy array\\n    return X,np.asarray(Y)\\n\\nX, Y = make_xy(critics)\\n\""
       ]
      }
     ],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}