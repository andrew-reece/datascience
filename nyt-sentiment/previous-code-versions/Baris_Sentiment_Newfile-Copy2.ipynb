{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Team - Predictive Model\n",
      "Baris Baloglu & Javier Pineda (de Mar)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### QuickRuns:\n",
      "Description: under each key section a quickrun bar helps to quickly navigate to the next necessary step of the parts of the notebook to improve overview and increase speed while running specific parts of the project:\n",
      "<br>\n",
      "\n",
      "<a href=\"#import_data\">Stanford</a>\n",
      "<br>\n",
      "<a href=\"#import_data\">Rottentomatoes</a>\n",
      "<br>\n",
      "<a href=\"#import_data\">NewYorkTimes</a>\n",
      "<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 1. Importing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 1.1 Normal Import Statements <a name=\"import_data\"></a>\n",
      "Collecting all import statements and global settings together in one spot."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#test if canvas stays in on plt.show\n",
      "%matplotlib inline\n",
      "# Not sure what we'll need exactly, so just importing all the usual suspects here\n",
      "import json\n",
      "import requests\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import re\n",
      "import scipy.stats as stats\n",
      "import os, sys\n",
      "import math\n",
      "import time\n",
      "\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "\n",
      "\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "#%pylab inline\n",
      "\n",
      "pd.set_option('display.width', 500)\n",
      "pd.set_option('display.max_columns', 30)\n",
      "\n",
      "# set some nicer defaults for matplotlib\n",
      "from matplotlib import rcParams\n",
      "\n",
      "#these colors come from colorbrewer2.org. Each is an RGB triplet\n",
      "dark2_colors = [(0.10588235294117647, 0.6196078431372549, 0.4666666666666667),\n",
      "                (0.8509803921568627, 0.37254901960784315, 0.00784313725490196),\n",
      "                (0.4588235294117647, 0.4392156862745098, 0.7019607843137254),\n",
      "                (0.9058823529411765, 0.1607843137254902, 0.5411764705882353),\n",
      "                (0.4, 0.6509803921568628, 0.11764705882352941),\n",
      "                (0.9019607843137255, 0.6705882352941176, 0.00784313725490196),\n",
      "                (0.6509803921568628, 0.4627450980392157, 0.11372549019607843),\n",
      "                (0.4, 0.4, 0.4)]\n",
      "\n",
      "rcParams['figure.figsize'] = (10, 6)\n",
      "rcParams['figure.dpi'] = 150\n",
      "rcParams['axes.color_cycle'] = dark2_colors\n",
      "rcParams['lines.linewidth'] = 2\n",
      "rcParams['axes.grid'] = False\n",
      "rcParams['axes.facecolor'] = 'white'\n",
      "rcParams['font.size'] = 14\n",
      "rcParams['patch.edgecolor'] = 'none'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######<a href=\"#sentiment_data\">Stanford</a> - <a href=\"#sentiment_data\">RottenTomatoes</a> - <a href=\"#sentiment_data\">NewYorkTimes</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2. Get Data\n",
      "\n",
      "Collect all different data sources used as training data in one chapter. All data will be stored in a CSV-File for later usage.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 2.1 Sentiment Analysis Words (sentiment_df) (Run mandatory) <a name=\"sentiment_data\"></a>\n",
      "\n",
      "This is the sentiment data which is used as a reference for word sentiment scores. It is needed for almost all following actions this is why it should be run in any case."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read sentiment data from text file\n",
      "sentiment_df = pd.read_table('sentiment_data.txt', sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######<a href=\"#sf_make_data\">Stanford</a> - <a href=\"#rt_csv_get_data\">RottenTomatoes</a> - <a href=\"#nyt_csv_get_data\">NewYorkTimes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 2.2 Stanford MovieDB (stanford_df) <a name=\"sf_make_data\"></a>\n",
      "25k reviews divided in 12.5k positive ones and 12.5k negative. Ratings range from 1-10 for 1 negative and 10 positive. All neutral reviews have been excluded beforehand. Dataframe will be constructed from filesystem structure. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Set up function to create stanford dataframe. A function is used to create reusability for the later use in case of testing data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# here the parameter \"data_set\" is a string (either 'train' or 'test')\n",
      "def make_stanford_df(data_set):\n",
      "\n",
      "    # making lists of negative and positive training data filenames, respectively\n",
      "    path_neg = \"stanford_movie/%s/neg/\" % data_set\n",
      "    neg_list = os.listdir(path_neg)\n",
      "    \n",
      "    path_pos = \"stanford_movie/%s/pos/\" % data_set\n",
      "    pos_list = os.listdir(path_pos)\n",
      "    \n",
      "    # making sure we're only getting the filenames we want\n",
      "    # there seems to be hidden files at least in the neg folder\n",
      "    neg_list = [i for i in neg_list if i[0].isdigit()]\n",
      "    pos_list = [i for i in pos_list if i[0].isdigit()]\n",
      "    \n",
      "    # making dataframe for negative training data\n",
      "    neg_df = pd.DataFrame(neg_list, columns = ['filename'])\n",
      "    \n",
      "    neg_df['id'] = neg_df.apply(lambda x: \n",
      "                            'neg' + x['filename'][:x['filename'].index('_')], axis=1)\n",
      "    \n",
      "    neg_df['rating'] = neg_df.apply(lambda x: \n",
      "                            x['filename'][x['filename'].index('_')+1:-4], axis=1)\n",
      "    \n",
      "    neg_df['path'] = path_neg\n",
      "    \n",
      "    # making dataframe for positive training data\n",
      "    pos_df = pd.DataFrame(pos_list, columns = ['filename'])\n",
      "    pos_df['id'] = pos_df.apply(lambda x: \n",
      "                            'pos' + x['filename'][:x['filename'].index('_')], axis=1)\n",
      "    pos_df['rating'] = pos_df.apply(lambda x: \n",
      "                            x['filename'][x['filename'].index('_')+1:-4], axis=1)\n",
      "    \n",
      "    pos_df['path'] = path_pos\n",
      "    \n",
      "    # concatenating negative and positive training data into one dataframe\n",
      "    stanford_df = pd.concat([neg_df, pos_df], ignore_index=True)\n",
      "    \n",
      "    # adding column with the movie reviews\n",
      "    stanford_df['review'] = stanford_df.apply(lambda x: \n",
      "                            open(x['path'] + x['filename'], 'r').read(), axis=1)\n",
      "\n",
      "    return stanford_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######<a href=\"#sf_csv_get_data\">Stanford</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Call function to create dataframe:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stanford_df = make_stanford_df('train')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save dataframe to file:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stanford_df.to_csv('stanford_df.csv', index=False)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load dataframe from CSV: <a name=\"sf_csv_get_data\"></a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stanford_df = pd.read_csv('stanford_df.csv')\n",
      "stanford_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>filename</th>\n",
        "      <th>id</th>\n",
        "      <th>rating</th>\n",
        "      <th>path</th>\n",
        "      <th>review</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>     0_3.txt</td>\n",
        "      <td>     neg0</td>\n",
        "      <td> 3</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> Story of a man who has unnatural feelings for ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 10000_4.txt</td>\n",
        "      <td> neg10000</td>\n",
        "      <td> 4</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> Airport '77 starts as a brand new luxury 747 p...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 10001_4.txt</td>\n",
        "      <td> neg10001</td>\n",
        "      <td> 4</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> This film lacked something I couldn't put my f...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 10002_1.txt</td>\n",
        "      <td> neg10002</td>\n",
        "      <td> 1</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> Sorry everyone,,, I know this is supposed to b...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 10003_1.txt</td>\n",
        "      <td> neg10003</td>\n",
        "      <td> 1</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> When I was little my parents took me along to ...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "      filename        id  rating                       path                                             review\n",
        "0      0_3.txt      neg0       3  stanford_movie/train/neg/  Story of a man who has unnatural feelings for ...\n",
        "1  10000_4.txt  neg10000       4  stanford_movie/train/neg/  Airport '77 starts as a brand new luxury 747 p...\n",
        "2  10001_4.txt  neg10001       4  stanford_movie/train/neg/  This film lacked something I couldn't put my f...\n",
        "3  10002_1.txt  neg10002       1  stanford_movie/train/neg/  Sorry everyone,,, I know this is supposed to b...\n",
        "4  10003_1.txt  neg10003       1  stanford_movie/train/neg/  When I was little my parents took me along to ..."
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######<a href=\"#sf_csv_clean_data\">Stanford</a> - (<a href=\"#rt_csv_get_data\">RottenTomatoes</a> - <a href=\"#nyt_csv_get_data\">NewYorkTimes</a>)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some Statistics: <a name=\"sf_stat_get_data\"></a> \n",
      "<br>Compare with: <a href=\"#sf_stat_clean_data\">Clean</a>, <a href=\"#sf_stat_prep_data\">Prepare</a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'length of set:', len(stanford_df)\n",
      "print 'average postlength:', int(np.mean(stanford_df[~stanford_df.review.isnull()].review.apply(lambda x: len(x))))\n",
      "print 'number of positive reviews:', len(stanford_df[stanford_df.rating >= 7])\n",
      "print 'number of negative reviews:', len(stanford_df[stanford_df.rating <= 4])\n",
      "print 'max postlength', stanford_df[~stanford_df.review.isnull()].review.apply(lambda x: len(x)).max()\n",
      "print 'min postlength', stanford_df[~stanford_df.review.isnull()].review.apply(lambda x: len(x)).min()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of set: 25000\n",
        "average postlength: 1325\n",
        "number of positive reviews: 12500\n",
        "number of negative reviews: 12500\n",
        "max postlength "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13704\n",
        "min postlength 52\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 2.3 RottenTomatoes (rottentomatoes_df) <a name=\"rt_get_data\"></a>\n",
      "Around 8k reviews divided in about 6k fresh ones and 2k rotten. Rating's range is binary for 1 fresh and 0 rotten. No neutral reviews have been excluded beforehand. Dataframe will be constructed from local CSV file out of HW3. <a name=\"rt_csv_get_data\"></a> "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rottentomatoes_df = pd.read_csv('critics.csv')\n",
      "rottentomatoes_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>critic</th>\n",
        "      <th>fresh</th>\n",
        "      <th>imdb</th>\n",
        "      <th>publication</th>\n",
        "      <th>quote</th>\n",
        "      <th>review_date</th>\n",
        "      <th>rtid</th>\n",
        "      <th>title</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> Owen Gleiberman</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td> Entertainment Weekly</td>\n",
        "      <td>                                               NaN</td>\n",
        "      <td> 2011-09-07</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>     Derek Adams</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>             Time Out</td>\n",
        "      <td> So ingenious in concept, design and execution ...</td>\n",
        "      <td> 2009-10-04</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> Richard Corliss</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>        TIME Magazine</td>\n",
        "      <td>                 The year's most inventive comedy.</td>\n",
        "      <td> 2008-08-31</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>     David Ansen</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>             Newsweek</td>\n",
        "      <td> A winning animated feature that has something ...</td>\n",
        "      <td> 2008-08-18</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>   Leonard Klady</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>              Variety</td>\n",
        "      <td> The film sports a provocative and appealing st...</td>\n",
        "      <td> 2008-06-09</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "            critic  fresh    imdb           publication                                              quote review_date  rtid      title\n",
        "0  Owen Gleiberman  fresh  114709  Entertainment Weekly                                                NaN  2011-09-07  9559  Toy story\n",
        "1      Derek Adams  fresh  114709              Time Out  So ingenious in concept, design and execution ...  2009-10-04  9559  Toy story\n",
        "2  Richard Corliss  fresh  114709         TIME Magazine                  The year's most inventive comedy.  2008-08-31  9559  Toy story\n",
        "3      David Ansen  fresh  114709              Newsweek  A winning animated feature that has something ...  2008-08-18  9559  Toy story\n",
        "4    Leonard Klady  fresh  114709               Variety  The film sports a provocative and appealing st...  2008-06-09  9559  Toy story"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######(<a href=\"#sf_csv_get_data\">Stanford</a>) - <a href=\"#rt_csv_clean_data\">RottenTomatoes</a> - (<a href=\"#nyt_csv_get_data\">NewYorkTimes</a>)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some Statistics: <a name=\"rt_stat_get_data\"></a> \n",
      "<br>Compare with: <a href=\"#rt_stat_clean_data\">Clean</a>, <a href=\"#rt_stat_prep_data\">Prepare</a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'length of set:', len(rottentomatoes_df)\n",
      "print 'average postlength:', int(np.mean(rottentomatoes_df[~rottentomatoes_df.quote.isnull()].quote.apply(lambda x: len(x))))\n",
      "print 'number of positive reviews:', len(rottentomatoes_df[rottentomatoes_df.fresh == 'fresh'])\n",
      "print 'number of negative reviews:', len(rottentomatoes_df[rottentomatoes_df.fresh == 'rotten'])\n",
      "print 'max postlength', rottentomatoes_df[~rottentomatoes_df.quote.isnull()].quote.apply(lambda x: len(x)).max()\n",
      "print 'min postlength', rottentomatoes_df[~rottentomatoes_df.quote.isnull()].quote.apply(lambda x: len(x)).min()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of set: 27692\n",
        "average postlength: 117\n",
        "number of positive reviews: 11833\n",
        "number of negative reviews: 8458\n",
        "max postlength 256\n",
        "min postlength "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 2.4 New York Times DB (nytimes_df) <a name=\"nyt_get_data\"></a>\n",
      "Around XX lead paragraphs of articles based from given keyword arguments (article set can be changed by altering search parameter below). Note that lead paragraphs are low on words. Data is retrieved online and is saved into a CSV file in the end. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "API parameter: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## NYT API keys\n",
      "api_key_article = \"851e7d0a131bee9bc01097470c238637:13:47475506\"\n",
      "api_key_community = \"519167db119ee6408c4ee51b3c391e11:0:47475506\"\n",
      "api_key_geo = \"a984ad78bf017f0ade1fcd980aa6353f:15:47475506\"\n",
      "api_key_popular = \"09dfaf288ad6c2ec46893a27ca758d41:19:47475506\"\n",
      "api_key_movies = \"e8a48f7d7731698b05267146c681c352:5:47475506\"\n",
      "api_key_semantic = \"9063b41607bbf486247b8e596a1456b8:7:47475506\"\n",
      "api_key_newswire = \"209ebb7b0ab44094970e8b39c63fea7e:2:47475506\"\n",
      "api_key_timestags = \"43b3366f288db10cb019fd532299723f:10:47475506\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Search parameters: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "begindate = \"20000101\" #YYYYMMDD\n",
      "enddate = \"20131112\" #YYYYMMDD\n",
      "\n",
      "## just picked a few terms meant to have a fair spread in content\n",
      "terms = ['mindfulness', 'debt', 'kardashian', 'obama',\n",
      "         'romney', 'obamacare', 'god', 'terrorism', 'nazi', \n",
      "         'hussein', 'war', 'depression', 'abortion', 'sex']\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Get data from nytimes.com: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# intially an empty dataframe\n",
      "nytimes_df = pd.DataFrame()\n",
      "\n",
      "# loop through terms\n",
      "for term in terms:\n",
      "    \n",
      "    # api request for each term\n",
      "    url = ''.join([\"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=\", term,\n",
      "                   \"&begin_date=\", begindate, \n",
      "                   \"&end_date=\", enddate,\n",
      "                   \"&api-key=\",api_key_article])\n",
      "        \n",
      "    req = requests.get(url).text\n",
      "    \n",
      "    # decode into json dicts\n",
      "    jsons = json.loads(req)\n",
      "    \n",
      "    # loop through each article returned from API request\n",
      "    for doc in jsons['response']['docs']:\n",
      "\n",
      "        # making dataframe; a term will appear in multiple rows\n",
      "        doc_df = pd.DataFrame([term], columns = ['term'])\n",
      "        \n",
      "        # alternative way of dealing with none-types\n",
      "        if json.dumps(doc['abstract']) != 'null':\n",
      "        \n",
      "            # encode weird ascii stuff\n",
      "            abstract = [doc['abstract'].encode('utf-8')]\n",
      "            \n",
      "            # making dataframe and adding abstracts\n",
      "            doc_df['abstract'] = abstract\n",
      "            \n",
      "        # this way we take all data, and we can do away with what we don't want later    \n",
      "        else:\n",
      "            abstract = np.nan\n",
      "            doc_df['abstract'] = abstract\n",
      "            \n",
      "        # can add an if-else clause for anything you want to get, then add to doc_df\n",
      "        if json.dumps(doc['lead_paragraph']) != 'null':\n",
      "            \n",
      "            lead = [doc['lead_paragraph'].encode('utf-8')]\n",
      "            doc_df['lead'] = lead\n",
      "            \n",
      "        else:\n",
      "            lead = np.nan\n",
      "            doc_df['lead'] = lead\n",
      "        \n",
      "        nytimes_df = pd.concat([nytimes_df, doc_df]).reset_index(drop=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save dataframe to file:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nytimes_df.to_csv('nytimes_df.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load dataframe from CSV: <a name=\"nyt_csv_get_data\"></a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nytimes_df = pd.read_csv('nytimes_df.csv')\n",
      "nytimes_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>abstract</th>\n",
        "      <th>lead</th>\n",
        "      <th>term</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> Mindfulness is terrific for the person practic...</td>\n",
        "      <td> The other night at a dinner party, a friend de...</td>\n",
        "      <td> mindfulness</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>                                               NaN</td>\n",
        "      <td> Mindfulness is terrific for the person practic...</td>\n",
        "      <td> mindfulness</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> Jennifer Egan article on her experience at Spi...</td>\n",
        "      <td> Peter Williams sits cross-legged on an upholst...</td>\n",
        "      <td> mindfulness</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> Two-thirds of doctors experience the emotional...</td>\n",
        "      <td>                                               NaN</td>\n",
        "      <td> mindfulness</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> In this week's Doctor and Patient column, Dr. ...</td>\n",
        "      <td> Everybody has to multitask at work. But when d...</td>\n",
        "      <td> mindfulness</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "                                            abstract                                               lead         term\n",
        "0  Mindfulness is terrific for the person practic...  The other night at a dinner party, a friend de...  mindfulness\n",
        "1                                                NaN  Mindfulness is terrific for the person practic...  mindfulness\n",
        "2  Jennifer Egan article on her experience at Spi...  Peter Williams sits cross-legged on an upholst...  mindfulness\n",
        "3  Two-thirds of doctors experience the emotional...                                                NaN  mindfulness\n",
        "4  In this week's Doctor and Patient column, Dr. ...  Everybody has to multitask at work. But when d...  mindfulness"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######(<a href=\"#sf_csv_get_data\">Stanford</a> - <a href=\"#rt_csv_get_data\">RottenTomatoes</a>) - <a href=\"#nyt_csv_clean_data\">NewYorkTimes</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some Statistics: <a name=\"nyt_stat_get_data\"></a> \n",
      "<br>Compare with: <a href=\"#nyt_stat_clean_data\">Clean</a>, <a href=\"#nyt_stat_prep_data\">Prepare</a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'length of set:', len(nytimes_df)\n",
      "print 'average postlength:', int(np.mean(nytimes_df.lead[~nytimes_df.lead.isnull()].apply(lambda x: len(x))))\n",
      "print 'number of positive reviews:', 'currently unknown'\n",
      "print 'number of negative reviews:', 'currently unknown'\n",
      "print 'max postlength', nytimes_df.lead[~nytimes_df.lead.isnull()].apply(lambda x: len(x)).max()\n",
      "print 'min postlength', nytimes_df.lead[~nytimes_df.lead.isnull()].apply(lambda x: len(x)).min()\n",
      "                            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of set: 140\n",
        "average postlength: 325\n",
        "number of positive reviews: currently unknown\n",
        "number of negative reviews: currently unknown\n",
        "max postlength 1380\n",
        "min postlength 35\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 3. Clean Data\n",
      "\n",
      "Clear datasources from any empty or unneccassary data rows or specific entries.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 3.1 Stanford MovieDB (stanford_clean_df) <a name=\"sf_csv_clean_data\"></a>\n",
      "Currently no cleaning neccessary. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stanford_clean_df = stanford_df\n",
      "stanford_clean_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>filename</th>\n",
        "      <th>id</th>\n",
        "      <th>rating</th>\n",
        "      <th>path</th>\n",
        "      <th>review</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>     0_3.txt</td>\n",
        "      <td>     neg0</td>\n",
        "      <td> 3</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> Story of a man who has unnatural feelings for ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 10000_4.txt</td>\n",
        "      <td> neg10000</td>\n",
        "      <td> 4</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> Airport '77 starts as a brand new luxury 747 p...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 10001_4.txt</td>\n",
        "      <td> neg10001</td>\n",
        "      <td> 4</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> This film lacked something I couldn't put my f...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 10002_1.txt</td>\n",
        "      <td> neg10002</td>\n",
        "      <td> 1</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> Sorry everyone,,, I know this is supposed to b...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 10003_1.txt</td>\n",
        "      <td> neg10003</td>\n",
        "      <td> 1</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> When I was little my parents took me along to ...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "      filename        id  rating                       path                                             review\n",
        "0      0_3.txt      neg0       3  stanford_movie/train/neg/  Story of a man who has unnatural feelings for ...\n",
        "1  10000_4.txt  neg10000       4  stanford_movie/train/neg/  Airport '77 starts as a brand new luxury 747 p...\n",
        "2  10001_4.txt  neg10001       4  stanford_movie/train/neg/  This film lacked something I couldn't put my f...\n",
        "3  10002_1.txt  neg10002       1  stanford_movie/train/neg/  Sorry everyone,,, I know this is supposed to b...\n",
        "4  10003_1.txt  neg10003       1  stanford_movie/train/neg/  When I was little my parents took me along to ..."
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######<a href=\"#prep_features\">Stanford</a> - (<a href=\"#rt_csv_clean_data\">RottenTomatoes</a> - <a href=\"#nyt_csv_clean_data\">NewYorkTimes</a>)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some Statistics: <a name=\"sf_stat_celan_data\"></a> \n",
      "<br>Compare with: <a href=\"#sf_stat_get_data\">Plain</a>, <a href=\"#sf_stat_prep_data\">Prepare</a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'length of set:', len(stanford_clean_df)\n",
      "print 'average postlength:', int(np.mean(stanford_clean_df[~stanford_clean_df.review.isnull()].review.apply(lambda x: len(x))))\n",
      "print 'number of positive reviews:', len(stanford_clean_df[stanford_clean_df.rating >= 7])\n",
      "print 'number of negative reviews:', len(stanford_clean_df[stanford_clean_df.rating <= 4])\n",
      "print 'max postlength', stanford_clean_df[~stanford_clean_df.review.isnull()].review.apply(lambda x: len(x)).max()\n",
      "print 'min postlength', stanford_clean_df[~stanford_clean_df.review.isnull()].review.apply(lambda x: len(x)).min()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of set: 25000\n",
        "average postlength: 1325\n",
        "number of positive reviews: 12500\n",
        "number of negative reviews: 12500\n",
        "max postlength "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13704\n",
        "min postlength 52\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 3.2 RottenTomatoes (rottentomatoes_clean_df)\n",
      "Around 8k reviews divided in about 6k fresh ones and 2k rotten. Rating's range is binary for 1 fresh and 0 rotten. No neutral reviews have been excluded beforehand. Dataframe will be constructed from local CSV file out of HW3. <a name=\"rt_csv_get_data\"></a> "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rottentomatoes_clean_df = rottentomatoes_df[~rottentomatoes_df.quote.isnull()]\n",
      "rottentomatoes_clean_df = rottentomatoes_clean_df[rottentomatoes_clean_df.fresh != 'none']\n",
      "rottentomatoes_clean_df = rottentomatoes_clean_df[rottentomatoes_clean_df.quote.str.len() > 0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save dataframe to file:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rottentomatoes_clean_df.to_csv('rottentomatoes_clean_df.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load dataframe from CSV: <a name=\"rt_csv_clean_data\"></a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rottentomatoes_clean_df = pd.read_csv('rottentomatoes_clean_df.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######(<a href=\"#sf_csv_clean_data\">Stanford</a>) - <a href=\"#prep_features\">RottenTomatoes</a> - (<a href=\"#nyt_csv_clean_data\">NewYorkTimes</a>)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some Statistics: <a name=\"rt_stat_clean_data\"></a> \n",
      "<br>Compare with: <a href=\"#rt_stat_get_data\">Plain</a>, <a href=\"#rt_stat_prep_data\">Prepare</a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rottentomatoes_clean_df = pd.read_csv('rottentomatoes_clean_df.csv')\n",
      "print 'length of set:', len(rottentomatoes_clean_df)\n",
      "print 'average postlength:', int(np.mean(rottentomatoes_clean_df.quote.apply(lambda x: len(x))))\n",
      "print 'number of positive reviews:', len(rottentomatoes_clean_df[rottentomatoes_clean_df.fresh == 'fresh'])\n",
      "print 'number of negative reviews:', len(rottentomatoes_clean_df[rottentomatoes_clean_df.fresh == 'rotten'])\n",
      "print 'max postlength', rottentomatoes_clean_df.quote.apply(lambda x: len(x)).max()\n",
      "print 'min postlength', rottentomatoes_clean_df.quote.apply(lambda x: len(x)).min()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of set: 15572\n",
        "average postlength: 117\n",
        "number of positive reviews: 9486\n",
        "number of negative reviews: 6086\n",
        "max postlength 256\n",
        "min postlength 4\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 3.3 New York Times DB (nytimes_clean_df)\n",
      "Eliminate all empty lead paragraphs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nytimes_clean_df = nytimes_df[~nytimes_df.lead.isnull()]\n",
      "nytimes_clean_df = nytimes_clean_df[nytimes_clean_df.lead != 'none']\n",
      "nytimes_clean_df = nytimes_clean_df[nytimes_clean_df.lead.str.len() > 0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save dataframe to file:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nytimes_clean_df.to_csv('nytimes_clean_df.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load dataframe from CSV: <a name=\"nyt_csv_clean_data\"></a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nytimes_clean_df = pd.read_csv('nytimes_clean_df.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######(<a href=\"#sf_csv_clean_data\">Stanford</a> - <a href=\"#rt_csv_clean_data\">RottenTomatoes</a>) - <a href=\"#prep_features\">NewYorkTimes</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some Statistics: <a name=\"nyt_stat_clean_data\"></a> \n",
      "<br>Compare with: <a href=\"#nyt_stat_get_data\">Plain</a>, <a href=\"#nyt_stat_prep_data\">Prepare</a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'length of set:', len(nytimes_clean_df)\n",
      "print 'average postlength:', int(np.mean(nytimes_clean_df.lead.apply(lambda x: len(x))))\n",
      "print 'number of positive reviews:', 'currently unknown'\n",
      "print 'number of negative reviews:', 'currently unknown'\n",
      "print 'max postlength', nytimes_clean_df.lead.apply(lambda x: len(x)).max()\n",
      "print 'min postlength', nytimes_clean_df.lead.apply(lambda x: len(x)).min()\n",
      "                            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of set: 134\n",
        "average postlength: 325\n",
        "number of positive reviews: currently unknown\n",
        "number of negative reviews: currently unknown\n",
        "max postlength 1380\n",
        "min postlength 35\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 4. Prepare Data\n",
      "\n",
      "Prepare datasources with neccessary extenstion including required featurelist. Result will be stored in local CSV files.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Features <a name=\"prep_features\"></a>\n",
      "Collection of feature methods that can be called by dataframe to apply on all rows."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def post_length(text):\n",
      "    \n",
      "    words_df = pd.DataFrame(text.split(' '), columns=['words'])\n",
      "    words_df['words'] = words_df.words.apply(lambda x: str.lower(re.sub(\"\\W\", '', x)))\n",
      "    words_df['word_length'] = words_df.words.apply(lambda x: len(x))\n",
      "    words_df = words_df[words_df.word_length > 0]\n",
      "    tot_word_count = len(words_df)\n",
      "    \n",
      "    return tot_word_count\n",
      "\n",
      "\n",
      "def avg_word_length(text):\n",
      "\n",
      "    words_df = pd.DataFrame(text.split(' '), columns=['words'])\n",
      "    words_df['words'] = words_df.words.apply(lambda x: str.lower(re.sub(\"\\W\", '', x)))           \n",
      "    words_df['word_length'] = words_df.words.apply(lambda x: len(x))\n",
      "    words_df = words_df[words_df.word_length > 0]      \n",
      "    average_length = round(np.mean(words_df.word_length.values), 2)\n",
      "    \n",
      "    return average_length\n",
      "\n",
      "\n",
      "def avg_senti_score(text):\n",
      "    #now = time.time()\n",
      "    words_df = pd.DataFrame(text.split(' '), columns=['words'])\n",
      "    words_df['words'] = words_df.words.apply(lambda x: str.lower(re.sub(\"\\W\", '', x)))\n",
      "    words_df['word_length'] = words_df.words.apply(lambda x: len(x))\n",
      "    words_df = words_df[words_df.word_length > 0]\n",
      "    words_df['in_sentiment'] = False\n",
      "    words_df['in_sentiment'][words_df.words.isin(sentiment_df.word)] = True\n",
      "    words_df['happiness_avg'] = np.nan\n",
      "    words_df['happiness_avg'][words_df.in_sentiment == True] = words_df.words[words_df.in_sentiment == True].apply(lambda x: \n",
      "                float(sentiment_df.happiness_average[sentiment_df.word == x].values))\n",
      "    average_score = round(np.mean(words_df.happiness_avg[~words_df.happiness_avg.isnull()].values), 3)\n",
      "    #later = time.time()\n",
      "    #print 'time used for entry:', float(later - now)\n",
      "\n",
      "    return float(average_score)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######<a href=\"#prep_function\">Stanford</a> - <a href=\"#prep_function\">RottenTomatoes</a> - <a href=\"#prep_function\">NewYorkTimes</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Prepare Function <a name=\"prep_function\"></a>\n",
      "\n",
      "This function will add the desired feature columns to any dataframe that has a column of texts."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \"text_col\" parameter is the column name (string) where the text is\n",
      "# features parameter is a list of functions to implement on the dataframe\n",
      "def make_prep_df(df, text_col, features):\n",
      "    \n",
      "    # making copy of dataframe\n",
      "    df_copy = df.copy()\n",
      "    \n",
      "    # renaming text column to make it easy to deal with\n",
      "    df_copy = df_copy.rename(columns={text_col: 'text_col'})\n",
      "    \n",
      "    # deleting rows where there are no words in the text column\n",
      "    df_copy = df_copy[~df_copy.text_col.isnull()].reset_index(drop=True)\n",
      "    \n",
      "    #map(features, lambda x: df_copy[x.__name__] = np.nan)\n",
      "    #map(features, lambda y: df_copy[y.__name__] = df_copy.text_col.apply(lambda x: y(x)))\n",
      "    \n",
      "    for func in features:\n",
      "        # making a column that has the same name as the function\n",
      "        df_copy[func.__name__] = np.nan\n",
      "        df_copy[func.__name__] = df_copy.text_col.apply(lambda x: func(x))\n",
      "        \n",
      "    # deleting rows where there is no average sentiment score\n",
      "    #df_copy = df_copy[~df_copy.avg_senti_score.isnull()]\n",
      "    #df_copy = df_copy.sort('avg_senti_score', ascending=False).reset_index(drop=True)\n",
      "    \n",
      "    # changing text column back to its original name\n",
      "    df_copy = df_copy.rename(columns={'text_col': text_col})\n",
      "    \n",
      "    # returns prepared dataframe\n",
      "    return df_copy\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######<a href=\"#sf_csv_prep_data\">Stanford</a> - <a href=\"#rt_csv_prep_data\">RottenTomatoes</a> - <a href=\"#nyt_csv_prep_data\">NewYorkTimes</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 4.1 Stanford MovieDB (stanford_prep_df)\n",
      "Add feature columns for Stanford MovieDB:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "functions = [post_length, avg_word_length, avg_senti_score]\n",
      "\n",
      "stanford_prep_df = make_prep_df(stanford_clean_df, 'review', functions)\n",
      "stanford_prep_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save dataframe to file:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stanford_prep_df.to_csv('stanford_prep_df.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load dataframe from CSV: <a name=\"sf_csv_prep_data\"></a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stanford_prep_df = pd.read_csv('stanford_prep_df.csv')\n",
      "stanford_prep_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>filename</th>\n",
        "      <th>id</th>\n",
        "      <th>rating</th>\n",
        "      <th>path</th>\n",
        "      <th>review</th>\n",
        "      <th>post_length</th>\n",
        "      <th>avg_word_length</th>\n",
        "      <th>avg_senti_score</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  5949_10.txt</td>\n",
        "      <td>  pos5949</td>\n",
        "      <td> 10</td>\n",
        "      <td> stanford_movie/train/pos/</td>\n",
        "      <td> Hello again, I have to comment on this wonderf...</td>\n",
        "      <td> 50</td>\n",
        "      <td> 5.24</td>\n",
        "      <td> 6.145</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 11062_10.txt</td>\n",
        "      <td> pos11062</td>\n",
        "      <td> 10</td>\n",
        "      <td> stanford_movie/train/pos/</td>\n",
        "      <td> Real cool, smart movie. I loved Sheedy's color...</td>\n",
        "      <td> 41</td>\n",
        "      <td> 4.80</td>\n",
        "      <td> 6.116</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>   7881_9.txt</td>\n",
        "      <td>  pos7881</td>\n",
        "      <td>  9</td>\n",
        "      <td> stanford_movie/train/pos/</td>\n",
        "      <td> What fun! Bucketfuls of good humor, terrific c...</td>\n",
        "      <td> 28</td>\n",
        "      <td> 7.04</td>\n",
        "      <td> 6.111</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>  2190_10.txt</td>\n",
        "      <td>  pos2190</td>\n",
        "      <td> 10</td>\n",
        "      <td> stanford_movie/train/pos/</td>\n",
        "      <td> Touching; Well directed autobiography of a tal...</td>\n",
        "      <td> 22</td>\n",
        "      <td> 5.82</td>\n",
        "      <td> 6.108</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 11060_10.txt</td>\n",
        "      <td> pos11060</td>\n",
        "      <td> 10</td>\n",
        "      <td> stanford_movie/train/pos/</td>\n",
        "      <td> This movie is wonderful. The writing, directin...</td>\n",
        "      <td> 45</td>\n",
        "      <td> 5.87</td>\n",
        "      <td> 6.078</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "       filename        id  rating                       path                                             review  post_length  avg_word_length  avg_senti_score\n",
        "0   5949_10.txt   pos5949      10  stanford_movie/train/pos/  Hello again, I have to comment on this wonderf...           50             5.24            6.145\n",
        "1  11062_10.txt  pos11062      10  stanford_movie/train/pos/  Real cool, smart movie. I loved Sheedy's color...           41             4.80            6.116\n",
        "2    7881_9.txt   pos7881       9  stanford_movie/train/pos/  What fun! Bucketfuls of good humor, terrific c...           28             7.04            6.111\n",
        "3   2190_10.txt   pos2190      10  stanford_movie/train/pos/  Touching; Well directed autobiography of a tal...           22             5.82            6.108\n",
        "4  11060_10.txt  pos11060      10  stanford_movie/train/pos/  This movie is wonderful. The writing, directin...           45             5.87            6.078"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######<a href=\"#train_data\">Stanford</a> - (<a href=\"rt_csv_prep_data\">RottenTomatoes</a> - <a href=\"#nyt_csv_prep_data\">NewYorkTimes</a>)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some Statistics: <a name=\"sf_stat_prep_data\"></a> \n",
      "<br>Compare with: <a href=\"#sf_stat_get_data\">Plain</a>, <a href=\"#sf_stat_clean_data\">Clean</a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'length of set:', len(stanford_prep_df)\n",
      "print 'average postlength:', int(np.mean(stanford_prep_df.review.apply(lambda x: len(x))))\n",
      "print 'number of positive reviews:', len(stanford_prep_df[stanford_prep_df.rating >= 7])\n",
      "print 'number of negative reviews:', len(stanford_prep_df[stanford_prep_df.rating <= 4])\n",
      "print 'max postlength', stanford_prep_df.review.apply(lambda x: len(x)).max()\n",
      "print 'min postlength', stanford_prep_df.review.apply(lambda x: len(x)).min()\n",
      "                            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of set: 25000\n",
        "average postlength: 1325\n",
        "number of positive reviews: 12500\n",
        "number of negative reviews: 12500\n",
        "max postlength 13704\n",
        "min postlength "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "52\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 4.2 RottenTomatoes (rottentomatoes_prep_df)\n",
      "Add feature columns:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "functions = [post_length, avg_word_length, avg_senti_score]\n",
      "\n",
      "rottentomatoes_prep_df = make_prep_df(rottentomatoes_clean_df, 'quote', functions)\n",
      "rottentomatoes_prep_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-45-b5e19bc4fb66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfunctions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpost_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_word_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_senti_score\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrottentomatoes_prep_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_prep_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrottentomatoes_clean_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'quote'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mrottentomatoes_prep_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-39-4ab865868cef>\u001b[0m in \u001b[0;36mmake_prep_df\u001b[0;34m(df, text_col, features)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# making a column that has the same name as the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mdf_copy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mdf_copy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_col\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# deleting rows where there is no average sentiment score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2445\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2447\u001b[0;31m         \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2448\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2449\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/lib.so\u001b[0m in \u001b[0;36mpandas.lib.map_infer (pandas/lib.c:41822)\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;32m<ipython-input-39-4ab865868cef>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# making a column that has the same name as the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mdf_copy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mdf_copy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_col\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# deleting rows where there is no average sentiment score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-38-45223b2d0b10>\u001b[0m in \u001b[0;36mavg_senti_score\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mwords_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'in_sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwords_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiment_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mwords_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'happiness_avg'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     words_df['happiness_avg'][words_df.in_sentiment == True] = words_df.words[words_df.in_sentiment == True].apply(lambda x: \n\u001b[0m\u001b[1;32m     33\u001b[0m                 float(sentiment_df.happiness_average[sentiment_df.word == x].values))\n\u001b[1;32m     34\u001b[0m     \u001b[0maverage_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhappiness_avg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mwords_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhappiness_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2445\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2447\u001b[0;31m         \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2448\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2449\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/lib.so\u001b[0m in \u001b[0;36mpandas.lib.map_infer (pandas/lib.c:41822)\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;32m<ipython-input-38-45223b2d0b10>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mwords_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'happiness_avg'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     words_df['happiness_avg'][words_df.in_sentiment == True] = words_df.words[words_df.in_sentiment == True].apply(lambda x: \n\u001b[0;32m---> 33\u001b[0;31m                 float(sentiment_df.happiness_average[sentiment_df.word == x].values))\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0maverage_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhappiness_avg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mwords_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhappiness_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m#later = time.time()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0;31m# scalars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                 raise TypeError('Could not compare %s type with Series'\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save dataframe to file:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rottentomatoes_prep_df.to_csv('rottentomatoes_prep_df.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load dataframe from CSV: <a name=\"rt_csv_prep_data\"></a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rottentomatoes_prep_df = pd.read_csv('rottentomatoes_prep_df.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######(<a href=\"#sf_csv_prep_data\">Stanford</a>) - <a href=\"#train_data\">RottenTomatoes</a> - (<a href=\"#nyt_csv_prep_data\">NewYorkTimes</a>)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some Statistics: <a name=\"rt_stat_prep_data\"></a> \n",
      "<br>Compare with: <a href=\"#rt_stat_get_data\">Plain</a>, <a href=\"#rt_stat_clean_data\">Clean</a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'length of set:', len(rottentomatoes_prep_df)\n",
      "print 'average postlength:', int(np.mean(rottentomatoes_prep_df.lead.apply(lambda x: len(x))))\n",
      "print 'number of positive reviews:', len(rottentomatoes_prep_df[rottentomatoes_prep_df.fresh == 'fresh'])\n",
      "print 'number of negative reviews:', len(rottentomatoes_prep_df[rottentomatoes_prep_df.fresh == 'rotten'])\n",
      "print 'max postlength', rottentomatoes_prep_df.lead.apply(lambda x: len(x)).max()\n",
      "print 'min postlength', rottentomatoes_prep_df.lead.apply(lambda x: len(x)).min()\n",
      "                            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of set: 134\n",
        "average postlength: 314\n",
        "number of positive reviews: currently unknown\n",
        "number of negative reviews: currently unknown\n",
        "max postlength 1280\n",
        "min postlength 35\n"
       ]
      }
     ],
     "prompt_number": 261
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 4.3 New York Times DB (nytimes_prep_df)\n",
      "Add feature columns:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "functions = [post_length, avg_word_length, avg_senti_score]\n",
      "\n",
      "nytimes_prep_df = make_prep_df(nytimes_clean_df, 'lead', functions)\n",
      "nytimes_prep_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save dataframe to file:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nytimes_prep_df.to_csv('nytimes_prep_df.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load dataframe from CSV: <a name=\"nyt_csv_prep_data\"></a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nytimes_prep_df = pd.read_csv('nytimes_prep_df.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######(<a href=\"#sf_csv_prep_data\">Stanford</a> - <a href=\"#train_data\">RottenTomatoes</a>) - <a href=\"#nyt_csv_prep_data\">NewYorkTimes</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some Statistics: <a name=\"nyt_stat_prep_data\"></a> \n",
      "<br>Compare with: <a href=\"#nyt_stat_get_data\">Plain</a>, <a href=\"#nyt_stat_clean_data\">Clean</a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'length of set:', len(rottentomatoes_prep_df)\n",
      "print 'average postlength:', int(np.mean(rottentomatoes_prep_df.lead.apply(lambda x: len(x))))\n",
      "print 'number of positive reviews:', 'currently unknown'\n",
      "print 'number of negative reviews:', 'currently unknown'\n",
      "print 'max postlength', rottentomatoes_prep_df.lead.apply(lambda x: len(x)).max()\n",
      "print 'min postlength', rottentomatoes_prep_df.lead.apply(lambda x: len(x)).min()\n",
      "                            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of set: 134\n",
        "average postlength: 314\n",
        "number of positive reviews: currently unknown\n",
        "number of negative reviews: currently unknown\n",
        "max postlength 1280\n",
        "min postlength 35\n"
       ]
      }
     ],
     "prompt_number": 261
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 5. Train Model <a name=\"train_data\"></a> \n",
      "\n",
      "Train different models with different data sources.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Make XY Function\n",
      "\n",
      "This function takes in the prepared dataframe source and outputs X (an array of features) and Y (an array of known scores)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# defining the make_xy() function\n",
      "# \"rating_col\" parameter is the name of the column where the ratings are;\n",
      "# can be continuous or binary values\n",
      "# features parameter is a list of the feature functions\n",
      "def make_xy(prep_data, rating_col, features):\n",
      "    \n",
      "    # using copy of dataframe just in case\n",
      "    prep_copy = prep_data.copy()\n",
      "    \n",
      "    # converting relevant columns to floats\n",
      "    \n",
      "    #map(features, lambda y:  prep_copy[y.__name__] = prep_copy[y.__name__].apply(lambda x: float(x)))\n",
      "    \n",
      "    for func in features:\n",
      "        prep_copy[func.__name__] = prep_copy[func.__name__].apply(lambda x: float(x))\n",
      "    \n",
      "    feature_array = []\n",
      "    for i in xrange(len(prep_copy)):\n",
      "        feature_list = [float(prep_copy[func.__name__][prep_copy.index == i]) for func in features]\n",
      "        feature_array.append(feature_list)\n",
      "    \n",
      "    #map(features, lambda x: df_copy[x.__name__] = np.nan)\n",
      "    #map(features, lambda y: df_copy[y.__name__] = df_copy.text_col.apply(lambda x: y(x)))\n",
      "    \n",
      "    # making 2D array of features\n",
      "    x = np.array(feature_array)\n",
      "    \n",
      "    # renaming the column that contains the ratings\n",
      "    prep_copy = prep_copy.rename(columns={rating_col: 'rating_col'})\n",
      "    \n",
      "    # making numpy array of the naive happy values we made up\n",
      "    y = np.array(prep_copy.rating_col.values)\n",
      "    \n",
      "    # returning x and y in a tuple\n",
      "    return x, y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 5.1 Train Model - Low Level Features to Predict Sentimentscore - Stanford Moviedatabase \n",
      "\n",
      "This function takes in the prepared dataframe source and outputs X (an array of features) and Y (an array of known scores)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_cols = [post_length, avg_word_length, avg_senti_score]\n",
      "stanford_test_df = make_stanford_df('test')\n",
      "stanford_test_prep_df = make_prep_df(stanford_test_df.head(10), 'review', features_cols)\n",
      "\n",
      "\n",
      "stanford_prep_df = stanford_prep_df.rename(columns = {'word_count' : 'post_length'})\n",
      "\n",
      "features_train = [post_length, avg_word_length]\n",
      "Xtrain,Ytrain = make_xy(stanford_prep_df, 'rating', features_train)\n",
      "\n",
      "features_train = [post_length, avg_word_length]\n",
      "Xtest,Ytest = make_xy(stanford_test_prep_df, 'rating', features_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# making object from MultinomialNB class\n",
      "#clf = MultinomialNB()\n",
      "clf = GaussianNB()\n",
      "\n",
      "# printing fit and score\n",
      "clf.fit(Xtrain, Ytrain)\n",
      "print round(clf.score(Xtrain, Ytrain), 4)\n",
      "print round(clf.score(Xtest, Ytest), 4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "Can't handle mix of unknown and binary",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-34-47b4b0a7fe82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\base.pyc\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    292\u001b[0m         \"\"\"\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\metrics.pyc\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize)\u001b[0m\n\u001b[0;32m   1062\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1064\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_clf_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1065\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'multilabel-indicator'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\metrics.pyc\u001b[0m in \u001b[0;36m_check_clf_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         raise ValueError(\"Can't handle mix of {0} and {1}\"\n\u001b[1;32m--> 115\u001b[1;33m                          \"\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: Can't handle mix of unknown and binary"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.2141\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 6. Predict from Data\n",
      "\n",
      "Predict outcome of given data source.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 7. Prediction Visualization\n",
      "\n",
      "Prepare datasources with neccessary extension including required featurelist. Result will be stored in local CSV files.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "*css tweaks in this cell*\n",
      "<style>\n",
      "div.text_cell_render {\n",
      "    line-height: 150%;\n",
      "    font-size: 110%;\n",
      "    width: 800px;\n",
      "    margin-left:50px;\n",
      "    margin-right:auto;\n",
      "    }\n",
      "</style>"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}