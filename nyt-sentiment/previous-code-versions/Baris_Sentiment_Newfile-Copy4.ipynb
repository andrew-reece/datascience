{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Team - Predictive Model\n",
      "Baris Baloglu & Javier Pineda (de Mar)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### QuickRuns:\n",
      "Description: under each key section a quickrun bar helps to quickly navigate to the next necessary step of the parts of the notebook to improve overview and increase speed while running specific parts of the project:\n",
      "<br>\n",
      "\n",
      "<a href=\"#import_data\">Stanford</a>\n",
      "<br>\n",
      "<a href=\"#import_data\">Rottentomatoes</a>\n",
      "<br>\n",
      "<a href=\"#import_data\">NewYorkTimes</a>\n",
      "<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 1. Importing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 1.1 Normal Import Statements <a name=\"import_data\"></a>\n",
      "Collecting all import statements and global settings together in one spot."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#test if canvas stays in on plt.show\n",
      "%matplotlib inline\n",
      "# Not sure what we'll need exactly, so just importing all the usual suspects here\n",
      "import json\n",
      "import requests\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import re\n",
      "import scipy.stats as stats\n",
      "import os, sys\n",
      "import math\n",
      "import time\n",
      "\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "\n",
      "\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "#%pylab inline\n",
      "\n",
      "pd.set_option('display.width', 500)\n",
      "pd.set_option('display.max_columns', 30)\n",
      "\n",
      "# set some nicer defaults for matplotlib\n",
      "from matplotlib import rcParams\n",
      "\n",
      "#these colors come from colorbrewer2.org. Each is an RGB triplet\n",
      "dark2_colors = [(0.10588235294117647, 0.6196078431372549, 0.4666666666666667),\n",
      "                (0.8509803921568627, 0.37254901960784315, 0.00784313725490196),\n",
      "                (0.4588235294117647, 0.4392156862745098, 0.7019607843137254),\n",
      "                (0.9058823529411765, 0.1607843137254902, 0.5411764705882353),\n",
      "                (0.4, 0.6509803921568628, 0.11764705882352941),\n",
      "                (0.9019607843137255, 0.6705882352941176, 0.00784313725490196),\n",
      "                (0.6509803921568628, 0.4627450980392157, 0.11372549019607843),\n",
      "                (0.4, 0.4, 0.4)]\n",
      "\n",
      "rcParams['figure.figsize'] = (10, 6)\n",
      "rcParams['figure.dpi'] = 150\n",
      "rcParams['axes.color_cycle'] = dark2_colors\n",
      "rcParams['lines.linewidth'] = 2\n",
      "rcParams['axes.grid'] = False\n",
      "rcParams['axes.facecolor'] = 'white'\n",
      "rcParams['font.size'] = 14\n",
      "rcParams['patch.edgecolor'] = 'none'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######<a href=\"#sentiment_data\">Stanford</a> - <a href=\"#sentiment_data\">RottenTomatoes</a> - <a href=\"#sentiment_data\">NewYorkTimes</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2. Get Data\n",
      "\n",
      "Collect all different data sources used as training data in one chapter. All data will be stored in a CSV-File for later usage.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 2.1 Sentiment Analysis Words (sentiment_df) (Run mandatory) <a name=\"sentiment_data\"></a>\n",
      "\n",
      "This is the sentiment data which is used as a reference for word sentiment scores. It is needed for almost all following actions this is why it should be run in any case."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read sentiment data from text file\n",
      "sentiment_df = pd.read_table('sentiment_data.txt', sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "StopWordList = stopwords.words(\"english\")\n",
      "sentiment_df['in_stopword'] = False\n",
      "sentiment_df['in_stopword'][sentiment_df.word.isin(StopWordList)] = True\n",
      "sentiment_df_NS = sentiment_df[sentiment_df.in_stopword == False]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######<a href=\"#sf_make_data\">Stanford</a> - <a href=\"#rt_csv_get_data\">RottenTomatoes</a> - <a href=\"#nyt_csv_get_data\">NewYorkTimes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 2.2 Stanford MovieDB (stanford_df) <a name=\"sf_make_data\"></a>\n",
      "25k reviews divided in 12.5k positive ones and 12.5k negative. Ratings range from 1-10 for 1 negative and 10 positive. All neutral reviews have been excluded beforehand. Dataframe will be constructed from filesystem structure. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Set up function to create stanford dataframe. A function is used to create reusability for the later use in case of testing data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# here the parameter \"data_set\" is a string (either 'train' or 'test')\n",
      "def make_stanford_df(data_set):\n",
      "\n",
      "    # making lists of negative and positive training data filenames, respectively\n",
      "    path_neg = \"stanford_movie/%s/neg/\" % data_set\n",
      "    neg_list = os.listdir(path_neg)\n",
      "    \n",
      "    path_pos = \"stanford_movie/%s/pos/\" % data_set\n",
      "    pos_list = os.listdir(path_pos)\n",
      "    \n",
      "    # making sure we're only getting the filenames we want\n",
      "    # there seems to be hidden files at least in the neg folder\n",
      "    neg_list = [i for i in neg_list if i[0].isdigit()]\n",
      "    pos_list = [i for i in pos_list if i[0].isdigit()]\n",
      "    \n",
      "    # making dataframe for negative training data\n",
      "    neg_df = pd.DataFrame(neg_list, columns = ['filename'])\n",
      "    \n",
      "    neg_df['id'] = neg_df.apply(lambda x: \n",
      "                            'neg' + x['filename'][:x['filename'].index('_')], axis=1)\n",
      "    \n",
      "    neg_df['rating'] = neg_df.apply(lambda x: \n",
      "                            x['filename'][x['filename'].index('_')+1:-4], axis=1)\n",
      "    \n",
      "    neg_df['path'] = path_neg\n",
      "    \n",
      "    # making dataframe for positive training data\n",
      "    pos_df = pd.DataFrame(pos_list, columns = ['filename'])\n",
      "    pos_df['id'] = pos_df.apply(lambda x: \n",
      "                            'pos' + x['filename'][:x['filename'].index('_')], axis=1)\n",
      "    pos_df['rating'] = pos_df.apply(lambda x: \n",
      "                            x['filename'][x['filename'].index('_')+1:-4], axis=1)\n",
      "    \n",
      "    pos_df['path'] = path_pos\n",
      "    \n",
      "    # concatenating negative and positive training data into one dataframe\n",
      "    stanford_df = pd.concat([neg_df, pos_df], ignore_index=True)\n",
      "    \n",
      "    # adding column with the movie reviews\n",
      "    stanford_df['review'] = stanford_df.apply(lambda x: \n",
      "                            open(x['path'] + x['filename'], 'r').read(), axis=1)\n",
      "\n",
      "    return stanford_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######<a href=\"#sf_csv_get_data\">Stanford</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Call function to create dataframe:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stanford_df = make_stanford_df('train')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save dataframe to file:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stanford_df.to_csv('stanford.csv', index=False)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load dataframe from CSV: <a name=\"sf_csv_get_data\"></a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stanford_df = pd.read_csv('stanford.csv')\n",
      "stanford_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\config.py:570: DeprecationWarning: height has been deprecated.\n",
        "\n",
        "  warnings.warn(d.msg, DeprecationWarning)\n",
        "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\config.py:570: DeprecationWarning: height has been deprecated.\n",
        "\n",
        "  warnings.warn(d.msg, DeprecationWarning)\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>filename</th>\n",
        "      <th>id</th>\n",
        "      <th>rating</th>\n",
        "      <th>path</th>\n",
        "      <th>review</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>     0_3.txt</td>\n",
        "      <td>     neg0</td>\n",
        "      <td> 3</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> Story of a man who has unnatural feelings for ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 10000_4.txt</td>\n",
        "      <td> neg10000</td>\n",
        "      <td> 4</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> Airport '77 starts as a brand new luxury 747 p...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 10001_4.txt</td>\n",
        "      <td> neg10001</td>\n",
        "      <td> 4</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> This film lacked something I couldn't put my f...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 10002_1.txt</td>\n",
        "      <td> neg10002</td>\n",
        "      <td> 1</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> Sorry everyone,,, I know this is supposed to b...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 10003_1.txt</td>\n",
        "      <td> neg10003</td>\n",
        "      <td> 1</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> When I was little my parents took me along to ...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "      filename        id  rating                       path                                             review\n",
        "0      0_3.txt      neg0       3  stanford_movie/train/neg/  Story of a man who has unnatural feelings for ...\n",
        "1  10000_4.txt  neg10000       4  stanford_movie/train/neg/  Airport '77 starts as a brand new luxury 747 p...\n",
        "2  10001_4.txt  neg10001       4  stanford_movie/train/neg/  This film lacked something I couldn't put my f...\n",
        "3  10002_1.txt  neg10002       1  stanford_movie/train/neg/  Sorry everyone,,, I know this is supposed to b...\n",
        "4  10003_1.txt  neg10003       1  stanford_movie/train/neg/  When I was little my parents took me along to ..."
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######<a href=\"#sf_csv_clean_data\">Stanford</a> - (<a href=\"#rt_csv_get_data\">RottenTomatoes</a> - <a href=\"#nyt_csv_get_data\">NewYorkTimes</a>)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some Statistics: <a name=\"sf_stat_get_data\"></a> \n",
      "<br>Compare with: <a href=\"#sf_stat_clean_data\">Clean</a>, <a href=\"#sf_stat_prep_data\">Prepare</a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'length of set:', len(stanford_df)\n",
      "print 'average postlength:', int(np.mean(stanford_df[~stanford_df.review.isnull()].review.apply(lambda x: len(x))))\n",
      "print 'number of positive reviews:', len(stanford_df[stanford_df.rating >= 7])\n",
      "print 'number of negative reviews:', len(stanford_df[stanford_df.rating <= 4])\n",
      "print 'max postlength', stanford_train_df[~stanford_df.review.isnull()].review.apply(lambda x: len(x)).max()\n",
      "print 'min postlength', stanford_train_df[~stanford_df.review.isnull()].review.apply(lambda x: len(x)).min()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of set: 25000\n",
        "average postlength: 1325\n",
        "number of positive reviews: 12500\n",
        "number of negative reviews: 12500\n",
        "max postlength 13704\n",
        "min postlength "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "52\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 2.3 RottenTomatoes (rottentomatoes_df) <a name=\"rt_get_data\"></a>\n",
      "Around 8k reviews divided in about 6k fresh ones and 2k rotten. Rating's range is binary for 1 fresh and 0 rotten. No neutral reviews have been excluded beforehand. Dataframe will be constructed from local CSV file out of HW3. <a name=\"rt_csv_get_data\"></a> "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rottentomatoes_df = pd.read_csv('critics.csv')\n",
      "rottentomatoes_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>critic</th>\n",
        "      <th>fresh</th>\n",
        "      <th>imdb</th>\n",
        "      <th>publication</th>\n",
        "      <th>quote</th>\n",
        "      <th>review_date</th>\n",
        "      <th>rtid</th>\n",
        "      <th>title</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> Owen Gleiberman</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td> Entertainment Weekly</td>\n",
        "      <td>                                               NaN</td>\n",
        "      <td> 2011-09-07</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>     Derek Adams</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>             Time Out</td>\n",
        "      <td> So ingenious in concept, design and execution ...</td>\n",
        "      <td> 2009-10-04</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> Richard Corliss</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>        TIME Magazine</td>\n",
        "      <td>                 The year's most inventive comedy.</td>\n",
        "      <td> 2008-08-31</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>     David Ansen</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>             Newsweek</td>\n",
        "      <td> A winning animated feature that has something ...</td>\n",
        "      <td> 2008-08-18</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>   Leonard Klady</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>              Variety</td>\n",
        "      <td> The film sports a provocative and appealing st...</td>\n",
        "      <td> 2008-06-09</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 207,
       "text": [
        "            critic  fresh    imdb           publication                                              quote review_date  rtid      title\n",
        "0  Owen Gleiberman  fresh  114709  Entertainment Weekly                                                NaN  2011-09-07  9559  Toy story\n",
        "1      Derek Adams  fresh  114709              Time Out  So ingenious in concept, design and execution ...  2009-10-04  9559  Toy story\n",
        "2  Richard Corliss  fresh  114709         TIME Magazine                  The year's most inventive comedy.  2008-08-31  9559  Toy story\n",
        "3      David Ansen  fresh  114709              Newsweek  A winning animated feature that has something ...  2008-08-18  9559  Toy story\n",
        "4    Leonard Klady  fresh  114709               Variety  The film sports a provocative and appealing st...  2008-06-09  9559  Toy story"
       ]
      }
     ],
     "prompt_number": 207
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######(<a href=\"#sf_csv_get_data\">Stanford</a>) - <a href=\"#rt_csv_clean_data\">RottenTomatoes</a> - (<a href=\"#nyt_csv_get_data\">NewYorkTimes</a>)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some Statistics: <a name=\"rt_stat_get_data\"></a> \n",
      "<br>Compare with: <a href=\"#rt_stat_clean_data\">Clean</a>, <a href=\"#rt_stat_prep_data\">Prepare</a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'length of set:', len(rottentomatoes_df)\n",
      "print 'average postlength:', int(np.mean(rottentomatoes_df[~rottentomatoes_df.quote.isnull()].quote.apply(lambda x: len(x))))\n",
      "print 'number of positive reviews:', len(rottentomatoes_df[rottentomatoes_df.fresh == 'fresh'])\n",
      "print 'number of negative reviews:', len(rottentomatoes_df[rottentomatoes_df.fresh == 'rotten'])\n",
      "print 'max postlength', rottentomatoes_df[~rottentomatoes_df.quote.isnull()].quote.apply(lambda x: len(x)).max()\n",
      "print 'min postlength', rottentomatoes_df[~rottentomatoes_df.quote.isnull()].quote.apply(lambda x: len(x)).min()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of set: 27692\n",
        "average postlength: 117\n",
        "number of positive reviews: 11833\n",
        "number of negative reviews: 8458\n",
        "max postlength 256\n",
        "min postlength "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4\n"
       ]
      }
     ],
     "prompt_number": 208
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 2.4 New York Times DB (nytimes_df) <a name=\"nyt_get_data\"></a>\n",
      "Around XX lead paragraphs of articles based from given keyword arguments (article set can be changed by altering search parameter below). Note that lead paragraphs are low on words. Data is retrieved online and is saved into a CSV file in the end. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "API parameter: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## NYT API keys\n",
      "api_key_article = \"851e7d0a131bee9bc01097470c238637:13:47475506\"\n",
      "api_key_community = \"519167db119ee6408c4ee51b3c391e11:0:47475506\"\n",
      "api_key_geo = \"a984ad78bf017f0ade1fcd980aa6353f:15:47475506\"\n",
      "api_key_popular = \"09dfaf288ad6c2ec46893a27ca758d41:19:47475506\"\n",
      "api_key_movies = \"e8a48f7d7731698b05267146c681c352:5:47475506\"\n",
      "api_key_semantic = \"9063b41607bbf486247b8e596a1456b8:7:47475506\"\n",
      "api_key_newswire = \"209ebb7b0ab44094970e8b39c63fea7e:2:47475506\"\n",
      "api_key_timestags = \"43b3366f288db10cb019fd532299723f:10:47475506\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 209
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Search parameters: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "begindate = \"20000101\" #YYYYMMDD\n",
      "enddate = \"20131112\" #YYYYMMDD\n",
      "\n",
      "## just picked a few terms meant to have a fair spread in content\n",
      "terms = ['mindfulness', 'debt', 'kardashian', 'obama',\n",
      "         'romney', 'obamacare', 'god', 'terrorism', 'nazi', \n",
      "         'hussein', 'war', 'depression', 'abortion', 'sex']\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 221
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Get data from nytimes.com: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# intially an empty dataframe\n",
      "nytimes_df = pd.DataFrame()\n",
      "\n",
      "# loop through terms\n",
      "for term in terms:\n",
      "    \n",
      "    # api request for each term\n",
      "    url = ''.join([\"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=\", term,\n",
      "                   \"&begin_date=\", begindate, \n",
      "                   \"&end_date=\", enddate,\n",
      "                   \"&api-key=\",api_key_article])\n",
      "        \n",
      "    req = requests.get(url).text\n",
      "    \n",
      "    # decode into json dicts\n",
      "    jsons = json.loads(req)\n",
      "    \n",
      "    # loop through each article returned from API request\n",
      "    for doc in jsons['response']['docs']:\n",
      "\n",
      "        # making dataframe; a term will appear in multiple rows\n",
      "        doc_df = pd.DataFrame([term], columns = ['term'])\n",
      "        \n",
      "        # alternative way of dealing with none-types\n",
      "        if json.dumps(doc['abstract']) != 'null':\n",
      "        \n",
      "            # encode weird ascii stuff\n",
      "            abstract = [doc['abstract'].encode('utf-8')]\n",
      "            \n",
      "            # making dataframe and adding abstracts\n",
      "            doc_df['abstract'] = abstract\n",
      "            \n",
      "        # this way we take all data, and we can do away with what we don't want later    \n",
      "        else:\n",
      "            abstract = np.nan\n",
      "            doc_df['abstract'] = abstract\n",
      "            \n",
      "        # can add an if-else clause for anything you want to get, then add to doc_df\n",
      "        if json.dumps(doc['lead_paragraph']) != 'null':\n",
      "            \n",
      "            lead = [doc['lead_paragraph'].encode('utf-8')]\n",
      "            doc_df['lead'] = lead\n",
      "            \n",
      "        else:\n",
      "            lead = np.nan\n",
      "            doc_df['lead'] = lead\n",
      "        \n",
      "        nytimes_df = pd.concat([nytimes_df, doc_df]).reset_index(drop=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 223
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save dataframe to file:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nytimes_df.to_csv('nytimes.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 224
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load dataframe from CSV: <a name=\"nyt_csv_get_data\"></a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nytimes_df = pd.read_csv('nytimes.csv')\n",
      "\n",
      "nytimes_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>abstract</th>\n",
        "      <th>lead</th>\n",
        "      <th>term</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>                                               NaN</td>\n",
        "      <td> A term for mental training reaches the height ...</td>\n",
        "      <td> mindfulness</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> Mindfulness is terrific for the person practic...</td>\n",
        "      <td> The other night at a dinner party, a friend de...</td>\n",
        "      <td> mindfulness</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>                                               NaN</td>\n",
        "      <td> Mindfulness is terrific for the person practic...</td>\n",
        "      <td> mindfulness</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> Jennifer Egan article on her experience at Spi...</td>\n",
        "      <td> Peter Williams sits cross-legged on an upholst...</td>\n",
        "      <td> mindfulness</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> Two-thirds of doctors experience the emotional...</td>\n",
        "      <td>                                               NaN</td>\n",
        "      <td> mindfulness</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 228,
       "text": [
        "                                            abstract                                               lead         term\n",
        "0                                                NaN  A term for mental training reaches the height ...  mindfulness\n",
        "1  Mindfulness is terrific for the person practic...  The other night at a dinner party, a friend de...  mindfulness\n",
        "2                                                NaN  Mindfulness is terrific for the person practic...  mindfulness\n",
        "3  Jennifer Egan article on her experience at Spi...  Peter Williams sits cross-legged on an upholst...  mindfulness\n",
        "4  Two-thirds of doctors experience the emotional...                                                NaN  mindfulness"
       ]
      }
     ],
     "prompt_number": 228
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######(<a href=\"#sf_csv_get_data\">Stanford</a> - <a href=\"#rt_csv_get_data\">RottenTomatoes</a>) - <a href=\"#nyt_csv_clean_data\">NewYorkTimes</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some Statistics: <a name=\"nyt_stat_get_data\"></a> \n",
      "<br>Compare with: <a href=\"#nyt_stat_clean_data\">Clean</a>, <a href=\"#nyt_stat_prep_data\">Prepare</a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'length of set:', len(nytimes_df)\n",
      "print 'average postlength:', int(np.mean(nytimes_df.lead[~nytimes_df.lead.isnull()].apply(lambda x: len(x))))\n",
      "print 'number of positive reviews:', 'currently unknown'\n",
      "print 'number of negative reviews:', 'currently unknown'\n",
      "print 'max postlength', nytimes_df.lead[~nytimes_df.lead.isnull()].apply(lambda x: len(x)).max()\n",
      "print 'min postlength', nytimes_df.lead[~nytimes_df.lead.isnull()].apply(lambda x: len(x)).min()\n",
      "                            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of set: 140\n",
        "average postlength: 314\n",
        "number of positive reviews: currently unknown\n",
        "number of negative reviews: currently unknown\n",
        "max postlength 1280\n",
        "min postlength 35\n"
       ]
      }
     ],
     "prompt_number": 232
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 3. Clean Data\n",
      "\n",
      "Clear datasources from any empty or unneccassary data rows or specific entries.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 3.1 Stanford MovieDB (stanford_clean_df) <a name=\"sf_csv_clean_data\"></a>\n",
      "Currently no cleaning neccessary. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stanford_clean_df = stanford_df\n",
      "stanford_clean_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\config.py:570: DeprecationWarning: height has been deprecated.\n",
        "\n",
        "  warnings.warn(d.msg, DeprecationWarning)\n",
        "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\config.py:570: DeprecationWarning: height has been deprecated.\n",
        "\n",
        "  warnings.warn(d.msg, DeprecationWarning)\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>filename</th>\n",
        "      <th>id</th>\n",
        "      <th>rating</th>\n",
        "      <th>path</th>\n",
        "      <th>review</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>     0_3.txt</td>\n",
        "      <td>     neg0</td>\n",
        "      <td> 3</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> Story of a man who has unnatural feelings for ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 10000_4.txt</td>\n",
        "      <td> neg10000</td>\n",
        "      <td> 4</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> Airport '77 starts as a brand new luxury 747 p...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 10001_4.txt</td>\n",
        "      <td> neg10001</td>\n",
        "      <td> 4</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> This film lacked something I couldn't put my f...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 10002_1.txt</td>\n",
        "      <td> neg10002</td>\n",
        "      <td> 1</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> Sorry everyone,,, I know this is supposed to b...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 10003_1.txt</td>\n",
        "      <td> neg10003</td>\n",
        "      <td> 1</td>\n",
        "      <td> stanford_movie/train/neg/</td>\n",
        "      <td> When I was little my parents took me along to ...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "      filename        id  rating                       path                                             review\n",
        "0      0_3.txt      neg0       3  stanford_movie/train/neg/  Story of a man who has unnatural feelings for ...\n",
        "1  10000_4.txt  neg10000       4  stanford_movie/train/neg/  Airport '77 starts as a brand new luxury 747 p...\n",
        "2  10001_4.txt  neg10001       4  stanford_movie/train/neg/  This film lacked something I couldn't put my f...\n",
        "3  10002_1.txt  neg10002       1  stanford_movie/train/neg/  Sorry everyone,,, I know this is supposed to b...\n",
        "4  10003_1.txt  neg10003       1  stanford_movie/train/neg/  When I was little my parents took me along to ..."
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######<a href=\"#prep_features\">Stanford</a> - (<a href=\"#rt_csv_clean_data\">RottenTomatoes</a> - <a href=\"#nyt_csv_clean_data\">NewYorkTimes</a>)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some Statistics: <a name=\"sf_stat_celan_data\"></a> \n",
      "<br>Compare with: <a href=\"#sf_stat_get_data\">Plain</a>, <a href=\"#sf_stat_prep_data\">Prepare</a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'length of set:', len(stanford_clean_df)\n",
      "print 'average postlength:', int(np.mean(stanford_clean_df[~stanford_clean_df.review.isnull()].review.apply(lambda x: len(x))))\n",
      "print 'number of positive reviews:', len(stanford_clean_df[stanford_clean_df.rating >= 7])\n",
      "print 'number of negative reviews:', len(stanford_clean_df[stanford_clean_df.rating <= 4])\n",
      "print 'max postlength', stanford_clean_df[~stanford_clean_df.review.isnull()].review.apply(lambda x: len(x)).max()\n",
      "print 'min postlength', stanford_clean_df[~stanford_clean_df.review.isnull()].review.apply(lambda x: len(x)).min()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of set: 25000\n",
        "average postlength: 1325\n",
        "number of positive reviews: 12500\n",
        "number of negative reviews: 12500\n",
        "max postlength 13704\n",
        "min postlength "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "52\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 3.2 RottenTomatoes (rottentomatoes_clean_df)\n",
      "Around 8k reviews divided in about 6k fresh ones and 2k rotten. Rating's range is binary for 1 fresh and 0 rotten. No neutral reviews have been excluded beforehand. Dataframe will be constructed from local CSV file out of HW3. <a name=\"rt_csv_get_data\"></a> "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rottentomatoes_clean_df = rottentomatoes_df[~rottentomatoes_df.quote.isnull()]\n",
      "rottentomatoes_clean_df = rottentomatoes_clean_df[rottentomatoes_clean_df.fresh != 'none']\n",
      "rottentomatoes_clean_df = rottentomatoes_clean_df[rottentomatoes_clean_df.quote.str.len() > 0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 255
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save dataframe to file:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rottentomatoes_clean_df.to_csv('rottentomatoes_clean_df.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 256
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load dataframe from CSV: <a name=\"rt_csv_clean_data\"></a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rottentomatoes_clean_df = pd.read_csv('rottentomatoes_clean_df.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 254
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######(<a href=\"#sf_csv_clean_data\">Stanford</a>) - <a href=\"#prep_features\">RottenTomatoes</a> - (<a href=\"#nyt_csv_clean_data\">NewYorkTimes</a>)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some Statistics: <a name=\"rt_stat_clean_data\"></a> \n",
      "<br>Compare with: <a href=\"#rt_stat_get_data\">Plain</a>, <a href=\"#rt_stat_prep_data\">Prepare</a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rottentomatoes_clean_df = pd.read_csv('rottentomatoes_clean_df.csv')\n",
      "print 'length of set:', len(rottentomatoes_clean_df)\n",
      "print 'average postlength:', int(np.mean(rottentomatoes_clean_df.quote.apply(lambda x: len(x))))\n",
      "print 'number of positive reviews:', len(rottentomatoes_clean_df[rottentomatoes_clean_df.fresh == 'fresh'])\n",
      "print 'number of negative reviews:', len(rottentomatoes_clean_df[rottentomatoes_clean_df.fresh == 'rotten'])\n",
      "print 'max postlength', rottentomatoes_clean_df.quote.apply(lambda x: len(x)).max()\n",
      "print 'min postlength', rottentomatoes_clean_df.quote.apply(lambda x: len(x)).min()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of set: 15572\n",
        "average postlength: 117\n",
        "number of positive reviews: 9486\n",
        "number of negative reviews: 6086\n",
        "max postlength 256\n",
        "min postlength 4\n"
       ]
      }
     ],
     "prompt_number": 262
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 3.3 New York Times DB (nytimes_clean_df)\n",
      "Eliminate all empty lead paragraphs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nytimes_clean_df = nytimes_df[~nytimes_df.lead.isnull()]\n",
      "nytimes_clean_df = nytimes_clean_df[nytimes_clean_df.lead != 'none']\n",
      "nytimes_clean_df = nytimes_clean_df[nytimes_clean_df.lead.str.len() > 0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 251
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save dataframe to file:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nytimes_clean_df.to_csv('nytimes_clean_df.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 253
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load dataframe from CSV: <a name=\"nyt_csv_clean_data\"></a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nytimes_clean_df = pd.read_csv('nytimes_clean_df.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 254
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######(<a href=\"#sf_csv_clean_data\">Stanford</a> - <a href=\"#rt_csv_clean_data\">RottenTomatoes</a>) - <a href=\"#prep_features\">NewYorkTimes</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some Statistics: <a name=\"nyt_stat_clean_data\"></a> \n",
      "<br>Compare with: <a href=\"#nyt_stat_get_data\">Plain</a>, <a href=\"#nyt_stat_prep_data\">Prepare</a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'length of set:', len(nytimes_clean_df)\n",
      "print 'average postlength:', int(np.mean(nytimes_clean_df.lead.apply(lambda x: len(x))))\n",
      "print 'number of positive reviews:', 'currently unknown'\n",
      "print 'number of negative reviews:', 'currently unknown'\n",
      "print 'max postlength', nytimes_clean_df.lead.apply(lambda x: len(x)).max()\n",
      "print 'min postlength', nytimes_clean_df.lead.apply(lambda x: len(x)).min()\n",
      "                            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of set: 134\n",
        "average postlength: 314\n",
        "number of positive reviews: currently unknown\n",
        "number of negative reviews: currently unknown\n",
        "max postlength 1280\n",
        "min postlength 35\n"
       ]
      }
     ],
     "prompt_number": 261
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 4. Prepare Data\n",
      "\n",
      "Prepare datasources with neccessary extenstion including required featurelist. Result will be stored in local CSV files.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Features <a name=\"prep_features\"></a>\n",
      "Collection of feature methods that can be called by dataframe to apply on all rows."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def post_length(text):\n",
      "    \n",
      "    words_df = pd.DataFrame(text.split(' '), columns=['words'])\n",
      "    words_df['words'] = words_df.words.apply(lambda x: str.lower(re.sub(\"\\W\", '', x)))\n",
      "    words_df['word_length'] = words_df.words.apply(lambda x: len(x))\n",
      "    words_df = words_df[words_df.word_length > 0]\n",
      "    tot_word_count = len(words_df)\n",
      "    return tot_word_count\n",
      "\n",
      "\n",
      "def avg_word_length(text):\n",
      "    words_df = pd.DataFrame(text.split(' '), columns=['words'])\n",
      "    words_df['words'] = words_df.words.apply(lambda x: str.lower(re.sub(\"\\W\", '', x)))           \n",
      "    words_df['word_length'] = words_df.words.apply(lambda x: len(x))\n",
      "    words_df = words_df[words_df.word_length > 0]      \n",
      "    average_length = round(np.mean(words_df.word_length.values), 2)    \n",
      "    return average_length\n",
      "\n",
      "\n",
      "def avg_senti_score(text):\n",
      "    #now = time.time()\n",
      "    words_df = pd.DataFrame(text.split(' '), columns=['words'])\n",
      "    words_df['words'] = words_df.words.apply(lambda x: str.lower(re.sub(\"\\W\", '', x)))\n",
      "    words_df['word_length'] = words_df.words.apply(lambda x: len(x))\n",
      "    words_df = words_df[words_df.word_length > 0]\n",
      "    words_df['in_sentiment'] = False\n",
      "    words_df['in_sentiment'][words_df.words.isin(sentiment_df.word)] = True\n",
      "    words_df['happiness_avg'] = np.nan\n",
      "    words_df['happiness_avg'][words_df.in_sentiment == True] = words_df.words[words_df.in_sentiment == True].apply(lambda x: \n",
      "                float(sentiment_df.happiness_average[sentiment_df.word == x].values))\n",
      "    average_score = round(np.mean(words_df.happiness_avg[~words_df.happiness_avg.isnull()].values), 3)\n",
      "    #later = time.time()\n",
      "    #print 'time used for entry:', float(later - now)\n",
      "    return float(average_score)\n",
      "\n",
      "\"\"\"\n",
      "def avg_senti_score2(text):\n",
      "    #now = time.time()\n",
      "    words_df = pd.DataFrame(text.split(' '), columns=['words'])\n",
      "    words_df['words'] = words_df.words.apply(lambda x: str.lower(re.sub(\"\\W\", '', x)))\n",
      "    words_df['word_length'] = words_df.words.apply(lambda x: len(x))\n",
      "    words_df = words_df[words_df.word_length > 0]\n",
      "    words_df['in_sentiment'] = False\n",
      "    words_df['in_sentiment'][words_df.words.isin(sentiment_df.word)] = True\n",
      "    words_df['happiness_avg2'] = np.nan\n",
      "    words_df['happiness_avg2'][words_df.in_sentiment == True] = words_df.words[words_df.in_sentiment == True].apply(lambda x: \n",
      "                float(sentiment_df.happiness_average2[sentiment_df.word == x].values))\n",
      "    average_score2 = round(np.mean(words_df.happiness_avg2[~words_df.happiness_avg2.isnull()].values), 3)\n",
      "    #later = time.time()\n",
      "    #print 'time used for entry:', float(later - now)\n",
      "    return float(average_score2)\n",
      "\"\"\"\n",
      "\n",
      "def avg_senti_score2(text):\n",
      "    #now = time.time()\n",
      "    words_df = pd.DataFrame(text.split(' '), columns=['words'])\n",
      "    words_df['words'] = words_df.words.apply(lambda x: str.lower(re.sub(\"\\W\", '', x)))\n",
      "    words_df['word_length'] = words_df.words.apply(lambda x: len(x))\n",
      "    words_df = words_df[words_df.word_length > 0]\n",
      "    words_df['in_sentiment'] = False\n",
      "    words_df['in_sentiment'][words_df.words.isin(sentiment_df_NS.word)] = True\n",
      "    words_df['happiness_avg_2'] = np.nan\n",
      "    words_df['happiness_avg_2'][words_df.in_sentiment == True] = words_df.words[words_df.in_sentiment == True].apply(lambda x: \n",
      "                float(sentiment_df_NS.happiness_average[sentiment_df_NS.word == x].values))\n",
      "    average_score_2 = round(np.mean(words_df.happiness_avg_2[~words_df.happiness_avg_2.isnull()].values), 3)\n",
      "    #later = time.time()\n",
      "    #print 'time used for entry:', float(later - now)\n",
      "\n",
      "    return float(average_score_2)\n",
      "\n",
      "def dyn_senti_score(text):    \n",
      "    #now = time.time()\n",
      "    words_df = pd.DataFrame(text.split(' '), columns=['words'])\n",
      "    words_df['words'] = words_df.words.apply(lambda x: str.lower(re.sub(\"\\W\", '', x)))\n",
      "    words_df['word_length'] = words_df.words.apply(lambda x: len(x))\n",
      "    words_df = words_df[words_df.word_length > 0]\n",
      "    words_df['in_sentiment'] = False\n",
      "    words_df['in_sentiment'][words_df.words.isin(sentiment_df_NS.word)] = True\n",
      "    words_df['happiness_avg'] = np.nan\n",
      "    words_df['happiness_avg'][words_df.in_sentiment == True] = words_df.words[words_df.in_sentiment == True].apply(lambda x: \n",
      "                float(sentiment_df_NS.happiness_average[sentiment_df_NS.word == x].values))\n",
      "   \n",
      "    avg_sent_score = round(np.mean(words_df.happiness_avg[~words_df.happiness_avg.isnull()].values), 3)\n",
      "\n",
      "    sent_min = words_df['happiness_avg'].min(axis=0)\n",
      "    sent_max = words_df['happiness_avg'].max(axis=0)\n",
      "    sent_range = sent_max - sent_min\n",
      "    range_constant = 0.1\n",
      "    dispersion = range_constant * sent_range\n",
      "    ## lower and upper boundaries for dynamic exclusion\n",
      "    \n",
      "    dyn_exclude_min = avg_sent_score - dispersion\n",
      "    dyn_exclude_max = avg_sent_score + dispersion\n",
      "    \n",
      "    words_df['dyn_exclusion'] = 'True'\n",
      "    words_df['dyn_exclusion'][(words_df.happiness_avg >=dyn_exclude_max)] = 'False'\n",
      "    words_df['dyn_exclusion'][(words_df.happiness_avg <=dyn_exclude_min)] = 'False'\n",
      "\n",
      "    \n",
      "    avghdyn = np.nan\n",
      "    avghdyn = words_df[words_df['dyn_exclusion'] == 'False']['happiness_avg'].mean()\n",
      "    \n",
      "    return float(avghdyn)\n",
      "\n",
      "def google_rank(text):   \n",
      "    words_df = pd.DataFrame(text.split(' '), columns=['words'])\n",
      "    words_df['words'] = words_df.words.apply(lambda x: str.lower(re.sub(\"\\W\", '', x)))\n",
      "    words_df['word_length'] = words_df.words.apply(lambda x: len(x))\n",
      "    words_df = words_df[words_df.word_length > 0]\n",
      "    words_df['in_sentiment'] = False\n",
      "    words_df['in_sentiment'][words_df.words.isin(sentiment_df_NS.word)] = True\n",
      "    words_df['google_rank'] = np.nan\n",
      "    words_df['google_rank'][words_df.in_sentiment == True] = words_df.words[words_df.in_sentiment == True].apply(lambda x: \n",
      "        float(sentiment_df.google_rank[sentiment_df.word == x].values))\n",
      "    google_rank = round(np.mean(words_df.google_rank[~words_df.google_rank.isnull()].values), 3)\n",
      "    return float(google_rank)\n",
      "\n",
      "def twitter_rank(text):  \n",
      "    words_df = pd.DataFrame(text.split(' '), columns=['words'])\n",
      "    words_df['words'] = words_df.words.apply(lambda x: str.lower(re.sub(\"\\W\", '', x)))\n",
      "    words_df['word_length'] = words_df.words.apply(lambda x: len(x))\n",
      "    words_df = words_df[words_df.word_length > 0]\n",
      "    words_df['in_sentiment'] = False\n",
      "    words_df['in_sentiment'][words_df.words.isin(sentiment_df_NS.word)] = True\n",
      "    words_df['twitter_rank'] = np.nan\n",
      "    words_df['twitter_rank'][words_df.in_sentiment == True] = words_df.words[words_df.in_sentiment == True].apply(lambda x: \n",
      "        float(sentiment_df.twitter_rank[sentiment_df.word == x].values))\n",
      "    twitter_rank = round(np.mean(words_df.twitter_rank[~words_df.twitter_rank.isnull()].values), 3)\n",
      "    return float(twitter_rank)\n",
      "\n",
      "def nyt_rank(text):   \n",
      "    words_df = pd.DataFrame(text.split(' '), columns=['words'])\n",
      "    words_df['words'] = words_df.words.apply(lambda x: str.lower(re.sub(\"\\W\", '', x)))\n",
      "    words_df['word_length'] = words_df.words.apply(lambda x: len(x))\n",
      "    words_df = words_df[words_df.word_length > 0]\n",
      "    words_df['in_sentiment'] = False\n",
      "    words_df['in_sentiment'][words_df.words.isin(sentiment_df_NS.word)] = True\n",
      "    words_df['nyt_rank'] = np.nan\n",
      "    words_df['nyt_rank'][words_df.in_sentiment == True] = words_df.words[words_df.in_sentiment == True].apply(lambda x: \n",
      "        float(sentiment_df.nyt_rank[sentiment_df.word == x].values))\n",
      "    nyt_rank = round(np.mean(words_df.nyt_rank[~words_df.nyt_rank.isnull()].values), 3)\n",
      "    return float(nyt_rank)\n",
      "\n",
      "def lyrics_rank(text):   \n",
      "    words_df = pd.DataFrame(text.split(' '), columns=['words'])\n",
      "    words_df['words'] = words_df.words.apply(lambda x: str.lower(re.sub(\"\\W\", '', x)))\n",
      "    words_df['word_length'] = words_df.words.apply(lambda x: len(x))\n",
      "    words_df = words_df[words_df.word_length > 0]\n",
      "    words_df['in_sentiment'] = False\n",
      "    words_df['in_sentiment'][words_df.words.isin(sentiment_df_NS.word)] = True\n",
      "    words_df['lyrics_rank'] = np.nan\n",
      "    words_df['lyrics_rank'][words_df.in_sentiment == True] = words_df.words[words_df.in_sentiment == True].apply(lambda x: \n",
      "        float(sentiment_df.lyrics_rank[sentiment_df.word == x].values))\n",
      "    lyrics_rank = round(np.mean(words_df.lyrics_rank[~words_df.lyrics_rank.isnull()].values), 3)\n",
      "    return float(lyrics_rank)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######<a href=\"#prep_function\">Stanford</a> - <a href=\"#prep_function\">RottenTomatoes</a> - <a href=\"#prep_function\">NewYorkTimes</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Prepare Function <a name=\"prep_function\"></a>\n",
      "\n",
      "This function will add the desired feature columns to any dataframe that has a column of texts."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \"text_col\" parameter is the column name (string) where the text is\n",
      "# features parameter is a list of functions to implement on the dataframe\n",
      "def make_prep_df(df, text_col, features):\n",
      "    \n",
      "    # making copy of dataframe\n",
      "    df_copy = df.copy()\n",
      "    \n",
      "    # renaming text column to make it easy to deal with\n",
      "    df_copy = df_copy.rename(columns={text_col: 'text_col'})\n",
      "    \n",
      "    # deleting rows where there are no words in the text column\n",
      "    df_copy = df_copy[~df_copy.text_col.isnull()].reset_index(drop=True)\n",
      "    \n",
      "    #map(features, lambda x: df_copy[x.__name__] = np.nan)\n",
      "    #map(features, lambda y: df_copy[y.__name__] = df_copy.text_col.apply(lambda x: y(x)))\n",
      "    \n",
      "    for func in features:\n",
      "        # making a column that has the same name as the function\n",
      "        df_copy[func.__name__] = np.nan\n",
      "        df_copy[func.__name__] = df_copy.text_col.apply(lambda x: func(x))\n",
      "        \n",
      "    # deleting rows where there is no average sentiment score\n",
      "    #df_copy = df_copy[~df_copy.avg_senti_score.isnull()]\n",
      "    #df_copy = df_copy.sort('avg_senti_score', ascending=False).reset_index(drop=True)\n",
      "    \n",
      "    # changing text column back to its original name\n",
      "    df_copy = df_copy.rename(columns={'text_col': text_col})\n",
      "    \n",
      "    # returns prepared dataframe\n",
      "    return df_copy\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######<a href=\"#sf_csv_prep_data\">Stanford</a> - <a href=\"#rt_csv_prep_data\">RottenTomatoes</a> - <a href=\"#nyt_csv_prep_data\">NewYorkTimes</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 4.1 Stanford MovieDB (stanford_prep_df)\n",
      "Add feature columns for Stanford MovieDB:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#functions = [post_length, avg_word_length, avg_senti_score]\n",
      "\n",
      "functions = [post_length, avg_word_length, avg_senti_score, avg_senti_score2, dyn_senti_score, google_rank, twitter_rank, nyt_rank, lyrics_rank]\n",
      "\n",
      "stanford_prep_df = make_prep_df(stanford_clean_df, 'review', functions)\n",
      "stanford_prep_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save dataframe to file:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stanford_prep_df.to_csv('stanford_prep_df.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load dataframe from CSV: <a name=\"sf_csv_prep_data\"></a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stanford_prep_df = pd.read_csv('stanford_prep_df.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######<a href=\"#train_data\">Stanford</a> - (<a href=\"rt_csv_prep_data\">RottenTomatoes</a> - <a href=\"#nyt_csv_prep_data\">NewYorkTimes</a>)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some Statistics: <a name=\"sf_stat_prep_data\"></a> \n",
      "<br>Compare with: <a href=\"#sf_stat_get_data\">Plain</a>, <a href=\"#sf_stat_clean_data\">Clean</a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'length of set:', len(stanford_prep_df)\n",
      "print 'average postlength:', int(np.mean(stanford_prep_df.lead.apply(lambda x: len(x))))\n",
      "print 'number of positive reviews:', len(stanford_prep_df[stanford_prep_df.rating >= 7])\n",
      "print 'number of negative reviews:', len(stanford_prep_df[stanford_prep_df.rating <= 4])\n",
      "print 'max postlength', stanford_prep_df.lead.apply(lambda x: len(x)).max()\n",
      "print 'min postlength', stanford_prep_df.lead.apply(lambda x: len(x)).min()\n",
      "                            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of set: 134\n",
        "average postlength: 314\n",
        "number of positive reviews: currently unknown\n",
        "number of negative reviews: currently unknown\n",
        "max postlength 1280\n",
        "min postlength 35\n"
       ]
      }
     ],
     "prompt_number": 261
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 4.2 RottenTomatoes (rottentomatoes_prep_df)\n",
      "Add feature columns:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "functions = [post_length, avg_word_length, avg_senti_score]\n",
      "\n",
      "rottentomatoes_prep_df = make_prep_df(rottentomatoes_clean_df, 'quote', functions)\n",
      "rottentomatoes_prep_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save dataframe to file:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rottentomatoes_prep_df.to_csv('rottentomatoes_prep_df.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load dataframe from CSV: <a name=\"rt_csv_prep_data\"></a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rottentomatoes_prep_df = pd.read_csv('rottentomatoes_prep_df.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######(<a href=\"#sf_csv_prep_data\">Stanford</a>) - <a href=\"#train_data\">RottenTomatoes</a> - (<a href=\"#nyt_csv_prep_data\">NewYorkTimes</a>)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some Statistics: <a name=\"rt_stat_prep_data\"></a> \n",
      "<br>Compare with: <a href=\"#rt_stat_get_data\">Plain</a>, <a href=\"#rt_stat_clean_data\">Clean</a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'length of set:', len(rottentomatoes_prep_df)\n",
      "print 'average postlength:', int(np.mean(rottentomatoes_prep_df.lead.apply(lambda x: len(x))))\n",
      "print 'number of positive reviews:', len(rottentomatoes_prep_df[rottentomatoes_prep_df.fresh == 'fresh'])\n",
      "print 'number of negative reviews:', len(rottentomatoes_prep_df[rottentomatoes_prep_df.fresh == 'rotten'])\n",
      "print 'max postlength', rottentomatoes_prep_df.lead.apply(lambda x: len(x)).max()\n",
      "print 'min postlength', rottentomatoes_prep_df.lead.apply(lambda x: len(x)).min()\n",
      "                            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of set: 134\n",
        "average postlength: 314\n",
        "number of positive reviews: currently unknown\n",
        "number of negative reviews: currently unknown\n",
        "max postlength 1280\n",
        "min postlength 35\n"
       ]
      }
     ],
     "prompt_number": 261
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 4.3 New York Times DB (nytimes_prep_df)\n",
      "Add feature columns:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "functions = [post_length, avg_word_length, avg_senti_score]\n",
      "\n",
      "nytimes_prep_df = make_prep_df(nytimes_clean_df, 'lead', functions)\n",
      "nytimes_prep_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save dataframe to file:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nytimes_prep_df.to_csv('nytimes_prep_df.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load dataframe from CSV: <a name=\"nyt_csv_prep_data\"></a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nytimes_prep_df = pd.read_csv('nytimes_prep_df.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "######(<a href=\"#sf_csv_prep_data\">Stanford</a> - <a href=\"#train_data\">RottenTomatoes</a>) - <a href=\"#nyt_csv_prep_data\">NewYorkTimes</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some Statistics: <a name=\"nyt_stat_prep_data\"></a> \n",
      "<br>Compare with: <a href=\"#nyt_stat_get_data\">Plain</a>, <a href=\"#nyt_stat_clean_data\">Clean</a>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'length of set:', len(rottentomatoes_prep_df)\n",
      "print 'average postlength:', int(np.mean(rottentomatoes_prep_df.lead.apply(lambda x: len(x))))\n",
      "print 'number of positive reviews:', 'currently unknown'\n",
      "print 'number of negative reviews:', 'currently unknown'\n",
      "print 'max postlength', rottentomatoes_prep_df.lead.apply(lambda x: len(x)).max()\n",
      "print 'min postlength', rottentomatoes_prep_df.lead.apply(lambda x: len(x)).min()\n",
      "                            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of set: 134\n",
        "average postlength: 314\n",
        "number of positive reviews: currently unknown\n",
        "number of negative reviews: currently unknown\n",
        "max postlength 1280\n",
        "min postlength 35\n"
       ]
      }
     ],
     "prompt_number": 261
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 5. Train Model <a name=\"train_data\"></a> \n",
      "\n",
      "Train different models with different data sources.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Make XY Function\n",
      "\n",
      "This function takes in the prepared dataframe source and outputs X (an array of features) and Y (an array of known scores)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# defining the make_xy() function\n",
      "# \"rating_col\" parameter is the name of the column where the ratings are;\n",
      "# can be continuous or binary values\n",
      "# features parameter is a list of the feature functions\n",
      "def make_xy(prep_data, rating_col, features):\n",
      "    \n",
      "    # using copy of dataframe just in case\n",
      "    prep_copy = prep_data.copy()\n",
      "    \n",
      "    # converting relevant columns to floats\n",
      "    \n",
      "    #map(features, lambda y:  prep_copy[y.__name__] = prep_copy[y.__name__].apply(lambda x: float(x)))\n",
      "    \n",
      "    for func in features:\n",
      "        prep_copy[func.__name__] = prep_copy[func.__name__].apply(lambda x: float(x))\n",
      "    \n",
      "    feature_array = []\n",
      "    for i in xrange(len(prep_copy)):\n",
      "        feature_list = [float(prep_copy[func.__name__][prep_copy.index == i]) for func in features]\n",
      "        feature_array.append(feature_list)\n",
      "    \n",
      "    #map(features, lambda x: df_copy[x.__name__] = np.nan)\n",
      "    #map(features, lambda y: df_copy[y.__name__] = df_copy.text_col.apply(lambda x: y(x)))\n",
      "    \n",
      "    # making 2D array of features\n",
      "    x = np.array(feature_array)\n",
      "    \n",
      "    # renaming the column that contains the ratings\n",
      "    prep_copy = prep_copy.rename(columns={rating_col: 'rating_col'})\n",
      "    \n",
      "    # making numpy array of the naive happy values we made up\n",
      "    y = np.array(prep_copy.rating_col.values)\n",
      "    \n",
      "    # returning x and y in a tuple\n",
      "    return x, y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 5.1 Train Model - Low Level Features to Predict Sentimentscore - Stanford Moviedatabase \n",
      "\n",
      "This function takes in the prepared dataframe source and outputs X (an array of features) and Y (an array of known scores)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_cols = [post_length, avg_word_length, avg_senti_score]\n",
      "stanford_test_df = make_stanford_df('test')\n",
      "stanford_test_df.to_csv('stanford_test.csv', index=False)\n",
      "stanford_test_prep_df = make_prep_df(stanford_test_df, 'review', features_cols)\n",
      "\n",
      "stanford_test_prep_df.to_csv('stanford_test_prep.csv', index=False)\n",
      "\n",
      "#stanford_prep_df = stanford_prep_df.rename(columns = {'word_count' : 'post_length'})\n",
      "\n",
      "#features_train = [post_length, avg_word_length]\n",
      "#Xtrain,Ytrain = make_xy(stanford_prep_df, 'rating', features_train)\n",
      "\n",
      "#features_train = [post_length, avg_word_length]\n",
      "#Xtest,Ytest = make_xy(stanford_test_prep_df, 'rating', features_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# making object from MultinomialNB class\n",
      "#clf = MultinomialNB()\n",
      "clf = GaussianNB()\n",
      "\n",
      "\n",
      "# printing fit and score\n",
      "clf.fit(Xtrain, Ytrain)\n",
      "print round(clf.score(Xtrain, Ytrain), 4)\n",
      "print round(clf.score(Xtest, Ytest), 4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "Can't handle mix of unknown and binary",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-34-47b4b0a7fe82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\base.pyc\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    292\u001b[0m         \"\"\"\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\metrics.pyc\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize)\u001b[0m\n\u001b[0;32m   1062\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1064\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_clf_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1065\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'multilabel-indicator'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\metrics.pyc\u001b[0m in \u001b[0;36m_check_clf_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         raise ValueError(\"Can't handle mix of {0} and {1}\"\n\u001b[1;32m--> 115\u001b[1;33m                          \"\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: Can't handle mix of unknown and binary"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.2141\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import LinearSVC\n",
      "\n",
      "stanford_test_prep_df['naive'] = 0.\n",
      "stanford_test_prep_df['naive'][stanford_test_prep_df.rating > 5] = 1\n",
      "\n",
      "features = [post_length, avg_word_length]\n",
      "X,Y = make_xy(stanford_test_prep_df, 'avg_senti_score', features)\n",
      "#X,Y = make_xy(stanford_test_prep_df, 'naive', features)\n",
      "# if we want to split a dataset into training and testing data\n",
      "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y)\n",
      "\n",
      "# making object from MultinomialNB class\n",
      "#clf = MultinomialNB()\n",
      "#clf = GaussianNB()\n",
      "clf = LinearSVC(tol = 50)\n",
      "#BernoulliNB(alpha=.01)\n",
      "#NearestCentroid()\n",
      "\n",
      "# printing fit and score\n",
      "clf.fit(Xtrain, Ytrain)\n",
      "\n",
      "# use clf.predict() to get values predicted by the classifier\n",
      "clf.predict(Xtrain)\n",
      "\n",
      "\n",
      "plt.hist(stanford_test_prep_df.avg_senti_score, bins = 50)\n",
      "#plt.hist(stanford_test_prep_df.naive, bins = 5)\n",
      "#plt.figure(2)\n",
      "plt.hist(clf.predict(Xtrain), bins = 50)\n",
      "#print rottentomatoes_prep_df.avg_senti_score.values[:20]\n",
      "\n",
      "# we need our own scoring function; this looks to see if the predicted values\n",
      "# are exactly the same as the actual values (this is NOT a good metric)\n",
      "#print round(clf.score(Xtrain, Ytrain), 4)\n",
      "#print round(clf.score(Xtest, Ytest), 4)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
      "#         Olivier Grisel <olivier.grisel@ensta.org>\n",
      "#         Mathieu Blondel <mathieu@mblondel.org>\n",
      "#         Lars Buitinck <L.J.Buitinck@uva.nl>\n",
      "# License: BSD 3 clause\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "import logging\n",
      "import numpy as np\n",
      "from optparse import OptionParser\n",
      "import sys\n",
      "from time import time\n",
      "import pylab as pl\n",
      "\n",
      "from sklearn.datasets import fetch_20newsgroups\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.feature_extraction.text import HashingVectorizer\n",
      "from sklearn.feature_selection import SelectKBest, chi2\n",
      "from sklearn.linear_model import RidgeClassifier\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn.linear_model import Perceptron\n",
      "from sklearn.linear_model import PassiveAggressiveClassifier\n",
      "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.neighbors import NearestCentroid\n",
      "from sklearn.utils.extmath import density\n",
      "from sklearn import metrics\n",
      "\n",
      "\n",
      "# Display progress logs on stdout\n",
      "logging.basicConfig(level=logging.INFO,\n",
      "                    format='%(asctime)s %(levelname)s %(message)s')\n",
      "\n",
      "\n",
      "# parse commandline arguments\n",
      "op = OptionParser()\n",
      "op.add_option(\"--report\",\n",
      "              action=\"store_true\", dest=\"print_report\",\n",
      "              help=\"Print a detailed classification report.\")\n",
      "op.add_option(\"--chi2_select\",\n",
      "              action=\"store\", type=\"int\", dest=\"select_chi2\",\n",
      "              help=\"Select some number of features using a chi-squared test\")\n",
      "op.add_option(\"--confusion_matrix\",\n",
      "              action=\"store_true\", dest=\"print_cm\",\n",
      "              help=\"Print the confusion matrix.\")\n",
      "op.add_option(\"--top10\",\n",
      "              action=\"store_true\", dest=\"print_top10\",\n",
      "              help=\"Print ten most discriminative terms per class\"\n",
      "                   \" for every classifier.\")\n",
      "op.add_option(\"--all_categories\",\n",
      "              action=\"store_true\", dest=\"all_categories\",\n",
      "              help=\"Whether to use all categories or not.\")\n",
      "op.add_option(\"--use_hashing\",\n",
      "              action=\"store_true\",\n",
      "              help=\"Use a hashing vectorizer.\")\n",
      "op.add_option(\"--n_features\",\n",
      "              action=\"store\", type=int, default=2 ** 16,\n",
      "              help=\"n_features when using the hashing vectorizer.\")\n",
      "op.add_option(\"--filtered\",\n",
      "              action=\"store_true\",\n",
      "              help=\"Remove newsgroup information that is easily overfit: \"\n",
      "                   \"headers, signatures, and quoting.\")\n",
      "\n",
      "(opts, args) = op.parse_args()\n",
      "if len(args) > 0:\n",
      "    op.error(\"this script takes no arguments.\")\n",
      "    sys.exit(1)\n",
      "\n",
      "print(__doc__)\n",
      "op.print_help()\n",
      "print()\n",
      "\n",
      "\n",
      "###############################################################################\n",
      "# Load some categories from the training set\n",
      "if opts.all_categories:\n",
      "    categories = None\n",
      "else:\n",
      "    categories = [\n",
      "        'alt.atheism',\n",
      "        'talk.religion.misc',\n",
      "        'comp.graphics',\n",
      "        'sci.space',\n",
      "    ]\n",
      "\n",
      "if opts.filtered:\n",
      "    remove = ('headers', 'footers', 'quotes')\n",
      "else:\n",
      "    remove = ()\n",
      "\n",
      "print(\"Loading 20 newsgroups dataset for categories:\")\n",
      "print(categories if categories else \"all\")\n",
      "\n",
      "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
      "                                shuffle=True, random_state=42,\n",
      "                                remove=remove)\n",
      "\n",
      "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
      "                               shuffle=True, random_state=42,\n",
      "                               remove=remove)\n",
      "print('data loaded')\n",
      "\n",
      "categories = data_train.target_names    # for case categories == None\n",
      "\n",
      "\n",
      "def size_mb(docs):\n",
      "    return sum(len(s.encode('utf-8')) for s in docs) / 1e6\n",
      "\n",
      "data_train_size_mb = size_mb(data_train.data)\n",
      "data_test_size_mb = size_mb(data_test.data)\n",
      "\n",
      "print(\"%d documents - %0.3fMB (training set)\" % (\n",
      "    len(data_train.data), data_train_size_mb))\n",
      "print(\"%d documents - %0.3fMB (test set)\" % (\n",
      "    len(data_test.data), data_test_size_mb))\n",
      "print(\"%d categories\" % len(categories))\n",
      "print()\n",
      "\n",
      "# split a training set and a test set\n",
      "y_train, y_test = data_train.target, data_test.target\n",
      "\n",
      "print(\"Extracting features from the training dataset using a sparse vectorizer\")\n",
      "t0 = time()\n",
      "if opts.use_hashing:\n",
      "    vectorizer = HashingVectorizer(stop_words='english', non_negative=True,\n",
      "                                   n_features=opts.n_features)\n",
      "    X_train = vectorizer.transform(data_train.data)\n",
      "else:\n",
      "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
      "                                 stop_words='english')\n",
      "    X_train = vectorizer.fit_transform(data_train.data)\n",
      "duration = time() - t0\n",
      "print(\"done in %fs at %0.3fMB/s\" % (duration, data_train_size_mb / duration))\n",
      "print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
      "print()\n",
      "\n",
      "print(\"Extracting features from the test dataset using the same vectorizer\")\n",
      "t0 = time()\n",
      "X_test = vectorizer.transform(data_test.data)\n",
      "duration = time() - t0\n",
      "print(\"done in %fs at %0.3fMB/s\" % (duration, data_test_size_mb / duration))\n",
      "print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
      "print()\n",
      "\n",
      "if opts.select_chi2:\n",
      "    print(\"Extracting %d best features by a chi-squared test\" %\n",
      "          opts.select_chi2)\n",
      "    t0 = time()\n",
      "    ch2 = SelectKBest(chi2, k=opts.select_chi2)\n",
      "    X_train = ch2.fit_transform(X_train, y_train)\n",
      "    X_test = ch2.transform(X_test)\n",
      "    print(\"done in %fs\" % (time() - t0))\n",
      "    print()\n",
      "\n",
      "\n",
      "def trim(s):\n",
      "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
      "    return s if len(s) <= 80 else s[:77] + \"...\"\n",
      "\n",
      "\n",
      "# mapping from integer feature name to original token string\n",
      "if opts.use_hashing:\n",
      "    feature_names = None\n",
      "else:\n",
      "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
      "\n",
      "\n",
      "###############################################################################\n",
      "# Benchmark classifiers\n",
      "def benchmark(clf):\n",
      "    print('_' * 80)\n",
      "    print(\"Training: \")\n",
      "    print(clf)\n",
      "    t0 = time()\n",
      "    clf.fit(X_train, y_train)\n",
      "    train_time = time() - t0\n",
      "    print(\"train time: %0.3fs\" % train_time)\n",
      "\n",
      "    t0 = time()\n",
      "    pred = clf.predict(X_test)\n",
      "    test_time = time() - t0\n",
      "    print(\"test time:  %0.3fs\" % test_time)\n",
      "\n",
      "    score = metrics.f1_score(y_test, pred)\n",
      "    print(\"f1-score:   %0.3f\" % score)\n",
      "\n",
      "    if hasattr(clf, 'coef_'):\n",
      "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
      "        print(\"density: %f\" % density(clf.coef_))\n",
      "\n",
      "        if opts.print_top10 and feature_names is not None:\n",
      "            print(\"top 10 keywords per class:\")\n",
      "            for i, category in enumerate(categories):\n",
      "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
      "                print(trim(\"%s: %s\"\n",
      "                      % (category, \" \".join(feature_names[top10]))))\n",
      "        print()\n",
      "\n",
      "    if opts.print_report:\n",
      "        print(\"classification report:\")\n",
      "        print(metrics.classification_report(y_test, pred,\n",
      "                                            target_names=categories))\n",
      "\n",
      "    if opts.print_cm:\n",
      "        print(\"confusion matrix:\")\n",
      "        print(metrics.confusion_matrix(y_test, pred))\n",
      "\n",
      "    print()\n",
      "    clf_descr = str(clf).split('(')[0]\n",
      "    return clf_descr, score, train_time, test_time\n",
      "\n",
      "\n",
      "results = []\n",
      "for clf, name in (\n",
      "        (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n",
      "        (Perceptron(n_iter=50), \"Perceptron\"),\n",
      "        (PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\"),\n",
      "        (KNeighborsClassifier(n_neighbors=10), \"kNN\")):\n",
      "    print('=' * 80)\n",
      "    print(name)\n",
      "    results.append(benchmark(clf))\n",
      "\n",
      "for penalty in [\"l2\", \"l1\"]:\n",
      "    print('=' * 80)\n",
      "    print(\"%s penalty\" % penalty.upper())\n",
      "    # Train Liblinear model\n",
      "    results.append(benchmark(LinearSVC(loss='l2', penalty=penalty,\n",
      "                                            dual=False, tol=1e-3)))\n",
      "\n",
      "    # Train SGD model\n",
      "    results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
      "                                           penalty=penalty)))\n",
      "\n",
      "# Train SGD with Elastic Net penalty\n",
      "print('=' * 80)\n",
      "print(\"Elastic-Net penalty\")\n",
      "results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
      "                                       penalty=\"elasticnet\")))\n",
      "\n",
      "# Train NearestCentroid without threshold\n",
      "print('=' * 80)\n",
      "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
      "results.append(benchmark(NearestCentroid()))\n",
      "\n",
      "# Train sparse Naive Bayes classifiers\n",
      "print('=' * 80)\n",
      "print(\"Naive Bayes\")\n",
      "results.append(benchmark(MultinomialNB(alpha=.01)))\n",
      "results.append(benchmark(BernoulliNB(alpha=.01)))\n",
      "\n",
      "\n",
      "class L1LinearSVC(LinearSVC):\n",
      "\n",
      "    def fit(self, X, y):\n",
      "        # The smaller C, the stronger the regularization.\n",
      "        # The more regularization, the more sparsity.\n",
      "        self.transformer_ = LinearSVC(penalty=\"l1\",\n",
      "                                      dual=False, tol=1e-3)\n",
      "        X = self.transformer_.fit_transform(X, y)\n",
      "        return LinearSVC.fit(self, X, y)\n",
      "\n",
      "    def predict(self, X):\n",
      "        X = self.transformer_.transform(X)\n",
      "        return LinearSVC.predict(self, X)\n",
      "\n",
      "print('=' * 80)\n",
      "print(\"LinearSVC with L1-based feature selection\")\n",
      "results.append(benchmark(L1LinearSVC()))\n",
      "\n",
      "\n",
      "# make some plots\n",
      "\n",
      "indices = np.arange(len(results))\n",
      "\n",
      "results = [[x[i] for x in results] for i in range(4)]\n",
      "\n",
      "clf_names, score, training_time, test_time = results\n",
      "training_time = np.array(training_time) / np.max(training_time)\n",
      "test_time = np.array(test_time) / np.max(test_time)\n",
      "\n",
      "pl.figure(figsize=(12,8))\n",
      "pl.title(\"Score\")\n",
      "pl.barh(indices, score, .2, label=\"score\", color='r')\n",
      "pl.barh(indices + .3, training_time, .2, label=\"training time\", color='g')\n",
      "pl.barh(indices + .6, test_time, .2, label=\"test time\", color='b')\n",
      "pl.yticks(())\n",
      "pl.legend(loc='best')\n",
      "pl.subplots_adjust(left=.25)\n",
      "pl.subplots_adjust(top=.95)\n",
      "pl.subplots_adjust(bottom=.05)\n",
      "\n",
      "for i, c in zip(indices, clf_names):\n",
      "    pl.text(-.3, i, c)\n",
      "\n",
      "pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SystemExit",
       "evalue": "2",
       "output_type": "pyerr",
       "traceback": [
        "An exception has occurred, use %tb to see the full traceback.\n",
        "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Usage: -c [options]\n",
        "\n",
        "-c: error: no such option: -f\n",
        "To exit: use 'exit', 'quit', or Ctrl-D.\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 6. Predict from Data\n",
      "\n",
      "Predict outcome of given data source.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 7. Prediction Visualization\n",
      "\n",
      "Prepare datasources with neccessary extension including required featurelist. Result will be stored in local CSV files.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "*css tweaks in this cell*\n",
      "<style>\n",
      "div.text_cell_render {\n",
      "    line-height: 150%;\n",
      "    font-size: 110%;\n",
      "    width: 800px;\n",
      "    margin-left:50px;\n",
      "    margin-right:auto;\n",
      "    }\n",
      "</style>"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}