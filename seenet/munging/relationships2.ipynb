{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import modules\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import re\n",
      "import datetime as dt\n",
      "import itertools as it"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 411
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load relationship data (formatted from relationships1.R)\n",
      "df = pd.io.parsers.read_csv('../data/relationships2.csv')\n",
      "comdf = pd.io.parsers.read_csv('../data/prox-pairs.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 412
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_cols = list(comdf.columns.values[4:])\n",
      "all_cols_dt = [dt.datetime.strptime(stamp, \"%Y-%m-%d\").date() for stamp in all_cols]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 413
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# leave out source/target cols\n",
      "df = df.iloc[:,2:]\n",
      "# replace NaN with ''\n",
      "df = df.fillna('')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 414
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get survey dates as datetime objects\n",
      "rel_dates = list(df.columns.values[1:])\n",
      "rel_dates_dt = [dt.datetime.strptime(stamp, \"%Y-%m-%d\").date() for stamp in rel_dates]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 415
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels = {'a':'','b':'BlogLivejournalTwitter','c':'FacebookAllTaggedPhotos','d':'PoliticalDiscussant','e':'SocializeTwicePerWeek','f':'CloseFriend'}\n",
      "\n",
      "master = []\n",
      "\n",
      "# group by subject pairs\n",
      "for g in df.groupby('pairs'):\n",
      "\n",
      "    # vals contains all survey answers\n",
      "    vals = g[1] \n",
      "    # row compiles the row values for each subject pair\n",
      "    row = [g[0]]\n",
      "    \n",
      "    # iterate through all survey answers (ie. dates) for a pair\n",
      "    for colidx, col in enumerate(vals.columns[1:]):\n",
      "        found = False\n",
      "        # go through all values in each column\n",
      "        # each column is a date the survey was given\n",
      "        # there should only be one survey answer in each column, although this isn't always so\n",
      "        for x in vals[col]:\n",
      "            # we're looking for non-empty cells\n",
      "            if isinstance(x,str) and len(x) > 1:                 \n",
      "                found = True\n",
      "                # if found, replace the actual string with an ordinal rank 1-5 (5=best)\n",
      "                # it's not clear that these categories are ordinal, but we're making them so\n",
      "                rel_value = [''.join(['TYPE',key]) for key, val in labels.iteritems() if x == val][0]\n",
      "                # append this new ranking to the row for that subject pair\n",
      "                row.append(rel_value)\n",
      "                break\n",
      "        # if the entire column in blank, use the previous value for that survey date\n",
      "        if not found:\n",
      "            oldval = row[-1] if len(row) > 1 else ''\n",
      "            row.append(oldval)\n",
      "    # append each subject pair row to master\n",
      "    master.append( row )\n",
      "\n",
      "# make df out of master\n",
      "df2_cols = ['pairs']+rel_dates_dt\n",
      "df2 = pd.DataFrame(data=master, columns=df2_cols)\n",
      "# turn NaNs to empty space\n",
      "df2 = df2.fillna('')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 432
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_full_cols = all_cols_dt\n",
      "df_full = pd.DataFrame(index=df2.pairs, columns=df_full_cols).reset_index()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 433
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Although we now have the relationship data organized the way we want it, eventually we'll still need to compare the dates that each survey was given with the dates in the com-pairs and prox-pairs time series.  Since there are only 5 or 6 survey dates and there are about 20 time series checkpoints, some imputation of relationship states is necessary at the interstices (not to mention the fact that the actual survey dates themselves don't match up with the time series checkpoints).  \n",
      "<br />\n",
      "So in order to figure out how one person feels about another at any given checkpoint in our time series, we take the closest past survey date and use the relationship status given at that date.  Ie. if UserA says UserB is a close friend in Nov 2008, and then says UserB is only an acquaintance in Jan 2009, if we have a time series checkpoint that arrives in Dec 2008, we'll report UserA -> UserB as \"close friend\" for that checkpoint.\n",
      "<br />\n",
      "\n",
      "We can either do that on-the-fly with d3, or just load up a separate data file with all this data pre-computed.  To save on rendering overhead, we load up the separate data file here.  (Since the data is fixed, we don't need to worry about new data being added into the mix.)\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# outer loop: go through each column in complete time series\n",
      "for fullidx, fullcol in enumerate(df_full.columns.values[1:]):\n",
      "    # inner loop: go through each column in relationship survey reports (ie. survey dates)\n",
      "    insert = df_full.columns.values[fullidx+1]\n",
      "    for df2idx, df2col in enumerate(df2.columns.values[1:]):\n",
      "        # if time series date <= survey report date, adopt survey data from df2col and move on\n",
      "        if fullcol <= df2col:\n",
      "            df_full[insert] = df2[df2col]\n",
      "            break\n",
      "        # in the case that we're already at the last survey date and ts checkpoints keep going\n",
      "        # then just use the ultimate survey date values\n",
      "        elif df2idx+1 == len(df2.columns.values[1:]):\n",
      "            df_full[insert] = df2[df2col]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 434
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# convert column names back to strings\n",
      "# not sure if this is necessary - i did this during a debugging frenzy\n",
      "col_date_strings = [d.strftime(\"%Y-%m-%d\") for d in all_cols_dt]\n",
      "df_full.columns = ['pairs']+col_date_strings"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 435
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# write to csv\n",
      "df_full.to_csv('../data/relations.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 419
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# write to json \n",
      "df_full.to_json('../data/relations.json', date_format='iso')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 436
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# json ended up being a better format for d3 to get at the data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}